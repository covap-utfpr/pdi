# Segmentação
<!--## Detecção por descontinuidade
### Detecção de ponto
### Detecção de linha-->
## Detecção de Bordas
<!--### Modelos de Bordas
### Método do gradiente ( Roberts, Prewitt, Sobel)
### Método de Marr-Hildreth-->
### Método de Canny
O algoritmo de Canny recebeu esse nome em alusão a John Canny, que o propôs em seu artigo, “A computational Approach to Edge Detection"[@canny1986computational], publicado em 1986. Sua formulação se baseava em três pontos principais:

- Uma baixa taxa de erro, ou seja, todas as bordas presentes na imagem devem ser encontradas e não deve haver respostas espúrias.
- O segundo critério diz que as bordas detectadas devem estar bem localizadas, em outras palavras, elas devem estar o mais próximo possível das bordas verdadeiras.
- O terceiro e último critério diz que se deve minimizar o número de máximos locais em torno da borda verdadeira, para que não sejam encontrados múltiplos pixels de borda onde deve haver somente um.

Em seu trabalho, Canny buscou encontrar soluções ótimas, matematicamente, que obedecessem os três critérios. Apesar disso, é muito difícil, ou impossível, encontrar uma solução que satisfaça completamente os objetivos descritos[@gonzalez2010, p.474]. Todavia é possível utilizar uma aproximação por meio de otimização numérica com as bordas em degrau em um exemplo 1-D que contenham ruído branco gaussiano e mostrar que uma boa aproximação para um ótimo detector de bordas é a primeira derivada de uma gaussiana[@gonzalez2010, p.474]:

$$\frac{\mathrm{d} }{\mathrm{d} x}e^{\frac{-x^2}{2\sigma^2}} = \frac{-x}{\sigma^2}e^{\frac{-x^2}{2\sigma^2}}$$

Canny demonstrou que a utilização dessa aproximação pode ser feita com uma taxa 20% inferior à solução numérica, o que a torna praticamente imperceptível para muitas das aplicações[@gonzalez2010, p.474].
A ideia anterior foi imaginada em um aspecto 1D, precisamos agora, expandir esse conceito para uma generalização 2D. Uma borda de degrau pode ser caracterizada pela sua posição, orientação e possível magnitude. Aplicar um filtro Gaussiano em uma imagem e depois diferenciá-la forma um simples e efetivo operador direcional[@sonka2014, p.145]. Digamos então que $f(x,y)$ seja uma imagem e $G(x,y)$ a função gaussiana:

$$G(x,y) = e^{-\frac{x^2+y^2}{2\sigma^2}}$$

Temos como saída a imagem suavizada:

$$f_s(x,y)=G(x,y)*f(x,y)$$

E após isso realizamos o cálculo da magnitude e direção do gradiente:

$$M(x,y) = \sqrt{g_x^2+g_y^2}$$
$$\alpha(x,y)= \tan^{-1}\left ( \frac{g_y}{g_x} \right )$$

onde $g_x=\partial f_s/\partial x$ e $g_y=\partial f_s/\partial y$. Para o cálculo das derivadas parciais podemos utilizar tanto Prewitt quanto Sobel. Como essa primeira etapa utiliza operadores que calculam as primeiras derivadas, acabamos com bordas grossas, e o terceiro objetivo da proposta de Canny é ter bordas com único ponto, por isso o próximo passo é a de afinar as bordas encontradas. O método que usaremos para isso é chamado supressão dos não máximos. Esse processo tem como base a discretização das direções da normal da borda(vetor gradiente), ou seja, em uma região 3x3 temos 4 direções possíveis, como pode ser visto na figura \@ref(fig:edgeorientation)(c), sendo que consideramos 4 pois é contando as duas direções, como exemplo, consideramos um borda de 45º se ela se encontra entre +157,5º e +112,5º ou -67,5º e -22,5º.
Na figura \@ref(fig:edgeorientation)(a) temos um exemplo de duas orientações que podem existir em uma borda horizontal, e na figura \@ref(fig:edgeorientation)(b) podemos ver a normal de uma borda horizontal e o intervalo de valores onde a direção do vetor gradiente pode existir.

(ref:edgeorientation) Discretização das direções. (a)Borda horizontal. (b) Intervalo dos possíveis valores do ângulo, normal da borda, para uma borda horizontal. (c) Intervalo de valores do ângulo da normal para os diferentes tipos de borda. [@gonzalez2010, p. 475]

```{r edgeorientation, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:edgeorientation)', fig.align='center', out.width='70%'}
knitr::include_graphics(rep('imagens/06-segmentacao/edge_orientation.png'))
```

Se consideramos $d1$, $d2$, $d3$ e $d4$ como as direções possíveis em uma área 3x3, podemos formular o seguinte esquema de supressão de não máximos de uma região 3x3 centrada em todos os pontos $(x,y)$ de [@gonzalez2010, p.475]:
- Encontrar a direção $d_k$ que está mais perto de $\alpha (x,y)$.
- Se o valor de $M(x,y)$ for inferior a pelo menos um dos seus dois vizinhos ao logo de $d_k$, deixe $g_N(x,y)=0$(supressão); caso contrário, deixe $g_N(x,y)=M(x,y)$.
Onde $g_N(x,y)$ é a imagem suprimida.
A última operação a ser realizada é a limiarização, para se remover os pontos de falsas bordas. Aqui usaremos a limiarização por histerese que utiliza dois limiares, um baixo($T_L$) e um alto ($T_H$), sendo que Canny sugeriu, em seu trabalho, que a razão entre o limiar alto para o baixo deva ser de dois ou três para um.
Podemos imaginar essa limiarização da seguinte forma, criamos duas imagens adicionais:

$$g_{NH}(x,y) = g_N(x,y)\geq T_H$$ e $$g_{NL}(x,y) = g_N(x,y)\geq T_L$$

Onde $g_{NH}(x,y)$ e $g_{NL}(x,y)$ são definidas inicialmente como $0$. Temos então que $g_{NH}(x,y)$conterá os pixels que são maiores que o nosso limiar e $g_{NL}(x,y)$ terá os pixels que estão acima do nosso limiar baixo, o que significa que ele contém os pixels que se encontram no meio dos dois limiares mais o que está acima do limiar alto, temos então que remover esses pixels, o que significa:
$$g_{NL}(x,y)=g_{NL}(x,y)-g_{NH}(x,y)$$

Podemos chamar os pixels de $g_{NH}(x,y)$ de pixels fortes e os de $g_{NL}(x,y)$ de fracos. Ao final dessa limiarização todos os pixels fortes são classificados como borda válida, mas com falhas, que nos leva a outro processo:

- Localizar o próximo pixel borda a ser revisado em $g_{NH}(x,y)$, chamaremos esse pixel de p.
- Classificar todos os pixels fracos de $g_{NL}(x,y)$ que tenham conexão, como a conectividade-8, como bordas válidas.
- Quando todos os pixels de $g_{NL}(x,y)$ Se forem analisados, pulamos para 4, senão voltamos para 1.
- Zerar todos os pixels de $g_{NL}(x,y)$ que não são bordas válidas.

Ao final desses processos teremos a imagem de saída do algoritmo de Canny. Como dito por [@gonzalez2010, p.476], o uso de duas imagens $g_{NH}(x,y)$ e $g_{NL}(x,y)$ é uma boa maneira para se explicar o algoritmo de uma maneira simples, mas na prática isso pode ser feito diretamente na imagem $g_N(x,y)$.
Por fim, sumarizando os passos do algoritmo, com um exemplo:

1. Imagem original

(ref:original) Imagem original.

```{r original, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:original)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/original.jpg'))
```

2. Aplicação do filtro gaussiano para suavizar a imagem.

(ref:gaussian) Imagem filtrada com filtro gaussiano.

```{r gaussian, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:gaussian)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/gaussian.jpg'))
```

3. Cálculo da magnitude do gradiente e dos ângulos.

(ref:derivadas) (a) Sobel na direção vertical. (b) Sobel na direção horizontal. (c) Gradiente. (d) Angulos. [@burger2009, p. 98]

```{r derivadas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:derivadas)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/derivadas.jpg'))
```

4. Aplicação da supressão não máxima para afinar as bordas.

(ref:supressao) Resultado da supressão não máxima.

```{r supressao, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:supressao)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/supressao.jpg'))
```

6. Usar limiarização por histerese e análise de conectividade para detectar e conectar as bordas.

(ref:threshold) Resultado da histerese e conecção de bordas.

```{r threshold, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:threshold)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/threshold.jpg'))
```

7. Resultado final.

(ref:canny) Resultado final da detecção de bordas de Canny.

```{r canny, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:canny)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/canny.jpg'))
```

## Transformada de Hough
A Transformada de Hough é uma técnica utilizada para detectar formas em imagens, sejam elas linhas, círculos ou elipses. Apesar de ela ser muito utilizada e ter sido criada para detecção principalmente de linhas, ela pode ser usada para a detecção de outras formas, como dito anteriormente.

### Transformada de Hough para detecção de linhas
Para começar a entender essa transformada, imaginemos que temos um ponto $(x_i, y_i)$ no plano $xy$ e a equação da reta $y_i=ax_i+b$. Pelo ponto $(x_i, y_i)$ passam infinitas retas e todas satisfazem a equação. Podemos escrever a equação anterior em relação a $b$, ou seja, $b=-x_ia+y_i$, o que nos leva ao plano $ab$(espaço de parâmetros) onde essa nova equação gerará uma única reta.

Agora imaginemos um outro ponto $(x_j, y_j)$ no plano $xy$, podemos também levá-lo ao plano ab com a equação $b=-x_ja+y_j$. Como podemos ver na figura \@ref(fig:planoxy)(b) as duas retas geradas no plano $ab$ se cruzam nas coordenadas $(a', b')$, e esse ponto de cruzamento representa a reta que cruza os dois pontos no plano $xy$, como podemos ver na mesma representação \@ref(fig:planoxy)(b). Na realidade, todos os pontos pertencentes a reta definida por esses dois pontos em $xy$ tem sua reta respectiva em $ab$ e todas elas se cruzam no ponto $(a', b')$, isso nos dá uma maneira de realizar a detecção de bordas, pois podemos imaginar essa reta como nossa borda, assim, para achá-la basta localizar o ponto no espaço de parâmetros onde um grande número de retas se cruzam.

(ref:planoxy) Plano xy e ab. [@gonzalez2010, p.483]

```{r planoxy, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:planoxy)', fig.align='center', out.width='65%'}
knitr::include_graphics(rep('imagens/06-segmentacao/planoxy.png'))
```

Ocorre um pequeno problema nessa forma, pois quando a reta se aproxima da direção vertical, $ab$ se aproxima do infinito. Para resolver essa dificuldade, em vez de levarmos os pontos a retas no espaço $ab$ cartesiano utilizamos um espaço em coordenadas polares. Para isso utilizamos a seguinte equação:
$$\rho=x\cos{\theta}+y\ sen{\ \theta}$$
Na figura \@ref(fig:planoxyrhotheta)(a) podemos ver isso de maneira gráfica, temos que p corresponde à distância da origem até a reta. Cada uma das curvas senoidais da figura \@ref(fig:planoxyrhotheta)(b) representa um conjunto de linhas que cruzam os dois pontos da figura \@ref(fig:planoxyrhotheta)(a), sendo que na interseção das curvas temos a reta que cruza esses pontos.

(ref:planoxyrhotheta) Imagem de ônibus com filtro de aguçamento e de suavização [@burger2009, p. 98]

```{r planoxyrhotheta, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:planoxyrhotheta)', fig.align='center', out.width='90%'}
knitr::include_graphics(rep('imagens/06-segmentacao/planoxyrhotheta.png'))
```

A figura \@ref(fig:planoxyrhotheta)(c) mostra como fazemos a representação do espaço , usamos uma matriz onde esse espaço é subdividido em várias células, chamadas células acumuladoras. Os valores de $\theta_{\text{min}}$ e $\theta_{\text{max}}$ são geralmente $-90^{\circ}\leq \theta\leq90^{\circ}$ e os valores de $\rho_min$ e $\rho_max$ são $-D\leq\rho\leq D$, onde $D$ é o comprimento da diagonal da imagem, ou seja, $D=\sqrt{vertical^2+horizontal^2}$. O que fazemos então é andar por todos os pontos de borda da imagem de entrada e calcular o valor de  a partir da equação apresentada anteriormente usando o valor de $(x,y)$ e variando o ângulo , com isso a cada valor do ângulo teremos um  diferente e somamos mais um na célula correspondente da matriz acumuladora, que inicialmente é toda preenchida com zeros. Ao final de todo o processo termos determinadas células com valores mais altos, essas são conhecidas como picos e correspondem ao cruzamento de duas ou mais curvas senoidais do plano  o que corresponde a uma linha ligando pontos no plano $xy$. 

A seguir temos um exemplo, que nos ajuda a entender e ver na prática o funcionamento da transformada de Hough. A figura \@ref(fig:houghumponto)(a) contém uma imagem de tamanho 101x101 com um ponto no centro, ou seja $(x,y)=(50,50)$ e a figura \@ref(fig:houghumponto)(b) contém a matriz acumuladora da transformada, onde podemos ver a curva senóide formada pelo ponto. Verificando os valores nela vemos que para $\rho=-90^{\circ}$ temos: 

$$\rho=50 \cdot \cos(-90^{\circ})+50\cdot\text{sen}(-90^{\circ}) = -50$$
para $\theta=90^{\circ}$ temos:

$$\rho=50\cdot \cos(90^{\circ})+50\cdot\text{sen}(90^{\circ})=50$$
para $\theta=45^{\circ}$ temos:

$$\rho=50\cdot \cos(45^{\circ})+50\cdot \text{sen}(45^{\circ})\approx70,71$$
e para $\theta=-45^{\circ}$ temos:

$$\rho=50\cdot\cos(-45º)+50\cdot \text{sen}(-45º)=0$$ 

(ref:houghumponto) Transformada de Hough para um ponto.

```{r houghumponto, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghumponto)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_um_ponto.jpg'))
```

Na figura \@ref(fig:houghdoispontosesquerda)(a) temos dois pontos, a e b, onde foi realizada a transformada de Hough que tem como espaço de saída a figura \@ref(fig:houghdoispontosesquerda)(b). A reta que passa por esses dois pontos, chamada de reta c é representada por uma reta pontilhada na figura \@ref(fig:houghdoispontosesquerda)(a) e na figura \@ref(fig:houghdoispontosesquerda)(b) temos o ponto no plano  que representa essa reta, ou seja, uma reta a uma distância $\rho\approx70,71$ da origem com ângulo de $45^{\circ}$.

(ref:houghdoispontosesquerda) Transformada de Hough para um ponto em 45º.

```{r houghdoispontosesquerda, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghdoispontosesquerda)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_dois_ponto_esquerda.png'))
```

Na figura \@ref(fig:houghdoispontosdireita)(a) temos mais um exemplo, desta vez com um ponto localizado a sua direita, diferentemente da anterior, esses dois pontos formam uma reta de $-45^{\circ}$, fato que pode ser visto na figura \@ref(fig:houghdoispontosdireita)(b) onde o ponto de encontro das duas curvas acontece em $\theta=-45^{\circ}$ com um valor de $\rho=0$ já que a reta cruza a origem, ou seja, não possui distância em relação a ela.

(ref:houghdoispontosdireita) Transformada de Hough para um ponto em -45º.

```{r houghdoispontosdireita, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghdoispontosdireita)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_dois_ponto_direita.png'))
```

Nosso último exemplo contém uma imagem com três pontos, onde temos três tipos de retas possíveis. Observando a figura \@ref(fig:houghtrespontos)(a) podemos ver os pontos a, b e c e as retas que passam por eles d, e e f, e na figura \@ref(fig:houghtrespontos)(b) temos a transformada de Hough para esse imagem, algo interessante de se notar é o fato de a reta que passa pelos pontos b e c ser detectada duas vezes, isso se deve a uma característica da transformada de Hough chamada relação de adjacência reflexiva, ou seja, isso acontece como resultado pela maneira como $\rho$ e  $\theta$ mudam de sinal quando chegamos as extremidades de $\pm90^{\circ}$.

(ref:houghtrespontos) Transformada de Hough para três pontos.

```{r houghtrespontos, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghtrespontos)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_tres_ponto.png'))
```

Na figura \@ref(fig:houghlineexemplo) temos nosso último exemplo na detecção de linhas, dessa vez realizado em uma imagem real, neste caso primeiramente foi realizado a detecção de bordas pelo método de Canny, como pode ser visto na figura \@ref(fig:houghlineexemplo)(a). Logo após foi realizada a transformação de Hough, com resultado em figura \@ref(fig:houghlineexemplo)(b) e por fim temos a imagem original com as linhas detectadas em figura \@ref(fig:houghlineexemplo)(c). Atenção ao fato de que nem todos os picos da transformada podem ser utilizados como linhas, pois teríamos um número enorme delas, para isso utilizamos um threshold, utilizando somente as linhas que tiverem o número de votos(acumulação na matriz) superior a um valor limítrofe.

(ref:houghlineexemplo) Resultado da transformada de Hough usada na detecção de linhas em uma imagem.

```{r houghlineexemplo, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghlineexemplo)', fig.align='center', out.width='95%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_line_exemplo.jpg'))
```

### Transformada de Hough para detecção de círculos
A transformada de Hough pode ser estendida para detecção de círculos, para isso substituímos a equação da reta pela equação do círculo:
$$(x-x_0)^2+(y-y_0)^2=r^2$$

Nesse caso também andamos por cada pixel das bordas da imagem e o levamos ao espaço de parâmetro com as seguintes equações:

$$x_0=x-r\cos(\theta)$$
e

$$y_0=y-\text{sen}(\theta)$$

A diferença é que neste caso o nosso espaço de parâmetro terá três dimensões, isso decorre do fato de que como desenhamos um círculo para cada pixel do círculo da imagem, a variação do diâmetro desse círculo deve levar a uma variação dos círculos descritos no espaço de parâmetros, então além da variação dos valores de $x$ e $y$ também devemos variar os valores de $r$. Uma representação disso pode ser vista na figura \@ref(fig:houghCircle)(a) onde temos três pixels que definem um círculo, na figura \@ref(fig:houghCircle)(b) temos os círculos no espaço de parâmetros e na figura \@ref(fig:houghCircle)(c) podemos ver um representação de um espaço de parâmetros com diferentes raios.

(ref:houghCircle) Transformada de Hough para círculos.[@nixon2019feature, p.255]

```{r houghCircle, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghCircle)', fig.align='center', out.width='60%'}
knitr::include_graphics(rep('imagens/06-segmentacao/houghCircle.png'))
```

A figura \@ref(fig:moedas) contém uma imagem com algumas moedas, na figura \@ref(fig:houghcircleraios)(a) temos as bordas da imagem detectada com o método de Canny, logo após, na figura \@ref(fig:houghcircleraios)(b) - (f) temos a representação do espaço de Hough para diferentes valores de raio. E na figura \@ref(fig:houghcircleresultado) temos o resultado da detecção de círculo após encontrados os picos do espaço de parâmetros.

(ref:moedas) Imagem original de moedas. [@burger2009, p. 98]

```{r moedas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:moedas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/moedas.jpg'))
```

(ref:houghcircleraios) Canny e espaço de parâmetros. [@burger2009, p. 98]

```{r houghcircleraios, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghcircleraios)', fig.align='center', out.width='100%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_circle_raios.jpg'))
```

(ref:houghcircleresultado) Resultado final da transformada de Hough para círculos. [@burger2009, p. 98]

```{r houghcircleresultado, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghcircleresultado)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_circle_resultado.jpg'))
```

## Detecção de Quinas
Quinas são pontos chaves na visão computacional por serem muito úteis na descrição e correspondência de objetos usando poucos dados. E para identificação dos pontos, existem diferentes métodos, dentre eles o mais comum é o de Harris, que é o sucessor do de Moravec [@nixon2019feature, p. 178].

### Detector de Quinas de Moravec
Moravec obtém sua medida de curvatura através de uma variação média de intensidade em quatro direções principais: $(0,1), (0,-1), (1,0)$ e $(-1,0)$. Isso é feito através da seguinte equação, considerando a análise sobre o $pixel(x,y)$, o deslocamento $(u,v)$ e a janela $2w+1$ [@nixon2019feature, p. 185].

$$E_{u,v}(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}[P_{x+i,\ y+j} - P_{x+i+u,\ y+j+v}]^2$$
Essa equação também aproxima a função de autocorrelação na direção $(u,v)$ [@nixon2019feature, p. 186].

O detector de Moravec apesar de ser intuitivo seu funcionamento, ele considera apenas um pequeno conjunto de mudanças possíveis. Então, Harris propôs ainda avaliar a autocorrelação, mas por uma expressão analítica [@nixon2019feature, p. 185].

### Detector de Quinas de Harris
O detector de Harris é desenvolvido na ideia de Moravec e sua equação, mas com uma abordagem mais complexa. Harris assume que $P_{x+i+u,\ y+j+v}$ possa ser estimado pela série de Taylor de primeira ordem [@nixon2019feature, p. 193]. Dessa forma,

$$P_{x+i+u,\ y+j+v} = P_{x+i,\ y+j} + \frac{\partial{P_{x+i,\ y+j}}}{\partial x}u + \frac{\partial{P_{x+i,\ y+j}}}{\partial y}v $$

Substituindo na equação de Moravec
$$E_{u,v}(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}[\frac{\partial{P_{x+i,\ y+j}}}{\partial x}u + \frac{\partial{P_{x+i,\ y+j}}}{\partial y}v]^2$$ 
E expandindo a potência
$$E_{u,v}(x,y) = A(x,y)u^2 + 2C(x,y)uv + B(x,y)v^2$$
Esta última equação pode ser representada forma de matriz. Representação útil para compreensão mais à frente neste tópico [@nixon2019feature, p. 187].
$$
\begin{split}
E_{u,v}(x,y) &= 
\begin{bmatrix}u & v\end{bmatrix}
\begin{bmatrix}A(x,y) & C(x,y)\\ C(x,y) & B(x,y)\end{bmatrix}
\begin{bmatrix}u \\ v\end{bmatrix}
\\&= D^TMD
\end{split}
$$
onde
$$A(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}(\frac{\partial P_{x+i, y+j}}{\partial x})^2$$
$$B(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w} (\frac{\partial P_{x+i, y+j}}{\partial y})^2$$
$$C(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w} (\frac{\partial P_{x+i, y+j}}{\partial x})(\frac{\partial P_{x+i, y+j}}{\partial y})$$
Como $E_{u.v}(x,y)$ tem a forma de uma função quadrática, então possui dois eixos principais. Podemos rotacioná-la a fim de alinhar seus eixos com os do sistema de coordenadas, obtendo $F_{u,v}(x,y)$ [@nixon2019feature, p. 187].
$$F_{u,v}(x,y) = \alpha(x,y)^2u^2 + \beta(x,y)^2v^2$$
Ou em sua forma matricial. Note que são rotacionados os eixos definidos pelo $D$
$$F_{u,v}(x,y) = R^TD^TMDR$$
$$F_{u,v}(x,y) = D^TR^TMRD$$
$$F_{u,v}(x,y) = D^TQD$$
$$Q = \begin{bmatrix} \alpha & 0\\ 0 & \beta  \end{bmatrix}$$
Os valores de $\alpha$ e $\beta$ são proporcionais à função de autocorrelação nos principais eixos. Dessa forma,  $\alpha$ e $\beta$  serão pequenos  se o $pixel(x,y)$ for de uma região com intensidade constante, um será de valor grande e outro pequeno se estiverem em uma borda reta, e ambos terão valores grandes se estiverem em uma borda com curvatura acentuada. Portanto, a medida de curvatura é definida como $k_k(x,y)$ [@nixon2019feature, p. 187].
$$k_k(x,y) = \alpha \beta - k(\alpha + \beta)^2$$
No qual $k$ controla a sensibilidade do detector.

Como $Q$ é uma composição ortogonal de $M$. Os elementos de Q são chamados de autovalores [@nixon2019feature, p. 188]. Inferimos que
$$Q = R^TMR$$
Então, a partir da equivalência de determinantes e traços, é possível produzir uma equação equivalente a $Y$ com os valores da matriz $M$ [@nixon2019feature, p. 188].
$$\alpha \beta = A(x,y)B(x,y) - C(x,y)^2$$
$$\alpha + \beta = A(x,y) + B(x,y)$$
Assim
$$
\begin{split}
k_k(x,y) &= \alpha \beta - k(\alpha + \beta)^2
\\&= A(x,y)B(x,y) - C(x,y)^2 - k(A(x,y) + B(x,y))^2
\\&=det(M) - k(trace(M))^2
\end{split}
$$
A Figura \@ref(fig:imagemQuinas) (a) é a imagem original. A Figura \@ref(fig:imagemQuinas) (b) foi gerada usando o detector de Harris com uma vizinhança 5x5 ($w=2$) para cada deslocamento $(u,v)$, com a derivada sendo calculada pelo Operador de Sobel (3x3) e com sensibilizador $k=0.01$. Limiarizou-se a imagem de curvatura, descartando os valores que não fossem maiores que 9% do valor máximo. E nas posições $(x,y)$ da imagem que continham as curvaturas, foi destacado em rosa. 
Observe que a imagem identificou as quinas do tabuleiro de xadrez e do cubo mágico, porém não detectou outras quinas como as das árvores. Além disso, foi encontrado quinas que não são próprias dos objetos, e sim da iluminação. 
Variando tanto o sensibilizador da função, $k$, como o limiar é provável que consigamos encontrar mais quinas, com o custo de também poder classificar ruídos que foram identificados como bordas também como quinas. Entretanto, já vimos que o filtro gaussiano pode ser que nos ajude neste problema. 


(ref:imagemQuinas) Exemplo de detecção de Quinas pelo método de Harris.

```{r imagemQuinas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemQuinas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemQuinas.png'))
```


## Detecção de Blobs
Blobs, do inglês bolhas, são regiões da imagem em que os pixels têm valores aproximadamente iguais. Uma boa representação - um tanto quanto artificial - disso é a função gaussiana, como pode ser vista na figura  \@ref(fig:gaussianblob)(a) e sua representação 2D na figura \@ref(fig:gaussianblob)(b), nela temos um conjunto de pixels com valores bem próximos, que caracterizam um blob.

(ref:gaussianblob) Função gaussiana em 3D e 2D.

```{r gaussianblob, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:gaussianblob)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/gaussian_blob.jpg'))
```

Apesar do exemplo, a detecção de blobs não se restringe a elementos circulares, mas a qualquer conjunto de pixels.

### LoG
Esse método utiliza o do Laplaciano do Gaussiano, que já foi apresentado anteriormente, mas que em resumo é o cálculo de derivadas segunda em uma imagem que foi anteriormente convolucionada com um filtro gaussiano, isso irá gerar fortes respostas positivas em blobs escuros e negativas em blobs escuros nos blobs de tamanho $\sqrt{2\sigma}$. Como existe uma relação entre a respostas e o tamanho do desvio padrão, é necessário realizar a operação com uma gama de valores para o sigma, e assim detectar blobs de diferentes tamanhos. 

(ref:nasahubbledeep) Imagem de Campo Ultraprofundo do Hubble. [@img:hubbledeep]

```{r nasahubbledeep, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:nasahubbledeep)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/nasa_hubble_deep.jpg'))
```

Como podemos ver na figura \@ref(fig:gaussianblob) com diferentes valores de sigma conseguimos detectar objetos de variados tamanhos, como exemplo na figura \@ref(fig:logsigmas)(a) detectamos as estrelas da figura \@ref(fig:nasahubbledeep) que apresentam uma menor resposta ao filtro laplaciano.

(ref:logsigmas) Laplaciano do Gaussiano com diferentes valores de sigma.

```{r logsigmas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:logsigmas)', fig.align='center', out.width='100%'}
knitr::include_graphics(rep('imagens/06-segmentacao/log_sigmas.jpg'))
```

Na figura \@ref(fig:loghubble) temos o resultado da detecção dos blobs utilizando LoG. Note que nem todas as estrelas foram detectadas, isso se deve ao fato do uso de um valor de threshold, onde definimos que queremos as detecções acima de determinado limiar. Na figura \@ref(fig:loghubblebaixo) podemos ver o resultado utilizando um valor de limiar menor, onde muito mais objetos foram localizados.

(ref:loghubble) Resultado da detecção de blobs com LoG.

```{r loghubble, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:loghubble)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/log_hubble.jpg'))
```

(ref:loghubblebaixo) Resultado da detecção de blobs com LoG com um threshold menor.

```{r loghubblebaixo, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:loghubblebaixo)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/log_hubble_baixo_threshold.jpg'))
```

### DoG
Esse método é basicamente o mesmo do anterior, mas possui uma certa vantagem, que é o fato de ele ser mais eficiente. Como também já foi mencionado no tópico na seção anterior é possível aproximar o Laplaciano do Gaussiano através da Diferença do Gaussiano(DoG), ou seja, primeiramente se realiza a filtragem gaussiano com dois sigmas diferentes e se faz a subtração entre os dois. Realizamos esse processo para diferentes pares de valores, obtendo assim o mesmo espaço de escala construído com o processo do LoG. Na figura \@ref(fig:doghubble) temos um exemplo de detecção por DoG.

(ref:doghubble) Resultado da detecção de blobs com DoG.

```{r doghubble, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:doghubble)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/dog_hubble.jpg'))
```

### DoH
Uma matriz Hessiana é uma matriz que contém as derivadas de uma função. No nosso caso, utilizamos a Hessiana de ordem 2, pois estamos trabalhando com imagens, que possuem duas dimensões. Ela pode ser representada da seguinte maneira:

$$H[f(x_1, x_2, \dots,x_n)]=
\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2}\\ 
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2}
\end{bmatrix}$$

A matriz Hessiana tem muita utilidade pois com ela podemos descrever a curvatura em um ponto da função multivariável, o que no nosso caso pode ajudar a detectar os blobs, já que eles são aglomerados de pixels e devem estar separados do restante da imagem, ou seja, um aglomerado claro em um fundo escuro ou o contrário, e isso irá fazer com que sua função tenha uma mudança de sinal que pode ser detectada utilizando-se as informações da matriz. Além disso, como dito por Herbert Bay et al.[@bay2006surf] os detectores baseados na Hessiana são mais estáveis e repetíveis(tem a mesma resposta para a mesma imagem com diferentes ângulos, iluminações etc.).

Um dos principais algoritmos que fazem uso dessa matriz se chama Speeded Up Robust Features (SURF)[@bay2006surf], esse método faz uso de várias técnicas que o tornam muito rápido, como seu próprio nome sugere. Uma dessas técnicas é o cálculo da integral da imagem, realizado a partir da soma de todos os pixels de uma área retangular a partir do x atual, sendo que este varia enquanto se é andado pela imagem. 

(ref:imageIntegral) Integral de uma imagem. [@Cen2016StudyOV]

```{r imageIntegral, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imageIntegral)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imageIntegral.png'))
```

Como pode ser visto na figura, a integral de uma imagem contém a soma das regiões, por exemplo, a primeira posição contém a soma de somente uma célula, no caso 1, a segunda tem a soma de duas células,  na primeira linha estamos basicamente somando as células de uma só linha, na segunda começamos a formar regiões retangulares, por exemplo, na segunda linha e terceira coluna temos o valor 6, resultante da soma das seis células da primeira linha com a segunda. Com a integral podemos calcular a área de qualquer região com apenas quatro operações, da seguinte forma:
$$soma = D+A-B-C$$

Onde {A,B,C,D} forma uma região. Como exemplo, caso queiramos calcular a área na região quadrada 2x2 na direita inferior utilizados:
$$soma = 9 + 1 - 3 - 3 = 4$$

Isso nos ajuda na aplicação de box filters, já que precisaríamos da soma de determinadas áreas, e com isso aumentamos a velocidade do método.
Sendo $X=(x,y)$ um ponto em uma imagem, sua matriz Hessiana em $X$ a uma escala  é dada por:

$$H(X,\sigma)=\begin{bmatrix}
L_{xx}(X, \sigma) & L_{xy}(X, \sigma)\\ 
L_{xy}(X, \sigma) & L_{yy}(X, \sigma)
\end{bmatrix}$$

Onde $L_{xx}(X, \sigma)$ é a convolução da imagem no ponto X com a derivada de segunda ordem gaussiana $\frac{\partial^2g(\sigma)}{\partial x^²}$ e assim por diante[@bay2006surf]. Aqui entra em cena mais um elemento para melhorar a velocidade do algoritmo, Bay, Herbert et al. utilizam box filters para aproximar o filtro gaussiano. Como podemos ver na figura, onde os dois primeiros filtros são os derivativos gaussianos discretizados e os dois últimos são os aproximados a partir de box filters.

(ref:discretizadogaussiano) Filtro gaussiano discretizado e aproximado na direção $y$ e $xy$. [@bay2006surf]

```{r discretizadogaussiano, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:discretizadogaussiano)', fig.align='center', out.width='85%'}
knitr::include_graphics(rep('imagens/06-segmentacao/discretizadogaussiano.png'))
```

Chamamos as derivadas realizadas na imagem de $D_{xx}$, $D_{yy}$, $D_{xy}$. Essas derivadas não são realizadas com somente um valor de $\sigma$, mas como os detectores anteriores usam uma sequência de valores para assim criar um espaço de escalas e conseguir detectar blobs de diferentes tamanhos. Assim, a determinante da Hessiana é dado por:

$$det(H_{\text{aprox}}) = D_{xx}D_{yy}-(0.9D_{xy})^2$$

Sendo que o valor $0.9$ é um peso introduzido pelos autores Bay, Hebert et al. para corrigir as respostas quando utilizamos várias escalas de sigma e obter uma invariância escalar. Na figura temos o resultado de uma detecção de blobs realizada pela Determinante do Hessiano.

(ref:dohhubble) Resultado da detecção de blobs com DoH. 

```{r dohhubble, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:dohhubble)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/doh_hubble.jpg'))
```

## Limiarização
"a seção anterior, as regiões eram identificadas achando primeiro os segmentos de borda e, em seguida, tentando-se conectá-las com as fronteiras. Nesta seção, discutem-se as técnicas de divisão de imagens diretamente em regiões com base nos valores de intensidade e/ou as propriedades desses valores" [@gonzalez2010, p. 486].

"Em virtude de suas propriedades intuitivas, simplicidade de implementação e velocidade computacional, a limiarização de imagens tem uma posição central nas aplicações de segmentação de imagem" [@gonzalez2010, p. 486].

É importante salientar que a chance de sucesso da limiarização de intensidade é proporcional à largura e a profundidade do(s) vale(s) que separam os modos (ou classes) do histograma. E os principais fatores que afetam as propriedades do(s) vale(s) são [@gonzalez2010, p. 487]:

- A separação entre picos: quanto mais distantes forem os picos entre si, melhores as possibilidades de separação da imagem

- Índice de ruído da imagem: os modos ampliam com o aumento do ruído

- O tamanho relativo dos objetos e do fundo

- A uniformidade da fonte de iluminação

- A uniformidade da reflexão da imagem

Suponha que os histogramas de intensidade de uma imagem composta por objetos claros sobre um fundo escuro, conforme Figura \@ref(fig:histograma4didatica) (a), de tal forma que os *pixels* do objeto e do fundo tenham valores de intensidade agrupados em dois modos ou dois grupos dominantes (Gonzalez; Woods, 2010, p. 486); a idéia é selecionar um limiar $T$ que separa estes modos. E caso tenha três modos, usa-se dois limiares, conforme Figura \@ref(fig:histograma4didatica) (b). Em outras palavras, a segmentação da imagem da Figura \@ref(fig:histograma4didatica) (a) é dada por $g(x,y)$^[se $f(x,y) \leq T$, significa que se desconsida^ o endereço daquele *píxel*]:

$$g(x,y) =
\begin{cases}
1,\ se f(x,y) > T \\
0,\ se f(x,y) \leq T
\end{cases}$$

(ref:histograma4didatica) Histogramas de intensidade que podem ser divididos por um limiar único, (a), e limiares duplos, (b).  [@gonzalez2010, p. 486]

```{r histograma4didatica, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:histograma4didatica)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/histograma4didatica.png'))
```
  
Quando $T$ é uma constante aplicável em uma imagem inteira, o processo é conhecido como limiarização global. Caso $T$ mude ao longo da imagem, usamos o termo limiarização variável. E quando $T$ denotar uma limiarização variável na qual o valor $T$ em qualquer ponto $(x,y)$ em uma imagem depende das propriedades de sua vizinhança (por exemplo, a intensidade média dos *pixels* da vizinhança), o chamamos de limiarização local ou regional^[O uso desses termos não é universal e é provável vê-los sendo utilizados indiferentemente na literatura de processamento de imagem.] [@gonzalez2010, p. 486].  

Os problemas de segmentação que exigem mais do que dois limiares são difíceis (muitas vezes impossíveis) de resolver e os melhores resultados, geralmente, são obtidos por meio de métodos como a limiarização variável ou aumento da região, como discutido [@gonzalez2010, p. 486].


- **O papel do ruído da limiarização**

O ruído de uma imagem é capaz de fazer com que fique difícil achar um limiar ideal para segmentar a imagem sem processamentos adicionais, pois o(s) vale(s) da imagem podem desaparecer [@gonzalez2010. 487]. 

Observe que conforme os exemplos da Figura \@ref(fig:imagemRuido) e seus respectivos histogramas, o aumento no desvio padrão nos níveis de intensidade do ruído gaussiano faz com que o vale que separava os dois modos desapareça, tornando difícil a segmentação do fundo e do objeto.

(ref:imagemRuido) (a) Imagem de 8 bits livre de ruído, típica de Computação Gráfica. (b) Imagem com ruído gaussiano aditivo de média 0 e desvio padrão de 10 níveis de intensidade. (c) Imagem com ruído gaussiano aditivo de média 0 e desvio padrão de 50 níveis de intensidade. (d) a (f) Histogramas correspondentes [@gonzalez2010, p. 487].

```{r imagemRuido, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemRuido)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemRuido.png'))
```

- **O papel da iluminação e refletância**

O problema da iluminação é quando não é possível ter uma incidência uniforme da luz, causando um sombreamento. O mesmo efeito acontece quando o problema não é na iluminação, mas nas características da superfície do objeto; pois a iluminação e refletância produzem o mesmo problema. Note que, pela Figura \@ref(fig:imagemRefletancia), o histograma deixou de ser bimodal. Logo para segmentar imagens com problemas de iluminação e refletância não é simples

(ref:imagemRefletancia) (a) Imagem ruidosa. (b) Rampa de intensidade no intervalo [0.2, 0.6]. (c) Produto de (a) e (b). (d) a (f) Histogramas correspondentes [@gonzalez2010, p. 488].

```{r imagemRefletancia, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemRefletancia)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemRefletancia.png'))
```

E como solução há três abordagens básicas. Corrigir diretamente o padrão de sombreamento através de uma multiplicação com o comportamento inverso do sombreamento. Por exemplo, a iluminação não uniforme, porém fixa, pode ser corrigida multiplicando a imagem pelo inverso do padrão de iluminação, que pode ser obtida na aquisição de uma imagem de uma superfície plana de intensidade constante. Outra maneira é corrigí-lo por meio do processamento, por exemplo, utilizando a transformada *top-hat*. E a terceira abordagem é a de contornar isso utilizando a limiarização variável [@gonzalez2010, p. 488].



### Limiarização global simples
A limiarização global simples é um método iterativo básico e que não é o mais eficiente. Ele é um processo iterativo que denomina o limiar ideal como aquele que produz menor diferença entre as médias de intensidade dos modos, o de segmentação e o desprezado [@gonzalez2010, p. 488].

Ele consiste em:

1. Selecionar uma estimativa inicial para o limiar global, $T$.

2. Segmentar a imagem usando $T$. Isso dará origem a dois grupos de pixels: $G_{1}$ , composto por todos os pixels com valores de intensidade $> T$, e $G_{2}$, composto pelos pixels com valores $\leq T$.

3. Calcular os valores de intensidade média dos grupos, $m_{1}$ e $m_{2}$.

4. Calcular um novo valor de limiar: $T = \frac{m_{1}+m_{2}}{2}$.

5. Repita as etapas 2 a 4 até que a diferença entre os valores de $T$ das iterações sucessivas seja menor que o parâmetro predefinido $\Delta T$.

Exemplo de Limiarização Global:
A Figura \@ref(fig:imagemLimiarGlobalSimples) (a) consiste na imagem de uma digital com ruído. A Figura \@ref(fig:imagemLimiarGlobalSimples) (b) mostra que seu histograma possui um vale bem nítido e pela aplicação do algoritmo, usando $\Delta T = 0$ e iniciando $T$ igual a média de intensidade da imagem, após três iterações, encontramos o limiar $T = 125.4$. A Figura \@ref(fig:imagemLimiarGlobalSimples) (c) mostra o resultado obtido como $T = 125$. Como esperado, a partir da separação clara entre os modos no histograma, segmentação entre o objeto e o fundo foi bastante eficaz.

(ref:imagemLimiarGlobalSimples) (a) Impressão digital ruidosa. (b) Histograma. (c) Segmentação resultante usando um limiar global. [@gonzalez2010, p. 489].

```{r imagemLimiarGlobalSimples, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarGlobalSimples)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarGlobalSimples.png'))
```


### Limiarização pelo Método de Otsu

O método de Otsu é uma abordagem que relaciona as informações do histograma com conceitos estatísticos para produzir o chamado limiar ótimo, que é denotado por aquele que maximiza a variância entre classes ou minimiza a variância intraclasse [@gonzalez2010, p. 489]. Lembrando que classe é o mesmo que modos do histograma.

O primeiro passo é obter o histograma da imagem normalizado, isto é, no qual os pesos de cada intensidade são a probabilidade da ocorrência daquela intensidade na imagem. Segue a equação abaixo que representa um histograma normalizado, no qual $L$ representa a quantidade de níveis de intensidade e $p_{i}$, a probabilidade de ocorrência da intensidade $i$ na imagem [@gonzalez2010, p. 490]. 

$$\sum_{i=0}^{L-1}{p_{i} = 1,\ p_{i} \geq 0}$$

Para entender a equação cerne de Otsu, é preciso compreender algumas equações que a compõe. A probabilidade de ocorrência do modo 1 é dada pela equação abaixo [@gonzalez2010, p. 490]

$$P_{1}(k) = \sum_{i=0}^{k}{p_{i}}$$
E o valor da intensidade média dos *pixels* da classe 1, $C_{1}$, para dado limiar $k$ pode ser calculado pela equação abaixo [@gonzalez2010, p. 490]

$$\begin{split}
m_{1}(k) & = \sum_{i=0}^{k}{iP(i/C_{1})}\\
& = \sum_{i=0}^{k}{iP(C_{1}/i)P(i)/P(C_{i})}\\
& = \frac{1}{P_{1}(k)}\sum_{i=0}^{k}{ip_{i}}\\
\end{split}$$
E a média acumulada (intensidade média) até o nível $k$ ou da classe $C_{1}$ é dada por [@gonzalez2010, p. 490]

$$m(k) = \sum_{i=0}^{k}{ip_{i}}$$

Entendidas as equações anteriores, chegamos a equação cerne, que denota a variância entre classes.

$$\sigma_B^2(k) = \frac{[m_GP_{1}(k) - m(k)]^{2}}{P_1(k)[1 - P_1(k)]}$$
Então, o limiar ótimo é o valor que maximiza a variância entre classes, denominado $k^*$ [@gonzalez2010, p. 491], representado na equação abaixo. E conforme informado anteriormente, esse resultado é o mesmo que minimiza a variância dentro das classes; isso se deve a uma propriedade estatística que relaciona a variância global de intensidade da imagem, a variância interclasse e a variância intraclasse.

$$\sigma_B^2(k^*) = \max_{0 \leq k \leq L-1} \sigma_B^2(k)$$
Se o máximo existir para mais de um valor de $k$, é habitual calcular a média dos valores de $k$ [@gonzalez2010, p. 491].

Uma métrica adimensional pode ser usada para obter uma estimativa quantitativa da separabilidade das classes, o que dá uma idéia da facilidade e do resultado da segmentação.

$$\eta = \frac{\sigma_B^2(k^*)}{\sigma_G^2}$$
Tendo o limiar ótimo, $k^*$, segmentamos a imagem como já visto.

Para o cálculo da métrica adimensional, é preciso conhecer a variância global das intensidades da imagem que pode ser obtida pela seguinte equação:
$$\sigma_G^2 = \sum_{i=0}^{L-1}{(i - m_G)}^2p_i$$
Resumo do algoritmo de Otsu [@gonzalez2010, p. 492]:

1. Calcular o histograma normalizado da imagem de entrada. Designar os componentes do histograma como $p_i, i = 0, 1, 2, ..., L-1$.
2. Calcular as somas acumuladas, $P_1(k)$, para $k = 0, 1, 2, ..., L-1$.
3. Calcular as médias acumuladas $m(k)$, para $k = 0, 1, 2, ..., L-1$.
4. Calcular a intensidade média global, $m_G$.
5. Calcular a variância entre classes, $\sigma_B^2(k)$, para $k = 0, 1, 2, ..., L-1$.
6. Obter o limiar ideal de Otsu, $k^*$, caso haja mais de um, faz-se a média dos valores.
7. Obter a medida de separabilidade, $\eta^*$, a fim de estimar a qualidade da segmentação.

A Figura \@ref(fig:imagemOtsu) (a) mostra uma imagem de microscópio ótico de células polimerosomas e a Figura \@ref(fig:imagemOtsu) (b), seu histograma. O objetivo deste exemplo é segmentar as moléculas do fundo. A Figura \@ref(fig:imagemOtsu) (c) é o resultado pela limiarização global simples. Como o histograma não tem vales distintos e a diferença de intensidade entre o fundo e os objetos é pequena, o algoritmo não conseguiu alcançar a segmentação desejada. A Figura \@ref(fig:imagemOtsu) (d) mostra o resultado obtido pelo método de Otsu. Esse resultado, obviamente, é superior ao da Figura \@ref(fig:imagemOtsu) (c). O valor do limiar calculado pelo algoritmo simples foi o de 169, enquanto o limiar calculado pelo método de Otsu era  o de 181, que está mais próximo das áreas mais claras na imagem que define as células. A medida de separabilidade \eta foi 0.467.

(ref:imagemOtsu) (a) Imagem original. (b) Histograma (os picos elevados foram cortados para realçar os detalhes nos valores mais baixos). (c) Resultado da segmentação pela limiarização global simples. (d) Resultado da segmentação pelo método de Otsu. [@gonzalez2010, p. 492].

```{r imagemOtsu, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemOtsu)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemOtsu.png'))
```


### Uso de suavização para limiarização
O objetivo da suavização é tentar separar os histogramas de imagens ruidosas, que tendem a ser unimodais, em modos com vales mais profundos; pois, quanto mais profundo o vale, melhor será a segmentação da imagem. 

Atente-se ao tipo de média e ao tamanho do *kernel*, aconselha-se o filtro gaussiano, pois ele minimiza o borramento de fronteira, e suaviza o ruído ainda que de maneira mais branda do que um filtro de média.

A Figura \@ref(fig:imagemSuavizacaoLimiarizacao) (a) mostra uma imagem ruidosa, a \@ref(fig:imagemSuavizacaoLimiarizacao) (b) mostra seu histograma, a Figura \@ref(fig:imagemSuavizacaoLimiarizacao) (c) mostra o resultado do método de Otsu. Já a Figura \@ref(fig:imagemSuavizacaoLimiarizacao) (d) mostra a imagem de (a) suavizada usando uma máscara de média de tamanho 5x5 e a Figura \@ref(fig:imagemSuavizacaoLimiarizacao) (e) é seu histograma e a Figura \@ref(fig:imagemSuavizacaoLimiarizacao) (f) é resultado da limiarização pelo método de Otsu.

(ref:imagemSuavizacaoLimiarizacao) Exemplo de suavização antes da aplicação do método de Otsu  [@gonzalez2010, p. 493].

```{r imagemSuavizacaoLimiarizacao, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemSuavizacaoLimiarizacao)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemSuavizacaoLimiarizacao.png'))
```


Apesar do filtro de média poder nos ajudar, nem sempre será capaz disso. A Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) (a) mostra uma imagem ruidosa e a \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) (b) mostra o seu histograma, observe que o pontinho branco parece nem estar presente no histograma. E após aplicado o método de Otsu, a \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) (c), observe que não foi obtida a segmentação desejada. Então, tentou-se um filtro de média 5x5, que reduz o ruído, Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) (d). O resultado no histograma foi a redução do espalhamento do histograma, Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) (e), mas a distribuição ainda é unimodal, resultando em falha na segmentação, o que é visto na Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) (f).

(ref:ImagemSuavizacaoLimiarizacaoProblem) Exemplo de insucesso na segmentação por Otsu, mesmo com prévia suavização.

```{r ImagemSuavizacaoLimiarizacaoProblem, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:ImagemSuavizacaoLimiarizacaoProblem)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/ImagemSuavizacaoLimiarizacaoProblem.png'))
```

Portanto, note que, se a região que deseja segmentar for muito pequena em relação ao background e houver ruído, o que pode surgir na captura da imagem, a chance de não dar certo pelos métodos vistos é grande; pois como os métodos que até agora vimos operam apenas no histograma da imagem, sem uso de maiores recursos. Como visto, imagens com essa característica, um mínimo ruído persiste e nem foi obtido um vale considerável entre as duas regiões. Isso pode ser atribuído ao fato de que a região é tão pequena que sua contribuição para o histograma é insignificante em comparação à intensidade da propagação causada pelo ruído [@gonzalez2010, p. 493]. A solução para isso é o uso de máscaras de borda, que será detalhado a seguir. 

### Uso de bordas para limiarização
Em uma imagem com ruído na qual a região a ser segmentada é muito pequena, é como se não houvesse aquela região e houvesse apenas o *background*. Isso é observado na aparência unimodal do histograma.

Portanto, fica difícil estimar um limiar ideal pelos algoritmos supracitados. E como visto anteriormente, é preciso uma aparência bimodal para uma boa segmentação, então, precisamos de um histograma equilibrado; para isso, tomamos o histograma das bordas mais destacadas da imagem. Isso pode ser resumido em gerar uma máscara de gradiente ou laplaciano da imagem, limiarizá-la com um valor alto e usar como máscara para imagem original e prosseguir com o processo de segmentação do objeto a partir dessa amostra, pois, dessa forma, é gerado um histograma simétrico e com um vale destacado, porque, com a máscara de borda, há probabilidade de um píxel estar no *background* ou *foreground* tende a ser equilibrada [@gonzalez2010, p. 494]. 

O que se espera com os tipos de máscaras de borda, conforme visto no estudo detecção de bordas, é que a de gradiente produzirá bordas mais grossas e menor detecção aos ruídos da imagem, e a de laplace, bordas mais finas e maior detecção de ruídos, além de apresentar melhor custo computacional. Entretanto, é possível modificar este algoritmo para que tanto a magnitude do gradiente quanto o valor absoluto das imagens laplacianas sejam utilizadas; nesse caso, poderíamos especificar um limiar para cada imagem e formar a lógica OU dos dois resultados para obter a imagem marcadora, essa abordagem é útil quando se deseja ter mais controle sobre os pontos que foram considerados como sendo pontos válidos de borda [@gonzalez2010, p. 494].

Resumo das etapas de segmentação pela identificação de bordas do objeto [@gonzalez2010, p. 494]:

1. Calcular uma imagem de borda da imagem capturada, $f(x,y)$, ora como a magnitude do gradiente, ora como o valor absoluto do laplaciano, usando qualquer um dos métodos.

2. Especificar um valor de limiar, $T$.

3. Limiarizar a imagem a partir da Etapa 1, utilizando o limiar estabelecido na Etapa 2 para produzir uma imagem binária, $g_{T}(x,y)$. Esta imagem é usada como uma imagem de máscara na etapa seguinte para selecionar os pixels de $f(x,y)$ que correspondem aos pixels “fortes” da borda.

4. Calcular um histograma utilizando apenas os pixels de $f(x,y)$, que correspondem aos endereços de pixel avaliados com o número 1 em $g_{T}(x,y)$.

5. Use o histograma da Etapa 4 para segmentar $f(x,y)$ globalmente, utilizando, por exemplo, o método de Otsu.

A Figura \@ref(fig:imagemLimiarizGradiente) (a) e (b) mostram as mesmas imagens da Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) e seu histograma. Vimos que essa imagem não adianta ser suavizada. Entretanto, usamos a estratégia de máscara de borda que obteve um ótimo resultado. A Figura \@ref(fig:imagemLimiarizGradiente) (c) mostra o gradiente já limiarizado, A Figura \@ref(fig:imagemLimiarizGradiente) (d) e (e) mostra a máscara multiplicada a imagem original, que tem um histograma mais relevante à segmentação. E a Figura \@ref(fig:imagemLimiarizGradiente) (f) mostra o resultado da segmentação pelo novo histograma, \@ref(fig:imagemLimiarizGradiente) (e), através do Método de Otsu. O limiar foi de $134$, que fica aproximadamente a meio caminho entre os picos no histograma.

(ref:imagemLimiarizGradiente) Exemplo de limiarização por meio de máscara de borda de gradiente.

```{r imagemLimiarizGradiente, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizGradiente)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizGradiente.png'))
```



Já a Figura \@ref(fig:imagemLimiarizLaplace) (a) e (b) mostra uma imagem de 8 bits de células de levedura e seu histograma. A tentativa em detectar em segmentar os pontos claros pelo método de Otsu sem prévia etapa não foi sucedida, embora o método seja capaz de isolar algumas das regiões das células muitas da regiões segmentadas à direita não estão separadas. O limiar calculado foi de $42$ e a medida de separabilidade foi de $0.636$.  
A Figura \@ref(fig:imagemLimiarizLaplace) (d) mostra a imagem $g_T(x,y)$ obtida pelo cálculo do valor absoluto da imagem laplaciana e a limiarização com $T$ definido a $115$ em uma escala de intensidade no intervalo $[0, 255]$. Este valor de $T$ corresponde aproximadamente ao percentil $99.5$ dos valores da imagem laplaciana absoluta; assim, a limiarização a este nível deve resultar em um conjunto de *pixels* reduzido, como mostra esta Figura. A Figura \@ref(fig:imagemLimiarizLaplace) (e) é o histograma dos *pixels* diferentes a zero no produto de (a) e (d). Finalmente a Figura \@ref(fig:imagemLimiarizLaplace) (f) mostra o resultado da segmentação global da imagem original utilizando o método de Otsu baseado no histograma da Figura \@ref(fig:imagemLimiarizLaplace) (e). Este resultado está de acordo com as localizações dos pontos claros na imagem. O limiar calculado pelo método de Otsu foi $115$ e a medida de separabilidade foi de $0.762$, sendo que ambos são superiores aos valores obtidos utilizando o histograma original [@gonzalez2010, p. 495].

(ref:imagemLimiarizLaplace) Exemplo de limiarização por meio de máscara de borda laplaciana.

```{r imagemLimiarizLaplace, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizLaplace)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizLaplace.png'))
```



### Limiares Múltiplos

A diferença entre os limiares múltiplos e o que vimos até agora é que se usa mais de um limiar para segmentar a imagem a fim de produzir uma melhor medida de separabilidade entre as classes, por conseguinte, melhor segmentação.
Entretanto, como as aplicações que requerem mais de dois limiares geralmente são resolvidas com mais do que apenas valores de intensidade. Ao invés disso, o caminho é usar descritores adicionais (por exemplo, cor) e o problema é moldado para reconhecimento de padrões, como explicado a seguir em Limiarização baseada em diversas variáveis [@gonzalez2010, p. 497].

No caso das classes $K, C_1, C_2, ..., C_K$, a variância entre classes se generaliza pela expressão
$$\sigma_{B}^{2} = \sum_{k=1}^K{P_k(m_k-m_G)^2}$$
na qual
$$P_k = \sum_{i\in C_k}{p_i}$$
$$m_k = \frac{1}{P_k} \sum_{i \in C_k}{ip_i} $$
As classes $K$ são separadas por $K-1$ limiares cujos valores, $k^*_1, k^*_2, ..., k^*_k-1$
$$
\sigma_{B}^{2}(k^*_1, k^*_2, ..., k^*_{K-1}) =
\max_{0<k_1<k_2<...k_{n-1}<L-1}{\sigma_{B}^{2}(k_1, k_2, ..., k_{K-1})}
$$

Como observado na equação anterior, o valor máximo é obtido testando todas as possibilidades de valores para cada limiar, mas lembre-se que não faz sentido assumir limiares para $0$ e $L-1$, pois são os extremos da faixa de intensidade.

Também pode ser feito a avaliação de sua medida de separabilidade. Como exemplo, tomemos um histograma com três classes [@gonzalez2010, p. 497]. 

$$\eta(k^*_1, k^*_2) = \frac{\sigma^2_{B}(k^*_1,k^*_2)}{\sigma^2_{G}}$$

A Figura \@ref(fig:imagemLimiarizacaoMult) (a) mostra a imagem de um *iceberg*. É notório que será possível dividí-la com dois limiares^[A limiarização com dois limiares às vezes é chamada histerese de limiarização.] a partir das predominâncias de três grupos de intensidade. Olhando no histograma, \@ref(fig:imagemLimiarizacaoMult) (b), pelos vales bem destacados também é observado isso. Encontra-se pelo método de Otsu dois limiares, $80$ e $177$, com uma excelente medida de separabilidade de $0.954$. Limiarizando a Figura \@ref(fig:imagemLimiarizacaoMult) (a) o resultado que se obtém é uma segmentação muito boa, Figura \@ref(fig:imagemLimiarizacaoMult) (c) [@gonzalez2010, p. 498].

(ref:imagemLimiarizacaoMult) (a) Imagem de um *iceberg*. (b) Histograma. (c) Imagem segmentada em três regiões usando os limiares duplos de Otsu.

```{r imagemLimiarizacaoMult, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizacaoMult)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizacaoMult.png'))
```

### Limiarização variável
Vimos perante seções anteriores, que fatores como ruído e iluminação são impecílios para uma boa segmentação. Também foi visto que suavização e informações das bordas podem ser usadas para resolver isto. No entanto, é frequente o caso que essas estratégias são ineficientes ou nem possíveis. Como solução para tal, usamos limiares variáveis.

### Particionamento da imagem
O particionamento da imagem consiste em fracionar a imagem em retângulos suficientemente pequenos de maneira que eles tenham iluminação e refletância uniformes e aplicar o método de Otsu em cada um deles. O sucesso do método é análogo ao da máscara de bordas, ele produz, para cada fração, histogramas simétricos com vales profundos [@gonzalez2010, p. 498].

A Figura \@ref(fig:imagemLimiarizacaoVariavel) (a) e (b) mostra uma imagem e seu histograma. Pelo seu histograma é plausível que não resultaria em uma boa segmentação, seja pelo método de Otsu, Figura \@ref(fig:imagemLimiarizacaoVariavel) (c) ou pelo método iterativo, Figura \@ref(fig:imagemLimiarizacaoVariavel) (d). Após fracionada a imagem, Figura \@ref(fig:imagemLimiarizacaoVariavel) (e), a segmentação por Otsu teve sucesso, Figura \@ref(fig:imagemLimiarizacaoVariavel) (f). [@gonzalez2010, p. 498]

(ref:imagemLimiarizacaoVariavel) Exemplo da técnica de particionamento da imagem.

```{r imagemLimiarizacaoVariavel, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizacaoVariavel)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizacaoVariavel.png'))
```


(ref:imagemHistoVari) Representa o histograma das subimagens da Figura \@ref(fig:imagemLimiarizacaoVariavel) (e).

```{r imagemHistoVari, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemHistoVari)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemHistoVari.png'))
```

### Limiarização variável baseada nas propriedades locais da imagem
É uma técnica em que se calcula um limiar para cada ponto, $(x,y)$, com base em uma ou mais propriedades calculadas em sua vizinhança. Apesar de parecer trabalhoso, os algoritmos e hardwares modernos permitem o processamento rápido da vizinhança, especialmente para as funções comuns, como as operações lógicas e aritméticas [@gonzalez2010, p. 499].
Utilizaremos como abordagem básica duas propriedades, $\sigma_{xy}(x,y)$ e $m_{xy}(x,y)$, já que indicam o grau de contraste e intensidade média na vizinhança. Seguem cálculos da limiarização usando apenas a intensidade do ponto, sendo $T_{xy}$, o limiar local. As equações seguintes são formas comuns de limiares variáveis locais [@gonzalez2010, p. 499]:

$$T_{xy} = a\sigma_{xy} + bm_{xy}$$
em que $a$ e $b$ são constantes não negativas, e

$$T_{xy} = a\sigma_{xy} + bm_{G}$$
, na qual $m_G$ é a média global da imagem.

Também pode ser usado predicados a fim de determinar o limiar, $T_{xy}$, de segmentação. No entanto, o preço dessa limiarização mais rebuscada é um aumento no custo computacional [@gonzalez2010, p. 499]. E a imagem $g_{xy}$, ficaria conforme um exemplo a seguir:

$$g(x,y) =
\begin{cases}
  1,\ se\ f(x,y) > a\sigma_{xy}\ \ E\ \ f(x,y) > bm_{xy}\\
  0,\ caso\ contrário
\end{cases}
$$


A Figura \@ref(fig:imagemLimiarizVariavel) (a) é a imagem de células de levedura da Figura anterior \@ref(fig:imagemLimiarizLaplace) (a). A Figura \@ref(fig:imagemLimiarizVariavel) (b) é um exemplo da segmentação da Figura \@ref(fig:imagemLimiarizVariavel) (a) com dois limiares. Entretanto, note que as células do canto superior direito foram segmentadas de forma unida. A Figura \@ref(fig:imagemLimiarizVariavel) (c) é a imagem dos desvios padrão locais da vizinhança de tamanho 3x3 de cada *píxel*. E foi escolhida a média global ao invés da local, pois geralmente produz melhores resultados quando o fundo é quase constante e todas as intensidades de objeto estão acima ou abaixo da intensidade do fundo. Os pesos $a=30$ e $b=1,5$ foram assumidos. E, por fim, foi limiarizada pelo predicado exemplificado na última equação e não pela intensidade de um ponto, Figura \@ref(fig:imagemLimiarizVariavel) (d). 

(ref:imagemLimiarizVariavel) Exemplo de limiarização variável baseada nas propriedades locais [@gonzalez2010, p. 500].

```{r imagemLimiarizVariavel, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizVariavel)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizVariavel.png'))
```


### Usando média de movimento
O método de médias móveis é usado geralmente quando os objetos de interesse são pequenos (ou finos) em relação ao tamanho da imagem, uma condição que as imagens de texto digitado ou manuscrito possuem [@gonzalez2010, p. 501]. "Essa aplicação é muito útil no processamento de documentos" [@gonzalez2010, p. 500]. O procedimento consiste em um *kernel* 1D que percorre a imagem linha por linha e calcula média móvel com base em um intervalo de um dado tamanho fixo. A regra inicial é usar um intervalo de tamanho 5 vezes maior que a largura média do objeto que deseja limiarizar [@gonzalez2010, p. 501].
Digamos que $z_{k+1}$ denota a intensidade do ponto encontrado na sequência de digitalização na Etapa $k+1$. A média móvel (intensidade média) com este novo ponto é dada por
$$\begin{split}
m(k+1) 
& = \frac{1}{n} \sum_{i = k+2-n}^{k+1}{z_i}\\
& = m(k) + \frac{1}{n}(z_{k+1} - z_{k-n})
\end{split}$$

na qual $n$ é o tamanho do intervalo ou número de *pixels* utilizados no cálculo da média e $m(1)=\frac{z1}{n}$. Este valor inicial não é rigorosamente correto porque a média de um único ponto é o valor do ponto em si. No entanto, o usamos para que cálculos especiais não sejam necessários quando é executada pela primeira vez. Já que a média móvel é calculada para cada ponto da imagem, a segmentação é baseada no limiar $T_{xy}=bm_{xy}$, em que $b$ é constante e $m_{xy}$ é a média móvel no ponto $(x,y)$ na imagem de entrada [@gonzalez2010, p. 500]. A diferença desse método ao explicado na seção anterior é que neste usasse um *kernel* 1D que avalia linha por linha a imagem.

Na Figura \@ref(fig:imagemMediaMovel1) (a) mostra uma imagem de texto escrito à mão sombreada por um padrão de intensidade. Esta forma de sombreamento de intensidade é típica de imagens obtidas com um flash fotográfico. A Figura \@ref(fig:imagemMediaMovel1) (b) é o resultado da segmentação pela limiarização global de Otsu. A Figura \@ref(fig:imagemMediaMovel1) (b) mostra uma segmentação bem sucedida com limiarização local usando médias móveis, usando $n=20$, já que a largura média do traço era de $4$ *pixels*, e $b=0.5$.

(ref:imagemMediaMovel1) Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de flash fotográfico. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. [@gonzalez2010, p. 501].

```{r imagemMediaMovel1, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemMediaMovel1)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemMediaMovel1.png'))
```


Já na Figura \@ref(fig:imagemMediaMovel2) (a) mostra uma imagem de texto escrito à mão corrompida por um sombreamento senoidal. Esta forma de sombreamento de intensidade é típica de quando o fornecimento de energia em um digitalizador de documentos não é apropriado. A Figura \@ref(fig:imagemMediaMovel2) (a) é a imagem original, a Figura \@ref(fig:imagemMediaMovel2) (b) é o resultado da limiarização por Otsu e a Figura \@ref(fig:imagemMediaMovel2) (c) é o resultado pela  média móvel. Os parâmetros utilizados foram o mesmo do anterior, sendo $n=20$ e $b=0.5$, o que mostra relativa robustez do método.

(ref:imagemMediaMovel2) Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de problemas em *scanner* em que o fornecimento de energia não é o apropriado. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. [@gonzalez2010, p. 502].

```{r imagemMediaMovel2, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemMediaMovel2)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemMediaMovel2.png'))
```


### Limiarização baseada em diversas variáveis
Até agora, falamos apenas da limiarização baseada em uma única variável: intensidade dos tons de cinza. Em alguns casos, um sensor pode disponibilizar mais de uma variável para identificar cada *pixel* em uma imagem e, assim, permitir uma limiarização multivariada.
Um exemplo notável é a imagem em cores, na qual os componentes são vermelho (R), verde (G) e azul (B). Neste caso, cada *“pixel”* é identificado por três
valores e pode ser representado como um vetor 3-D, $z = (z_1+z_2+z_3)^T$, cujos componentes são as cores RGB em um ponto. Estes pontos 3-D são frequentemente chamados de *voxels*, para denotar elementos volumétricos em oposição aos elementos de imagem [@gonzalez2010, p. 501].

Numa limiarização focada na intensidade de cinza, de apenas uma variável, avaliamos apenas a intensidade, um gráfico de duas variáveis (histograma convencional). A sua limiarização é simples. Já no R, G, B, gráfico tridimensional, avaliamos a distância dos píxels da imagem a um píxel de referência, e o limiar é representado pelo contorno de uma Figura(a) simétrica na qual **contém** os *píxels* segmentados e tem como seu centro o *píxel* de referência. Conforme demonstrado na Figura \@ref(fig:imagemLimiarizMultiv).

(ref:imagemLimiarizMultiv) Segmentação multivariada no RGB. Gráfico-3D [@gonzalez2010, p. 295].

```{r imagemLimiarizMultiv, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizMultiv)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizMultiv.png'))
```



Suponha que queiramos extrair de uma imagem colorida todas as regiões com uma faixa de cor específica: por exemplo, tons avermelhados da Figura \@ref(fig:imagemLimiarizMultiv2) (a). Vamos denotar a cor avermelhada média em que estamos interessados, a amostra é demarcada pelo retângulo de bordas claras em Figura \@ref(fig:imagemLimiarizMultiv2) (a). Uma forma de segmentar uma imagem colorida com base neste parâmetro é calcular uma medida de distância, $D(z, a)$, entre um ponto de cor arbitrária, $z$, e a cor média, $a$. Então, tem-se a segmentação, Figura \@ref(fig:imagemLimiarizMultiv2) (b):

$$ g=
\begin{cases}
  1,\ se\ D(z,a)\ <\ T\\
  0,\ caso\ contrário
\end{cases}
$$

(ref:imagemLimiarizMultiv2) Exemplo de segmentação multivariada no RGB. [@gonzalez2010, p. 295].

```{r imagemLimiarizMultiv2, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizMultiv2)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizMultiv2.png'))
```

Porém, esse cálculo de distância dos pontos ao centro em formato esférico é trabalhoso para o computador. Uma maneira mais eficiente é usar um delimitador cúbico. Nessa metodologia, o cubo é centralizado em $a$ e suas dimensões ao longo de cada um dos eixos de cor são escolhidas em proporção ao desvio padrão das amostras da imagem ao longo de cada um dos eixos (R, G e B).

Portanto, o procedimento da Figura \@ref(fig:imagemLimiarizMultiv2) (a) consistiu em calcular o vetor médio $a$ utilizando os pontos de cor contidos no retângulo. Em seguida, calculou-se o desvio padrão dos componentes vermelho, verde e azul dessas amostras. Um cubo foi centralizado em $a$, e as dimensões ao longo de cada um dos eixos RGB foram escolhidas como 1,25 multiplicado pelo desvio padrão ao longo dos eixos correspondentes. Por exemplo, no eixo $R$, vermelho, a dimensão do cubo é de $(a_R - 1,25\sigma_R)$ até $(a_R + 1,25\sigma_R)$, no qual $a_R$ indica o valor do componente vermelho de $a$. E por fim, realizou-se a limiarização.
