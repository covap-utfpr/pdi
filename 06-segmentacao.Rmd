# Segmentação
A segmentação subdivide uma imagem para detecção de regiões ou objetos para uma determinada aplicação. Os principais métodos de segmentação utilizam a distribuição dos valores de intensidade, seja pelos padrões de similaridade, ou de descontinuidade [@gonzalez2010, p.454]. Nas técnicas de similaridade, as imagens são divididas em regiões semelhantes com base em um conjunto de características. Na segmentação por descontinuidade se consideram as mudanças abruptas de intensidades, caracterizadas por pontos isolados, linhas ou bordas na imagem.

## Detecção por descontinuidade
Bordas podem ser descritas como o limite ou a fronteira entre duas regiões onde ocorre uma variação brusca de intensidade em uma determinada direção. Uma linha pode ser vista como um segmento de borda em que a intensidade do fundo de cada lado da linha ou é muito superior, ou muito inferior à intensidade dos pixels da linha. Linhas com o comprimento e largura iguais a um pixel são tratados como pontos isolados [@gonzalez2010, p. 456].
Os métodos de detecção de bordas se baseiam no comportamento das derivadas, que podem detectar mudanças locais abruptas. Em uma função digital, as derivadas são aproximadas como termos de diferenças. Aproximações podem ser obtidas por meio de expansões em séries de Taylor, como demonstrado no livro “Processamento digital de imagens” [@gonzalez2010, p. 457], em que os resultados para a primeira e a segunda ordem no ponto $x$ pode ser obtido pelas Equações \@ref(eq:der1ordem) e \@ref(eq:der2ordem) respectivamente:

$$\frac{\delta f}{\delta x} = f'(x) = f(x+1) - f(x)
(\#eq:der1ordem)$$
$$\frac{\delta^2 f}{\delta x^2} = f''(x) = f(x+1) + f(x-1) - 2f(x)
(\#eq:der2ordem)$$

Para avaliar o comportamento das derivadas na transição de intensidades apresentamos na Figura \@ref(fig:imagemDerivadas) um perfil de intensidade horizontal (linha de digitalização) de uma imagem, juntamente com os resultados das duas últimas equações, \@ref(eq:der1ordem) e \@ref(eq:der2ordem), para alguns pontos. A imagem contém vários objetos sólidos, uma linha e um ponto interno de ruído, e a linha de  digitalização está próxima ao centro, incluindo o ponto isolado. A Figura \@ref(fig:imagemDerivadas)(c) mostra uma simplificação do perfil e como as derivadas de primeira e segunda ordem se comportam quando encontram um ponto isolado, uma linha e as bordas dos objetos.

Com base nos resultados das Equações \@ref(eq:der1ordem) e \@ref(eq:der2ordem), na Figura \@ref(fig:imagemDerivadas), observa-se que atendem as propriedades das derivadas. No início e ao longo da rampa de intensidade, a derivada de primeira ordem é diferente de zero, enquanto a segunda derivada é diferente de zero apenas no início e no final da rampa. Estes comportamentos indicam que as derivadas de primeira ordem produzem bordas grossas, e as de segunda ordem produzem bordas mais finas [@gonzalez2010, p.458].

(ref:imagemDerivadas) (a) Imagem. (b) Perfil de intensidade horizontal no centro da imagem. (c) Perfil simplificado e resultados das derivadas. [@gonzalez2010, p. 457].

```{r imagemDerivadas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemDerivadas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemDerivadas.png'))
```

No ponto de ruído, a resposta para a derivada de segunda ordem é mais forte do que para a primeira derivada. Derivadas de segunda ordem acentuam as respostas em mudanças bruscas, podendo melhorar pequenos detalhes [@gonzalez2010, p. 458]. Na linha com detalhes bem finos, a derivada de segunda ordem também tem maior magnitude. Nota-se nas bordas em rampa e nas bordas em degrau, que a segunda derivada tem sinais opostos (negativo para positivo ou vice-versa) conforme entra e sai da borda, o que caracteriza uma “borda dupla”. O sinal da segunda derivada também pode ser utilizado para determinar se uma transição em uma borda é de claro para escuro (segunda derivada negativa) ou de escuro para claro (segunda derivada positiva) [@gonzalez2010, p. 458].

### Detecção de pontos isolados

Considerando que as derivadas de segunda ordem têm uma resposta mais forte aos detalhes finos, o operador diferencial laplaciano \@ref(eq:opLaplaciano)

$$\nabla^2f(x,y) = \frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2}
(\#eq:opLaplaciano)$$
é ideal para a detecção de pontos [@gonzalez2010, p. 459].  As aproximações das derivadas de segunda ordem por termos de diferenças vistas podem ser estendidas para os dois termos do laplaciano \@ref(eq:termLapl1) e \@ref(eq:termLapl2)

$$\frac{\partial^2f}{\partial x^2} = f(x+1, y) + f(x-1, y) -2f(x,y)
(\#eq:termLapl1)$$
$$\frac{\partial^2f}{\partial y^2} = f(x, y+1) + f(x, y-1) -2f(x,y)
(\#eq:termLapl2)$$

Ao se relacionar essas três últimas equações, \@ref(eq:opLaplaciano), \@ref(eq:termLapl1) e \@ref(eq:termLapl2), obtém-se o laplaciano discreto \@ref(eq:opLaplacianoDisc):
$$\nabla^2f(x,y) = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) -4f(x,y)
(\#eq:opLaplacianoDisc)$$

Essa equação pode ser implementada utilizando a máscara de filtragem identificada na Figura \@ref(fig:mascarasLaplacianas)(a). Para incluir as direções diagonais na definição do laplaciano digital, acrescenta-se mais dois termos a esta equação, \@ref(eq:opLaplacianoDisc), um para cada direção diagonal. A Figura \@ref(fig:mascarasLaplacianas)(b) mostra a máscara de filtragem desta atualização que inclui as diagonais.

(ref:mascarasLaplacianas) (a) Máscara referente a equação laplaciana discreta. (b) Máscara que inclui as diagonais. [@gonzalez2010, p. 106]

```{r mascarasLaplacianas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:mascarasLaplacianas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/mascarasLaplacianas.png'))
```

A intensidade de um ponto isolado será muito diferente do seu entorno, portanto, ao aplicar a máscara, as únicas diferenças de intensidade relevantes serão as mais altas, maiores que um limite determinado ($T$) para serem consideradas pontos isolados [@gonzalez2010, p. 459]. Para detectar o ponto se utiliza a seguinte expressão \@ref(eq:sentencLaplac):

$$
g(x,y) = 
\begin{cases}
  1,\ se\ R(x,y) \geq T
  \\0,\ caso\ contrário
\end{cases}
(\#eq:sentencLaplac)
$$
em que $g$ é a imagem de saída, $T$ é um limiar não negativo e $R$ é o operador laplaciano. O ponto isolado será detectado no local $(x, y)$ em que a máscara está centrada se o módulo da resposta nesse ponto exceder o limiar estabelecido. Os pontos detectados são rotulados como 1 na imagem de saída, e os demais como 0, o que produz uma imagem binária. 

### Detecção de linhas
Semelhante à detecção de pontos isolados, as derivadas de segunda ordem geram respostas mais fortes na detecção de linhas, e produzem linhas mais finas do que as derivadas de primeira ordem [@gonzalez2010, p. 460]. Ao utilizar a máscara laplaciana da Figura \@ref(fig:mascarasLaplacianas) sobre a imagem de um componente em um circuito eletrônico (parte de uma conexão *wire-bond*), representado na Figura \@ref(fig:imagemDeteccaoLinhas)(a), obtém-se como resultado a Figura \@ref(fig:imagemDeteccaoLinhas)(b). Na seção ampliada da Figura \@ref(fig:imagemDeteccaoLinhas)(b), as linhas mais claras identificam os pontos positivos, o cinza escuro são os valores negativos, e o cinza médio representa zero. O efeito de linha dupla é evidente na região ampliada ao se utilizar a segunda derivada.

(ref:imagemDeteccaoLinhas) (a) Imagem do circuito. (b) Resultado do filtro laplaciano. (c) Valor absoluto do filtro laplaciano. (d) Valores positivos do filtro laplaciano. [@gonzalez2010, p. 460]

```{r imagemDeteccaoLinhas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemDeteccaoLinhas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemDeteccaoLinhas.png'))
```

Para destacar as linhas após a aplicação do filtro e remover os valores negativos pode ser utilizado o módulo dos valores calculados ou utilizar apenas os valores positivos do laplaciano [@gonzalez2010, p. 460], os resultados destas metodologias estão identificados na Figura \@ref(fig:imagemDeteccaoLinhas)(c) e (d), respectivamente. Nota-se que as linhas geradas pela abordagem do módulo são mais grossas, pois a espessura é o dobro se comparada com a outra metodologia. Nas duas situações, as linhas mais largas que o tamanho do filtro laplaciano são separadas por um “vale” de zeros. A detecção de linhas é ideal quando a espessura é menor que o detector, ao contrário se recomenda tratar o elemento como uma região e utilizar outros métodos [@gonzalez2010, p. 460].

O filtro laplaciano, na Figura \@ref(fig:mascarasLaplacianas), é isotrópico, assim, a sua resposta independe da direção [@gonzalez2010, p. 460]. No caso das linhas, pode ser interessante a detecção em apenas uma determinada direção, utilizando, por exemplo, uma das máscaras apresentadas na Figura \@ref(fig:mascarasDeteccaoLinhas). Para a primeira máscara da Figura \@ref(fig:mascarasDeteccaoLinhas), os sinais mais fortes ocorrem em linhas horizontais da imagem que passam pela linha do meio da máscara. O segundo filtro detecta melhor as linhas com $45°$ de inclinação. O terceiro filtro para linhas verticais. O quarto filtro para linhas com $-45º$ de inclinação. Vale destacar que estamos utilizando a convenção de que os eixos da imagem têm sua origem no canto superior esquerdo, com o eixo $x$ positivo apontando para baixo e o eixo $y$ positivo se estendendo à direita. Os ângulos das linhas são medidos em relação ao eixo $x$ positivo. 

(ref:mascarasDeteccaoLinhas) Máscaras para detecção de linhas em uma determinada direção [@gonzalez2010, p. 461].

```{r mascarasDeteccaoLinhas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:mascarasDeteccaoLinhas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/mascarasDeteccaoLinhas.png'))
```

Quando o objetivo é detectar todas as linhas da imagem em uma direção específica, aplica-se a máscara associada a essa direção e se define um limiar ($T$) para selecionar os sinais mais fortes. Para os quatro últimos filtros apresentados, as linhas de 1 pixel de espessura apresentam os maiores resultados [@gonzalez2010, p. 462].

## Detecção de Bordas
### Modelos de Bordas
Na Figura \@ref(fig:modelosBordas), estão os principais modelos de borda, que são classificados de acordo com os perfis de intensidade. A primeira borda,  borda em degrau, (a), apresenta uma transição entre dois níveis de intensidade e são consideradas ideais com uma distância de 1 pixel. Na prática, as bordas nas imagens digitais não apresentam uma transição tão bem definida, assim, modelos mais apropriados consideram um perfil de rampa como da Figura \@ref(fig:modelosBordas)(b) [@gonzalez2010, p. 462]. Quanto mais indefinida é a transição da borda, menor é a inclinação da rampa. Em vez de uma borda com 1 pixel de espessura, todos os pontos na rampa fazem parte da borda.
Além disso, na Figura \@ref(fig:modelosBordas), mostra os modelos de bordas com seus respectivos perfis de intensidade.

(ref:modelosBordas) (a) Borda degrau. (b) Borda rampa. (c) Borda telhado. [@gonzalez2010, p. 462]

```{r modelosBordas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:modelosBordas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/modelosBordas.png'))
```

No terceiro modelo de borda, Figura \@ref(fig:modelosBordas)(c), em forma de telhado ou *roof edge*, a base (largura) de uma borda é definida pela espessura e a nitidez da linha. Quando a base é igual 1 *pixel* de espessura, uma borda em forma de telhado é definida como uma linha [@gonzalez2010, p. 462]. 

As imagens da Figura \@ref(fig:derivadasImagensRuidosas) não apresentam ruídos, entretanto os modelos de detecção devem considerar que as bordas estejam desfocadas e com ruídos.  Na primeira coluna da Figura \@ref(fig:modelosBordas) estão quatro bordas de perfil rampa com diferentes níveis de ruídos, e abaixo de cada imagem, está o perfil horizontal de intensidade que passa pelo centro da imagem. A primeira imagem no canto esquerdo não apresenta ruído, e as outras três imagens da primeira coluna foram alteradas com ruído gaussiano aditivo com média zero e desvio padrão de $0.1$, $1.0$ e $10.0$  níveis de intensidade, respectivamente.

(ref:derivadasImagensRuidosas) Primeira coluna: imagens e perfis de intensidade de uma borda em declive corrompida pelo ruído gaussiano aleatório de desvio padrão $0.0$, $0.1$, $1.0$ e $10.0$ níveis de intensidade, respectivamente. Segunda coluna: imagens da primeira derivada. Terceira coluna: imagens da segunda derivada. [@gonzalez2010, p. 465]

```{r derivadasImagensRuidosas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:derivadasImagensRuidosas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/derivadasImagensRuidosas.png'))
```

Na segunda e terceira coluna estão identificados, respectivamente, a primeira e a segunda derivada dos perfis de intensidade da primeira coluna. A primeira derivada é utilizada para detectar bordas, pois identifica pontos de transição abrupta de intensidade na imagem.  Para o resultado da primeira derivada na primeira linha, os valores na rampa são positivos e, nas regiões de intensidade constante é igual a zero. As duas faixas pretas na imagem da parte superior da coluna central são os resultados iguais a zero da primeira derivada, e os valores constantes estão identificados como cinza claro.

Como as bordas são uma transição de uma região escura para uma região branca, a segunda derivada na terceira coluna é positiva no início da rampa e negativa no final. A linha que passa por estes dois resultados da derivada se intercepta com o eixo de intensidade zero, gerando o ponto de cruzamento por zero que é utilizado para localizar o centro de bordas espessas [@gonzalez2010, p. 464]. Nas regiões de intensidade constante, as derivadas de segunda ordem também são zero, e se apresentam na cor cinza claro nas imagens da terceira coluna. As linhas finas verticais brancas e pretas são os resultados positivos e negativos da segunda derivada.

Mesmo não sendo perceptível os ruídos nas imagens da segunda e terceira linha, eles apresentaram um impacto significativo nas derivadas, principalmente na derivada de segunda ordem que é mais sensível a eles. Quanto maior o ruído, mais difícil de se associar com os perfis das derivadas, dificultando a detecção de bordas. Este comportamento pode ser tratado com a suavização da imagem em uma etapa anterior a segmentação [@gonzalez2010, p. 464].

### Método do gradiente (Roberts, Prewitt, Sobel)
Na detecção de bordas, as derivadas de primeira ordem são calculadas utilizando a magnitude do gradiente, que é um vetor cuja a direção indica os pontos de maior variação de intensidade [@pedrini2008, p. 155]. A Figura \@ref(fig:vetorGradiente) indica que a direção do gradiente sempre será perpendicular à direção tangente da borda. Para uma função $f(x, y)$, o gradiente de $f$ nas coordenadas $(x, y)$ na forma matricial é expresso como a Equação \@ref(eq:gradMatriz)

$$\nabla f 
= \begin{bmatrix}
G_x
\\ G_y
\end{bmatrix}
= \begin{bmatrix}
\frac{\partial f}{\partial x}
\\ \frac{\partial f}{\partial y}
\end{bmatrix}
(\#eq:gradMatriz)$$

(ref:vetorGradiente) Vetor gradiente $\nabla f$ em uma borda. [@pedrini2008, p. 155]

```{r vetorGradiente, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:vetorGradiente)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/vetorGradiente.png'))
```

O módulo ou magnitude (tamanho) do vetor $\nabla f$ é dado como $M(x,y)$, Equação \@ref(eq:magnitEq).
$$M(x,y) = \sqrt{G^2_x + G^2_y}
(\#eq:magnitEq)$$

O módulo do gradiente é a maior taxa de variação de $f(x,y)$ na direção do vetor gradiente. Devido ao custo computacional, a magnitude do gradiente é aproximada pelo uso dos valores absolutos, Equação \@ref(eq:magnitEqAprox) [@pedrini2008, p. 155].
$$M(x,y) \simeq |G_x| + |G_y|
(\#eq:magnitEqAprox)$$

A direção do vetor gradiente é dada pela Equação \@ref(eq:angGradient), que retorna um ângulo
$$
\alpha(x,y) = 
tg^{-1}
\begin{bmatrix}
\frac{G_y}{G_x}
\end{bmatrix}
(\#eq:angGradient)$$

medido em relação ao eixo $x$. Da mesma forma que a magnitude $M(x, y)$, ou imagem gradiente, o ângulo $\alpha(x, y)$ também é uma imagem do mesmo tamanho que a original formado pela divisão da imagem $G_y$ por $G_x$ [@gonzalez2010, p. 466].

Para calcular as derivadas parciais $\partial f/ \partial x$ e $\partial f/ \partial y$ no caso de quantidades digitais,  é necessário utilizar aproximações discretas e, em seguida, determinar as máscaras de filtragem correspondentes.  Uma forma de aproximação é considerar a diferença entre os elementos da vizinhança para calcular a magnitude do gradiente [@pedrini2008, p. 157]. Ao se utilizar as diferenças cruzadas, como na seguinte Equação \@ref(eq:magDifCruz)

$$M(x,y) \simeq |f(x,y) - f(x+1, y+1)| + |f(x,y+1) - f(x+1, y)|
(\#eq:magDifCruz)$$
é o mesmo que aplicar os filtros de tamanho 2x2 da Figura \@ref(fig:operadorRoberts) e somar os resultados absolutos.

(ref:operadorRoberts) Operador de Roberts [@pedrini2008, p. 157].

```{r operadorRoberts, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:operadorRoberts)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/operadorRoberts.png'))
```

Estes operadores, conhecidos como operadores de Roberts, foram uma das primeiras tentativas de usar máscaras 2-D, entretanto não são tão úteis quanto as máscaras simétricas ao redor do ponto central, em que as menores são de tamanho 3×3 [@gonzalez2010, p. 467]. As aproximações mais simples para as derivadas parciais usando máscaras de tamanho 3×3 são dadas pela Equação \@ref(eq:aproxDerParciais)

$$ 
\begin{split}
M(x,y) &\simeq
|[f(x+1,y-1) + f(x+1,y) + f(x+1,y+1)]-\\
 &\ \ \ \ \ [f(x-1,y-1) + f(x-1,y) + f(x-1,y+1)]+\\
 &\ \ \ \ \ [f(x-1,y+1) + f(x,y+1) + f(x+1,y+1)]-\\
 &\ \ \ \ \ [f(x-1,y-1) + f(x,y-1) + f(x+1,y-1)]|
\end{split}
(\#eq:aproxDerParciais)$$

(ref:operadorPrewitt) Operador de Prewitt [@pedrini2008, p. 158].

```{r operadorPrewitt, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:operadorPrewitt)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/operadorPrewitt.png'))
```

A Equação anterior, \@ref(eq:gradMatriz), pode ser implementada aplicando as máscaras da Figura \@ref(fig:operadorPrewitt), que recebem o nome de operadores de Prewitt. Uma variação deste último método utiliza o valor $2$ como peso no centro do coeficiente [@pedrini2008, p. 158]

$$ 
\begin{split}
M(x,y) &\simeq
|[f(x+1,y-1) + 2f(x+1,y) + 2f(x+1,y+1)]-\\
 &\ \ \ \ \ [f(x-1,y-1) + 2f(x-1,y) + f(x-1,y+1)]+\\
 &\ \ \ \ \ [f(x-1,y+1) + 2f(x,y+1) + f(x+1,y+1)]-\\
 &\ \ \ \ \ [f(x-1,y-1) + 2f(x,y-1) + f(x+1,y-1)]|
\end{split}
(\#eq:aproxDerParciais2)$$

(ref:operadorSobel) Operador de Sobel [@pedrini2008, p. 158].

```{r operadorSobel, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:operadorSobel)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/operadorSobel.png'))
```

O resultado das equação pode ser obtido com a soma dos valores absolutos dos resultados das máscaras na Figura \@ref(fig:operadorSobel), chamadas de operadores de Sobel. Mesmo que as máscaras de Prewitt sejam mais simples de implementar do que as máscaras de Sobel, as de Sobel são mais utilizadas por melhor suavização, diminuindo os ruídos [@gonzalez2010, p. 468].

Ao calcular a magnitude como uma aproximação da soma dos valores absolutos dos componentes de gradiente $G_x$ e $G_y$, Equação \@ref(eq:magnitEqAprox), pode se perder a propriedade isotrópica dos filtros. No caso das máscaras de Sobel e de Prewitt, este problema não ocorre, pois dão resultados isotrópicos apenas para bordas verticais e horizontais, e que são independentes da Equação \@ref(eq:magnitEq) ou Equação \@ref(eq:magnitEqAprox) [@gonzalez2010, p. 468].

### Método de Marr-Hildreth
Nos métodos de detecção de bordas utilizando a derivada de segunda ordem se observa maior sensibilidade aos ruídos, assim, recomenda-se um pré-processamento de suavização. A técnica de detecção proposta por Marr e Hildreth (1980), por exemplo, combina a [filtragem Gaussiana](#filtro-gaussiano) com o operador Laplaciano (Figura \@ref(fig:mascarasLaplacianas)) [@pedrini2008, p. 163]. Após a suavização da imagem com o filtro gaussiano, as bordas são identificadas pelos pontos de cruzamento por zero da segunda derivada.

Um aspecto que torna a técnica interessante para imagens de diferentes escalas é que considera as características da borda e dos ruídos, empregando-se operadores de tamanho mais adequado para cada imagem [@gonzalez2010, p. 470]. Operadores de maior tamanho são recomendados para detectar bordas borradas, enquanto operadores menores detectam melhor detalhes finos com foco nítido. Como o laplaciano é isotrópico, respondendo de forma igual às variações nas diferentes direções, evita-se a utilização de várias máscaras [@gonzalez2010, p. 472]. 

O operador proposto por Marr e Hildreth é obtido pela convolução, Equação \@ref(eq:marHildreth)
$$g(x,y) = \nabla^2[G(x,y)*f(x,y)]
(\#eq:marHildreth)$$
em que $f(x,y)$ é a imagem, $\nabla^2$ é o operador laplaciano, ($\partial^2 f / \partial x^2 + \partial^2 f / \partial y^2$), e $G$ é a função gaussiana 2-D, \@ref(eq:funcGauss2-D):
$$G(x,y) = e^{-\frac{x^2 + y^2}{2\sigma^2}}
(\#eq:funcGauss2-D)$$
com desvio padrão $\sigma$. Em razão da linearidade das operações, a ordem da diferenciação e da convolução podem ser alteradas [@pedrini2008, p. 163], assim, após a diferenciação da expressão gaussiana, obtém-se  o Laplaciano da Gaussiana (LoG), Equação \@ref(eq:laplGauss):
$$\nabla^2G(x,y) = 
\begin{bmatrix}
\frac{x^2 + y^2 - \sigma^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2\sigma^2}}
\end{bmatrix}
(\#eq:laplGauss)$$

As máscaras podem ser geradas pela amostragem  da Equação \@ref(eq:laplGauss) com ajustes nos coeficientes para que a soma seja zero. Um exemplo de máscara 5x5 que atende ao Laplaciano da Gaussiana está na Figura \@ref(fig:laplacianoGaussiana)(d). O comportamento dessa máscara é próximo do efeito da função LoG na Figura \@ref(fig:laplacianoGaussiana)(a), em que o termo positivo e central é rodeado por uma região negativa cujo os valores aumentam ao se distanciar da origem, e uma região externa com zeros [@gonzalez2010, p. 472].

(ref:laplacianoGaussiana) (a) Gráfico 3-D do negativo de LoG. (b) Imagem do negativo de LoG. (c) Seção transversal de (a). (d) Aproximação de máscara 5x5 para LoG. [@gonzalez2010, p. 471]

```{r laplacianoGaussiana, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:laplacianoGaussiana)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/laplacianoGaussiana.png'))
```

Devido ao formato na Figura \@ref(fig:laplacianoGaussiana), a função LoG é conhecida como  operador de chapéu mexicano. Seu gráfico 3-D, sua imagem e sua seção transversal se referem ao negativo da função LoG. Na seção transversal (Figura \@ref(fig:laplacianoGaussiana)(c)), o cruzamento por zero do LoG ocorre em $x^2 + y^2 = 2 \sigma^2$ , definindo um círculo centrado na origem e de raio $2\sigma$.

Na prática, o filtro LoG é gerado pelas seguintes etapas [@gonzalez2010, p. 472]:

1. Define-se um filtro $n$×$n$ gaussiano a partir de amostragem com a Equação \@ref(eq:funcGauss2-D).  Lembrando da sugestão que o tamanho do filtro gaussiano, $n$, precisa ser o menor inteiro ímpar maior ou igual a $6\sigma$.

2. Após suavização da imagem com o filtro gaussiano, o resultado é processado pelo laplaciano, por exemplo, com uma máscara 3×3 da Figura \@ref(fig:mascarasLaplacianas).

3. Na imagem resultante da etapa anterior são encontrados os pontos de cruzamento por zero. Estes pontos podem ser identificados em um pixel, $p$, com base na sua vizinhança 3x3. No caso de $p$ ser um cruzamento por zero, pelo menos dois de seus vizinhos opostos devem apresentar sinais diferentes. Neste caso são realizados quatro testes:  esquerda/direita, acima/abaixo e com as duas diagonais. Quando se utiliza um limiar para identificar o cruzamento por zero, tanto os sinais dos vizinhos opostos devem ser diferentes quanto o valor absoluto da diferença numérica deve ultrapassar o limiar para que o ponto $p$ seja um cruzamento por zero.

O filtro LoG também pode ser aproximado com a convolução de uma máscara gerada a partir da diferença de duas funções gaussianas (DoG), Equação \@ref(eq:difGauss) [@gonzalez2010, p. 473]:
$$DoG(x,y) = \frac{1}{2\pi \sigma^2_1}  e^  {-\frac{x^2+y^2}{2\sigma^2_1}}
-
\frac{1}{2\pi \sigma^2_2}  e^  {-\frac{x^2+y^2}{2\sigma^2_2}}
(\#eq:difGauss)$$

com $\sigma_1 > \sigma_2$. Marr e Hildreth mostraram que para $\sigma_2/\sigma_1 = 1.6$ o operador tem maior aproximação com a função LoG [@gonzalez2010, p. 473]. Para que LoG e DoG tenham os mesmos cruzamentos por zero se sugere que se mantenha a seguinte relação para o valor de $\sigma$ em LoG, Equação \@ref(eq:relacaoCruzZero):
$$\sigma^2 = \frac{\sigma^2_1\sigma^2_2}{\sigma^2_1 - \sigma^2_2}
\ln 
\begin{bmatrix}
\frac{\sigma^2_1}{\sigma^2_2}
\end{bmatrix}
(\#eq:relacaoCruzZero)$$

Para estabelecer uma mesma escala de amplitude no resultado dos dois operadores, LoG e DoG, ocorre um ajuste para o mesmo valor na origem em ambas as funções [@gonzalez2010, p. 474].  

### Método de Canny
O algoritmo de Canny recebeu esse nome em alusão a John Canny, que o propôs em seu artigo, “A computational Approach to Edge Detection" [@canny1986computational], publicado em 1986. Sua formulação se baseava em três pontos principais:

- Uma baixa taxa de erro, ou seja, todas as bordas presentes na imagem devem ser encontradas e não deve haver respostas espúrias.
- O segundo critério diz que as bordas detectadas devem estar bem localizadas, em outras palavras, elas devem estar o mais próximo possível das bordas verdadeiras.
- O terceiro, e último, critério diz que se deve minimizar o número de máximos locais em torno da borda verdadeira para que não sejam encontrados múltiplos pixels de borda onde deve haver somente um.

Em seu trabalho, Canny buscou encontrar soluções ótimas, matematicamente, que obedecessem os três critérios. Apesar disso, é muito difícil, ou impossível, encontrar uma solução que satisfaça completamente os objetivos descritos [@gonzalez2010, p.474]. Todavia é possível utilizar uma aproximação por meio de otimização numérica com as bordas em degrau em um exemplo 1-D que contenham ruído branco gaussiano para mostrar que uma boa aproximação de um ótimo detector de bordas é a primeira derivada de uma gaussiana, Equação \@ref(eq:primeiraDerGauss) [@gonzalez2010, p.474]:

$$\frac{\mathrm{d} }{\mathrm{d} x}e^{\frac{-x^2}{2\sigma^2}} = \frac{-x}{\sigma^2}e^{\frac{-x^2}{2\sigma^2}}
(\#eq:primeiraDerGauss)$$

Canny demonstrou que a utilização dessa aproximação pode ser feita com uma taxa 20% inferior à solução numérica, o que a torna, praticamente, imperceptível para muitas das aplicações [@gonzalez2010, p.474].

A ideia anterior foi imaginada em um aspecto 1-D, precisamos expandir esse conceito para uma generalização 2-D. Uma borda de degrau pode ser caracterizada pela sua posição, orientação e possível magnitude. Aplicar um filtro Gaussiano em uma imagem e depois diferenciá-la forma um simples e efetivo operador direcional [@sonka2014, p.145]. Digamos, então, que $f(x,y)$ seja uma imagem e $G(x,y)$, a função gaussiana, Equação \@ref(eq:funcGauss2-DCanny):

$$G(x,y) = e^{-\frac{x^2+y^2}{2\sigma^2}}
(\#eq:funcGauss2-DCanny)$$

Temos como saída a imagem suavizada, $f_s$, Equação \@ref(eq:cannyGauss):

$$f_s(x,y)=G(x,y)*f(x,y)
(\#eq:cannyGauss)$$

E, após isso, realizamos o cálculo da magnitude, Equação \@ref(eq:magnitGradCanny), e a direção do gradiente, Equação \@ref(eq:dirGradCanny):

$$M(x,y) = \sqrt{g_x^2+g_y^2}
(\#eq:magnitGradCanny)$$
$$\alpha(x,y)= \tan^{-1}\left ( \frac{g_y}{g_x} \right )
(\#eq:dirGradCanny)$$

onde $g_x=\partial f_s/\partial x$ e $g_y=\partial f_s/\partial y$. Para o cálculo das derivadas parciais, podemos utilizar tanto Prewitt quanto Sobel. 

Como essa primeira etapa utiliza operadores que calculam as primeiras derivadas, isso produz bordas grossas, e o terceiro objetivo da proposta de Canny é ter bordas com único ponto, por isso o próximo passo é o de afinar as bordas encontradas. O método que usaremos para isso é chamado supressão dos não máximos. 

A etapa de não máximos tem como base a discretização das direções da normal da borda (vetor gradiente), ou seja, em uma região 3x3, temos 4 direções possíveis, como pode ser visto na Figura \@ref(fig:edgeorientation)(c); por exemplo, uma borda de $45º$, se ela estiver entre $+157.5º$ e $+112.5º$ ou $-67.5º$ e $-22.5º$.
Na Figura \@ref(fig:edgeorientation)(a), temos um exemplo de duas orientações que podem existir em uma borda horizontal. Na Figura \@ref(fig:edgeorientation)(b), podemos ver a normal de uma borda horizontal e o intervalo de valores onde a direção do vetor gradiente pode existir.

(ref:edgeorientation) Discretização das direções. (a) Borda horizontal. (b) Intervalo dos possíveis valor do ângulo normal da borda para uma borda horizontal. (c) Intervalo de valores do ângulo da normal para os diferentes tipos de borda. [@gonzalez2010, p. 475]

```{r edgeorientation, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:edgeorientation)', fig.align='center', out.width='70%'}
knitr::include_graphics(rep('imagens/06-segmentacao/edge_orientation.png'))
```

Se considerarmos $d_1$, $d_2$, $d_3$ e $d_4$ como as direções possíveis em uma área 3x3, podemos formular o seguinte esquema de supressão de não máximos em todos os pontos $(x,y)$ [@gonzalez2010, p.475]:

- Encontrar a direção $d_k$ que está mais perto de $\alpha (x,y)$.

- Se o valor de $M(x,y)$ for inferior a pelo menos um dos seus dois vizinhos ao longo de $d_k$, deixe $g_N(x,y)=0$ (supressão), senão deixe $g_N(x,y)=M(x,y)$, em que $g_N(x,y)$ é a imagem suprimida.

A última operação a ser realizada é a limiarização para se remover os pontos de falsas bordas. Aqui, usaremos a limiarização por histerese, que utiliza dois limiares, um baixo ($T_L$) e um alto ($T_H$), sendo que Canny sugeriu, em seu trabalho, que a razão entre o limiar alto e o baixo deve ser de 2:1 ou 3:1.

Podemos imaginar essa limiarização da seguinte forma, em que se cria duas imagens adicionais, \@ref(eq:imgLimiarAlto) e \@ref(eq:imgLimiarBaixo)

$$g_{NH}(x,y) = g_N(x,y)\geq T_H
(\#eq:imgLimiarAlto)$$

\begin{center}e\end{center} 

$$g_{NL}(x,y) = g_N(x,y)\geq T_L
(\#eq:imgLimiarBaixo)$$

Onde $g_{NH}(x,y)$ e $g_{NL}(x,y)$ são definidas inicialmente como $0$. 

Dessa forma, $g_{NH}(x,y)$ conterá os pixels que são maiores que o nosso limiar alto e $g_{NL}(x,y)$, os que estão acima do nosso limiar baixo, o que significa que $g_{NL}(x,y)$ contém os pixels que estão entre os dois limiares e os que estão acima do limiar alto. A próxima etapa é remover esses pixels redundantes entre  $g_{NL}$ e $g_{NH}$, \@ref(eq:remocRedundancia):
$$g_{NL}(x,y)=g_{NL}(x,y)-g_{NH}(x,y)
(\#eq:remocRedundancia)$$

Sem redundância, chama-se os pixels de $g_{NH}(x,y)$ de pixels fortes e, os de $g_{NL}(x,y)$, de fracos. Ao final dessa limiarização, todos os pixels fortes são classificados como borda válida, mas com falhas, que nos leva a outro processo:

1) Localizar o próximo pixel de borda, $p$, a ser revisado em $g_{NH}(x,y)$.
2) Classificar todos os pixels fracos de $g_{NL}(x,y)$ que tenham conexão como bordas válidas, por exemplo, os que tiverem conectividade-8.
3) Enquanto todos os pixels de $g_{NL}(x,y)$ não forem analisados, retorna-se ao passo 1, senão continuamos ao passo 4.
4) Zerar todos os pixels de $g_{NL}(x,y)$ que não são bordas válidas.

Ao final desses processos, teremos a imagem de saída do algoritmo de Canny. Como dito por [@gonzalez2010, p.476], o uso de duas imagens para $g_{NH}(x,y)$ e $g_{NL}(x,y)$ é uma boa maneira para se explicar o algoritmo de uma maneira simples, mas, na prática, isso pode ser feito diretamente na imagem $g_N(x,y)$.

Finalmente, sumarizando os passos do algoritmo, com um exemplo passo-a-passo:

1) Imagem original

(ref:original) Imagem original.

```{r original, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:original)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/original.jpg'))
```

2) Aplicação do filtro gaussiano para suavizar a imagem.

(ref:gaussian) Imagem filtrada com filtro gaussiano.

```{r gaussian, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:gaussian)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/gaussian.jpg'))
```

3) Cálculo da magnitude do gradiente e dos ângulos.

(ref:derivadas) (a) Sobel na direção vertical. (b) Sobel na direção horizontal. (c) Gradiente. (d) Ângulos. [@burger2009, p. 98]

```{r derivadas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:derivadas)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/derivadas.jpg'))
```

4) Aplicação da supressão não máximos para afinar as bordas.

(ref:supressao) Resultado da supressão não máxima.

```{r supressao, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:supressao)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/supressao.jpg'))
```

5) Usar limiarização por histerese.

(ref:threshold) Resultado da histerese.

```{r threshold, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:threshold)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/threshold.jpg'))
```

6) Resultado final, após a análise de conectividade para detectar e conectar as bordas.

(ref:canny) Resultado final da detecção de bordas de Canny.

```{r canny, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:canny)', fig.align='center', out.width='50%'}
knitr::include_graphics(rep('imagens/06-segmentacao/canny.jpg'))
```

## Transformada de Hough
A Transformada de Hough é uma técnica utilizada para detectar formas em imagens, sejam elas linhas, círculos ou elipses, apesar de ela ser muito utilizada e ter sido criada, principalmente, para detecção de linhas.

### Transformada de Hough para detecção de linhas
Para começar a entender essa transformada, imaginemos que temos um ponto $(x_i, y_i)$ no plano $xy$ e a equação da reta $y_i=ax_i+b$. É fato que pelo ponto $(x_i, y_i)$, passam infinitas retas. Podemos escrever a equação anterior em relação a $b$, ou seja, $b=-x_ia+y_i$, o que nos leva ao plano $ab$ (espaço de parâmetros) onde essa nova equação gerará uma única reta.

Imaginemos um outro ponto $(x_j, y_j)$ no plano $xy$, podemos também levá-lo ao plano $ab$ através da equação $b=-x_ja+y_j$. Como podemos ver na Figura \@ref(fig:planoxy)(b), as duas retas geradas no plano $ab$ se cruzam nas coordenadas $(a', b')$. O ponto de cruzamento representa a reta que cruza os dois pontos no plano $xy$, como podemos ver na mesma representação \@ref(fig:planoxy)(a). Na realidade, todos os pontos pertencentes a reta definida por esses dois pontos em $xy$, tem sua reta respectiva em $ab$ e todas elas se cruzam no ponto $(a', b')$, isso nos dá uma maneira de realizar a detecção de bordas, pois podemos imaginar essa reta no plano $xy$ como nossa borda, assim, para achá-la, basta localizar o ponto no espaço de parâmetros onde um grande número de retas se cruzam.

(ref:planoxy) Planos $xy$ e $ab$ [@gonzalez2010, p.483].

```{r planoxy, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:planoxy)', fig.align='center', out.width='65%'}
knitr::include_graphics(rep('imagens/06-segmentacao/planoxy.png'))
```

Ocorre um pequeno problema nessa forma, pois quando a reta se aproxima da direção vertical, $a$, o coeficiente angular da reta, aproxima-se do infinito. Por essa razão, em vez de levarmos os pontos a retas no espaço $ab$ cartesiano, utilizamos um espaço em coordenadas polares. Portanto, utilizamos a seguinte Equação \@ref(eq:coordPolar):

$$\rho=x\cos{\theta}+y\ sen{\ \theta}
(\#eq:coordPolar)$$

A Figura \@ref(fig:planoxyrhotheta) mostra a aplicação de coordenadas polares nesse contexto por exemplos gráficos. Na Figura \@ref(fig:planoxyrhotheta)(a), $\rho$ é a distância da origem até a reta. Na Figura \@ref(fig:planoxyrhotheta)(b), mostra-se que cada uma das curvas senoidais representa as infinitas retas que passam por cada um dos dois pontos, $(x_i,y_i)$ e $(x_j,y_j)$ e a interseção das curvas, $(\rho',\theta')$, é a reta que passa por esses dois pontos.

(ref:planoxyrhotheta) Exemplo de conversão de uma reta no plano cartesiano para o plano polar. (a) Pode ser dois pontos arbitrários de uma imagemImagem de ônibus com filtro de aguçamento e de suavização. [@burger2009, p. 98]

```{r planoxyrhotheta, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:planoxyrhotheta)', fig.align='center', out.width='90%'}
knitr::include_graphics(rep('imagens/06-segmentacao/planoxyrhotheta.png'))
```

A Figura \@ref(fig:planoxyrhotheta)(c) mostra como fazemos a representação digital do espaço de coordenadas polares, usamos uma matriz onde esse espaço é subdividido em várias células, chamadas células acumuladoras. Os valores de $\theta_{\text{min}}$ e $\theta_{\text{max}}$ são, geralmente, $-90^{\circ}\leq \theta\leq90^{\circ}$ e os valores de $\rho_{min}$ e $\rho_{max}$ são $-D\leq\rho\leq D$, onde $D$ é o comprimento da diagonal da imagem, ou seja, $D=\sqrt{altura^2+largura^2}$. Essa etapa consiste em andar por todos os pontos, $(x,y)$, de borda da imagem de entrada e calcular o valor de $\rho$, a partir da Equação \@ref(eq:coordPolar), variando o ângulo $\theta$. Com isso, a cada valor do ângulo, teremos um $\rho$ diferente e, então, na célula acumuladora $(\rho,\theta)$ da matriz, \@ref(fig:planoxyrhotheta)(c), incrementa-se 1, uma espécie de voto a candidato de reta. Ao final de todo o processo, temos determinadas células com valores mais altos, conhecidas como picos, que correspondem ao cruzamento de duas ou mais curvas senoidais do plano $(\rho,\theta)$ e a uma linha que liga pontos no plano $xy$. 

A seguir temos um exemplo, que nos ajuda a entender e ver o funcionamento da transformada de Hough na prática. A Figura \@ref(fig:houghumponto)(a) contém uma imagem de tamanho 101x101 com um ponto no centro, ou seja, $(x,y)=(50,50)$. A Figura \@ref(fig:houghumponto)(b) contém a matriz acumuladora da transformada, que podemos ver a curva senoidal formada pelo ponto. Verificando os valores nela, vemos os resultados com diferentes $\theta$: 

- para $\theta=-90^{\circ}$ 
$$\rho=50 \cdot \cos(-90^{\circ})+50\cdot\text{sen}(-90^{\circ}) = -50$$
- para $\theta=90^{\circ}$
$$\rho=50\cdot \cos(90^{\circ})+50\cdot\text{sen}(90^{\circ})=50$$
- para $\theta=45^{\circ}$
$$\rho=50\cdot \cos(45^{\circ})+50\cdot \text{sen}(45^{\circ})\approx70,71$$
- para $\theta=-45^{\circ}$
$$\rho=50\cdot\cos(-45º)+50\cdot \text{sen}(-45º)=0$$ 

(ref:houghumponto) Transformada de Hough para um ponto.

```{r houghumponto, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghumponto)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_um_ponto.jpg'))
```

Na Figura \@ref(fig:houghdoispontosesquerda)(a), temos dois pontos, $a$ e $b$, onde foi realizada a transformada de Hough que tem a Figura \@ref(fig:houghdoispontosesquerda)(b) como espaço de saída. A reta $c$ que passa por esses dois pontos, representada em pontilhado na Figura \@ref(fig:houghdoispontosesquerda)(a) e, na Figura \@ref(fig:houghdoispontosesquerda)(b), temos o ponto no plano  que representa essa reta, ou seja, uma reta a uma distância $\rho\approx70,71$ da origem com o ângulo de $45^{\circ}$.

(ref:houghdoispontosesquerda) Transformada de Hough para um ponto em 45º.

```{r houghdoispontosesquerda, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghdoispontosesquerda)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_dois_ponto_esquerda.png'))
```

Na Figura \@ref(fig:houghdoispontosdireita)(a) temos mais um exemplo, desta vez com um ponto localizado a sua direita, diferentemente da anterior, esses dois pontos formam uma reta de $-45^{\circ}$, fato que pode ser visto na Figura \@ref(fig:houghdoispontosdireita)(b) onde o ponto de encontro das duas curvas acontece em $\theta=-45^{\circ}$ com um valor de $\rho=0$ já que a reta cruza a origem, ou seja, não possui distância em relação a ela.

(ref:houghdoispontosdireita) Transformada de Hough para um ponto em -45º.

```{r houghdoispontosdireita, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghdoispontosdireita)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_dois_ponto_direita.png'))
```

Nosso último exemplo contém uma imagem com três pontos, onde temos três tipos de retas possíveis. Observando a figura \@ref(fig:houghtrespontos)(a), podemos ver os pontos $a$, $b$ e $c$ e as retas $d$, $e$ e $f$ que passam por eles e, na Figura \@ref(fig:houghtrespontos)(b), temos a transformada de Hough para essa imagem, algo interessante de se notar é o fato de a reta que passa pelos pontos $b$ e $c$ pode ser detectada duas vezes, isso se deve a uma característica da transformada de Hough chamada relação de adjacência reflexiva, ou seja, isso acontece como resultado pela maneira como $\rho$ e  $\theta$ mudam de sinal quando chegamos as extremidades de $\pm90^{\circ}$.

(ref:houghtrespontos) Transformada de Hough para três pontos.

```{r houghtrespontos, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghtrespontos)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_tres_ponto.png'))
```

Na Figura \@ref(fig:houghlineexemplo), temos nosso último exemplo na detecção de linhas, mas, desta vez, realizado em uma imagem real. Primeiramente, foi realizada a detecção de bordas pelo método de Canny, como pode ser visto na Figura \@ref(fig:houghlineexemplo)(a). Logo após, foi realizada a transformação de Hough, com resultado em Figura \@ref(fig:houghlineexemplo)(b) e, por fim, temos a imagem original com as linhas detectadas na Figura \@ref(fig:houghlineexemplo)(c). Atenção ao fato de que nem todos os picos da transformada podem ser utilizadas como linhas, pois teríamos um número enorme delas, então utilizamos um *threshold* para somente as linhas que tiverem um número de votos (acumulação na matriz) superior a um valor limítrofe serem utilizadas.

(ref:houghlineexemplo) Resultado da transformada de Hough usada na detecção de linhas em uma imagem.

```{r houghlineexemplo, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghlineexemplo)', fig.align='center', out.width='95%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_line_exemplo.jpg'))
```

### Transformada de Hough para detecção de círculos
A transformada de Hough pode ser estendida para detecção de círculos através da substituição da equação da reta pela equação do círculo \@ref(eq:eqCirculo):
$$(x-x_0)^2+(y-y_0)^2=r^2
(\#eq:eqCirculo)$$

Nesse caso, também andamos por cada pixel $(x,y)$ das bordas da imagem e o levamos ao espaço de parâmetro com as seguintes equações \@ref(eq:eqCirculoCoordPolar1) e \@ref(eq:eqCirculoCoordPolar2):

- $$x_0=x-r\cos(\theta)
(\#eq:eqCirculoCoordPolar1)$$
- $$y_0=y-\text{sen}(\theta)
(\#eq:eqCirculoCoordPolar2)$$

A diferença é que, neste caso, o nosso espaço de parâmetro terá três dimensões, porque, como desenhamos um círculo para cada pixel do círculo da imagem, a variação do diâmetro desse círculo deve levar a uma variação dos círculos descritos no espaço de parâmetros, então, também devemos variar os valores de $r$ além dos valores de $x$ e $y$. Uma representação disso é vista na Figura \@ref(fig:houghCircle)(a), a qual temos três pixels que definem um círculo, na Figura \@ref(fig:houghCircle)(b), a qual temos os círculos no espaço de parâmetros, e, na Figura \@ref(fig:houghCircle)(c), podemos ver uma representação de um espaço de parâmetros com diferentes raios.

(ref:houghCircle) Transformada de Hough para círculos [@nixon2019feature, p.255].

```{r houghCircle, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghCircle)', fig.align='center', out.width='60%'}
knitr::include_graphics(rep('imagens/06-segmentacao/houghCircle.png'))
```

A Figura \@ref(fig:moedas) contém uma imagem com algumas moedas. Na figura \@ref(fig:houghcircleraios)(a), temos as bordas da imagem detectada com o método de Canny. Logo após, na Figura \@ref(fig:houghcircleraios)(b) - (f), temos a representação do espaço de Hough para diferentes valores de raio. E, na figura \@ref(fig:houghcircleresultado), temos o resultado da detecção de círculo após encontrados os picos do espaço de parâmetros.

(ref:moedas) Imagem original de moedas.

```{r moedas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:moedas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/moedas.jpg'))
```

(ref:houghcircleraios) Canny e espaço de parâmetros.

```{r houghcircleraios, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghcircleraios)', fig.align='center', out.width='100%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_circle_raios.jpg'))
```

(ref:houghcircleresultado) Resultado final da transformada de Hough para círculos.

```{r houghcircleresultado, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:houghcircleresultado)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/hough_circle_resultado.jpg'))
```

## Detecção de Quinas
Quinas são pontos chaves na visão computacional por serem muito úteis na descrição e correspondência de objetos usando poucos dados. E existem diferentes métodos para identificação dos pontos, dentre eles o mais comum é o de Harris, que é o sucessor do de Moravec [@nixon2019feature, p. 178].

### Detector de Quinas de Moravec
Moravec obtém sua medida de curvatura através de uma variação média de intensidade em quatro direções principais: $(0,1), (0,-1), (1,0)$ e $(-1,0)$. Isso é feito através da seguinte Equação \@ref(eq:moravec), considerando a análise sobre o pixel $(x,y)$, o deslocamento $(u,v)$ e a janela $2w+1$ [@nixon2019feature, p. 185].

$$E_{u,v}(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}[P_{x+i,\ y+j} - P_{x+i+u,\ y+j+v}]^2
(\#eq:moravec)$$

Essa equação também aproxima a função de autocorrelação na direção $(u,v)$ [@nixon2019feature, p. 186].

O detector de Moravec apesar de ser intuitivo seu funcionamento, ele considera apenas um pequeno conjunto de mudanças possíveis. Então, Harris propôs ainda avaliar a autocorrelação, mas por uma expressão analítica [@nixon2019feature, p. 185].

### Detector de Quinas de Harris
O detector de Harris é desenvolvido na ideia de Moravec e sua equação, mas com uma abordagem mais complexa. Harris assume que $P_{x+i+u,\ y+j+v}$ possa ser estimado pela série de Taylor de primeira ordem [@nixon2019feature, p. 193]. Dessa forma \@ref(eq:taylor1Ordem),

$$P_{x+i+u,\ y+j+v} = P_{x+i,\ y+j} + \frac{\partial{P_{x+i,\ y+j}}}{\partial x}u + \frac{\partial{P_{x+i,\ y+j}}}{\partial y}v
(\#eq:taylor1Ordem)$$

Substituindo a equação anterior, \@ref(eq:taylor1Ordem), na equação de Moravec, \@ref(eq:moravec), produz-se \@ref(eq:taylor1OrdemMoravec)
$$E_{u,v}(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}[\frac{\partial{P_{x+i,\ y+j}}}{\partial x}u + \frac{\partial{P_{x+i,\ y+j}}}{\partial y}v]^2
(\#eq:taylor1OrdemMoravec)$$ 
E expandindo a potência, \@ref(eq:HarrisExpandPotencia)
$$E_{u,v}(x,y) = A(x,y)u^2 + 2C(x,y)uv + B(x,y)v^2
(\#eq:HarrisExpandPotencia)$$
Esta última equação pode ser representada na forma de matriz \@ref(eq:HarrisMatrices). Representação útil para compreensão mais à frente neste tópico [@nixon2019feature, p. 187].
$$
\begin{split}
E_{u,v}(x,y) &= 
\begin{bmatrix}u & v\end{bmatrix}
\begin{bmatrix}A(x,y) & C(x,y)\\ C(x,y) & B(x,y)\end{bmatrix}
\begin{bmatrix}u \\ v\end{bmatrix}
\\&= D^TMD
\end{split}
(\#eq:HarrisMatrices)$$
onde
$$A(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}(\frac{\partial P_{x+i, y+j}}{\partial x})^2
(\#eq:A)$$
$$B(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w} (\frac{\partial P_{x+i, y+j}}{\partial y})^2
(\#eq:B)$$
$$C(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w} (\frac{\partial P_{x+i, y+j}}{\partial x})(\frac{\partial P_{x+i, y+j}}{\partial y})
(\#eq:C)$$

Como $E_{u.v}(x,y)$ tem a forma de uma função quadrática, então possui dois eixos principais. Então, podemos rotacioná-la a fim de alinhar seus eixos com os do sistema de coordenadas, obtendo $F_{u,v}(x,y)$, Equação \@ref(eq:harrisRotacionada) [@nixon2019feature, p. 187].
$$F_{u,v}(x,y) = \alpha(x,y)^2u^2 + \beta(x,y)^2v^2
(\#eq:harrisRotacionada)$$

ou em sua forma matricial \@ref(eq:harrisRotMatrix). Note que são rotacionados os eixos definidos por $D$.
$$
\begin{split}
F_{u,v}(x,y) &= R^TD^TMDR\\
& = D^TR^TMRD\\
& = D^TQD
\end{split}
(\#eq:harrisRotMatrix)
$$

$$Q = \begin{bmatrix} \alpha & 0\\ 0 & \beta  \end{bmatrix}
(\#eq:qMatrix)$$
Os valores de $\alpha$ e $\beta$ são proporcionais à função de autocorrelação nos principais eixos. Dessa forma,  $\alpha$ e $\beta$  serão pequenos  se o pixel $(x,y)$ for de uma região com intensidade constante, um será de valor grande e outro pequeno se estiverem em uma borda reta, e ambos terão valores grandes se estiverem em uma borda com curvatura acentuada. Portanto, a medida de curvatura em um determinado ponto é definida como $k_k(x,y)$, \@ref(eq:medidaCurvatura) [@nixon2019feature, p. 187].
$$k_k(x,y) = \alpha \beta - k(\alpha + \beta)^2
(\#eq:medidaCurvatura)$$
No qual $k$ controla a sensibilidade do detector.

Como $Q$ é uma composição ortogonal de $M$. Os elementos de Q são chamados de autovalores [@nixon2019feature, p. 188]. Inferimos que
$$Q = R^TMR
(\#eq:qCompOrtogonal)$$
Então, a partir da equivalência de determinantes e traços, é possível produzir uma relação equivalente a $Q$ com os valores da matriz $M$, \@ref(eq:harris1de2) e \@ref(eq:harris2-De2) [@nixon2019feature, p. 188].
$$\alpha \beta = A(x,y)B(x,y) - C(x,y)^2
(\#eq:harris1de2)$$

$$\alpha + \beta = A(x,y) + B(x,y)
(\#eq:harris2-De2)$$

Assim, conforme \@ref(eq:harris1de2) e \@ref(eq:harris2-De2), a medida de curvatura, \@ref(eq:medidaCurvatura), pode ser obtida por \@ref(eq:medidaCurvatura2):
$$
\begin{split}
k_k(x,y) &= \alpha \beta - k(\alpha + \beta)^2
\\&= A(x,y)B(x,y) - C(x,y)^2 - k(A(x,y) + B(x,y))^2
\\&=det(M) - k(trace(M))^2
\end{split}
(\#eq:medidaCurvatura2)$$
A Figura \@ref(fig:imagemQuinas)(a) é a imagem original. A Figura \@ref(fig:imagemQuinas)(b) foi gerada usando o detector de Harris com uma vizinhança 5x5 ($w=2$) para cada deslocamento $(u,v)$, com a derivada sendo calculada pelo Operador de Sobel (3x3) e com sensibilizador $k=0.01$. Limiarizou-se a imagem de curvatura, descartando os valores que não fossem maiores que 9% do valor máximo. E nas posições $(x,y)$ da imagem que continham as curvaturas, foi destacado em rosa. 
Observe que a imagem identificou as quinas do tabuleiro de xadrez e do cubo mágico, porém não detectou outras quinas como as das árvores. Além disso, foi encontrado quinas que não são próprias dos objetos, e sim da iluminação. 
Variando tanto o sensibilizador da função, $k$, como o limiar é provável que consigamos encontrar mais quinas, com o custo de também poder classificar ruídos que foram identificados como bordas também como quinas. Entretanto, já vimos que o filtro gaussiano pode ser que nos ajude nesse problema. 


(ref:imagemQuinas) Exemplo de detecção de Quinas pelo método de Harris.

```{r imagemQuinas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemQuinas)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemQuinas.png'))
```


## Detecção de *Blobs*
*Blobs*, traduzido para português como bolhas, são regiões da imagem em que os pixels têm valores, aproximadamente, iguais. Uma boa representação - um tanto quanto artificial - disso é a função gaussiana, como pode ser vista sua representação 3-D, na Figura  \@ref(fig:gaussianblob)(a), e sua representação 2-D, na Figura \@ref(fig:gaussianblob)(b), temos, em ambas, um conjunto de pixels com valores bem próximos, o que caracteriza um *blob.*

(ref:gaussianblob) Função gaussiana em 3-D e 2-D.

```{r gaussianblob, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:gaussianblob)', fig.align='center', out.width='75%'}
knitr::include_graphics(rep('imagens/06-segmentacao/gaussian_blob.jpg'))
```

Apesar do exemplo, a detecção de *blobs* não se restringe aos elementos circulares, mas a qualquer conjunto de pixels.

### LoG
Esse método utiliza o [Laplaciano da Gaussiana](#método-de-marr-hildreth), que já foi apresentado anteriormente, mas que, resumidamente, é o cálculo de derivadas de segunda ordem em uma imagem convolucionada com um filtro gaussiano. Isso gerará fortes respostas positivas em *blobs* escuros e negativas em *blobs* claros de tamanho $\sqrt{2\sigma}$. Como existe uma relação entre as respostas e o tamanho do $\sigma$, é necessário realizar a operação com vários valores de $\sigma$, pois, assim, detecta-se *blobs* de diferentes tamanhos. 

(ref:nasahubbledeep) Imagem de Campo Ultraprofundo do Hubble [@img:hubbledeep].

```{r nasahubbledeep, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:nasahubbledeep)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/nasa_hubble_deep.jpg'))
```

Como podemos ver na Figura \@ref(fig:gaussianblob) com diferentes valores de $\sigma$, consegue-se detectar objetos de tamanhos variados, por exemplo, na Figura \@ref(fig:logsigmas)(a), detectam-se as estrelas da Figura \@ref(fig:nasahubbledeep) que apresentam uma menor resposta ao filtro laplaciano.

(ref:logsigmas) Laplaciano do Gaussiano com diferentes valores de sigma.

```{r logsigmas, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:logsigmas)', fig.align='center', out.width='100%'}
knitr::include_graphics(rep('imagens/06-segmentacao/log_sigmas.jpg'))
```

Na Figura \@ref(fig:loghubble), tem-se o resultado da detecção dos *blobs* utilizando LoG. Note que nem todas as estrelas foram detectadas, isso se deve ao fato do uso de um valor de *threshold*, o qual queremos as detecções acima de um determinado limiar. Na Figura \@ref(fig:loghubblebaixo), pode-se ver o resultado com um valor de limiar menor, onde muito mais objetos foram localizados.

(ref:loghubble) Resultado da detecção de *blobs* com LoG.

```{r loghubble, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:loghubble)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/log_hubble.jpg'))
```

(ref:loghubblebaixo) Resultado da detecção de *blobs* com LoG com um *threshold* menor.

```{r loghubblebaixo, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:loghubblebaixo)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/log_hubble_baixo_threshold.jpg'))
```

### DoG
O método de DoG é, basicamente, o mesmo do anterior, mas possui uma certa vantagem, que é o fato de ele ser mais eficiente. Como também já foi mencionado no tópico na seção anterior, [Marr-Hildreth](#método-de-marr-hildreth), é possível aproximar o Laplaciano da Gaussiana através da Diferença de Gaussianas (DoG), ou seja, primeiramente, realiza-se a filtragem gaussiana com dois $\sigma$ diferentes e se faz a subtração entre os dois. Realizamos esse processo para diferentes pares de valores, dessa forma, obtém-se o mesmo espaço de escala construído com o processo do LoG. Na Figura \@ref(fig:doghubble), tem-se um exemplo de detecção por DoG.

(ref:doghubble) Resultado da detecção de *blobs* com DoG.

```{r doghubble, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:doghubble)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/dog_hubble.jpg'))
```

### DoH
Uma matriz Hessiana é uma matriz que contém as derivadas de uma função. No nosso caso, utilizamos a Hessiana de ordem 2, pois estamos trabalhando com imagens, logo duas dimensões. Ela pode ser representada da seguinte maneira \@ref(eq:matrizHessiana):

$$H[f(x_1, x_2, \dots,x_n)]=
\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n}\\ 
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \ldots & \frac{\partial^2 f}{\partial x^2_n}
\end{bmatrix}
(\#eq:matrizHessiana)$$

A matriz Hessiana tem muita utilidade, pois ela possibilita descrever a curvatura em um ponto da função multivariável, o que, no nosso caso, pode ajudar a detectar os *blobs*, já que eles são aglomerados de pixels e devem estar separados do restante da imagem, ou seja, um aglomerado claro em um fundo escuro e vice-versa. Isso irá fazer com que sua função tenha uma mudança de sinal que pode ser detectada através das informações da matriz. Além disso, como dito por Herbert Bay et al.[@bay2006surf], os detectores baseados na Hessiana são mais estáveis e repetíveis (tem a mesma resposta para a mesma imagem com diferentes ângulos, iluminações etc.).

Um dos principais algoritmos que fazem uso dessa matriz se chama *Speeded Up Robust Features* (SURF)[@bay2006surf]. Esse método faz uso de várias técnicas que o tornam muito rápido, como seu próprio nome sugere. Uma dessas técnicas é o cálculo da integral da imagem, realizado a partir da soma de todos os pixels de uma área retangular a partir do $x$ atual, sendo que este varia a medida que se anda pela imagem. 

(ref:imageIntegral) Integral de uma imagem [@Cen2016StudyOV].

```{r imageIntegral, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imageIntegral)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imageIntegral.png'))
```

Como pode ser visto na Figura \@ref(fig:imageIntegral), a integral de uma imagem contém a soma das regiões, por exemplo, a primeira posição contém a soma de somente uma célula, no caso $1$. A segunda posição tem a soma de duas células. Note que, na primeira linha, está, basicamente, somando as células de uma só linha. Na segunda linha, começa-se a formar regiões retangulares, por exemplo, na segunda linha e na terceira coluna há o valor $6$, resultante da soma das seis células da primeira linha com a segunda. Com a integral, pode-se calcular a área de qualquer região com apenas quatro operações, da seguinte forma, \@ref(eq:integralGeral):
$$soma = D+A-B-C
(\#eq:integralGeral)$$

onde ${A,B,C,D}$ formam uma região, como exemplo, o cálculo da área 2x2 no canto inferior direito da Figura \@ref(fig:imageIntegral), \@ref(eq:integralAplic):
$$soma = 9 + 1 - 3 - 3 = 4
(\#eq:integralAplic)$$

Isso nos ajuda na aplicação de *box filters*, já que precisaríamos da soma de determinadas áreas, porque, com isso, aumentamos a velocidade do método.
Sendo $X=(x,y)$ um ponto em uma imagem, sua matriz Hessiana em $X$ a uma escala $\sigma$ é dada por:

$$H(X,\sigma)=\begin{bmatrix}
L_{xx}(X, \sigma) & L_{xy}(X, \sigma)\\ 
L_{xy}(X, \sigma) & L_{yy}(X, \sigma)
\end{bmatrix}
(\#eq:hessianaImagem)$$

onde $L_{xx}(X, \sigma)$ é a convolução da imagem no ponto $X$ com a derivada de segunda ordem gaussiana $\frac{\partial^2g(\sigma)}{\partial x^²}$ e assim por diante [@bay2006surf]. Aqui, entra em cena mais um elemento para melhorar a velocidade do algoritmo, Bay, Herbert et al. utilizam *box filters* para aproximar o filtro gaussiano. Como podemos ver, na Figura \@ref(fig:discretizadogaussiano), os dois primeiros filtros são os derivativos gaussianos discretizados e os dois últimos são os aproximados a partir de *box filters*.

(ref:discretizadogaussiano) Filtro gaussiano discretizado e aproximado nas direções $y$ e $xy$ [@bay2006surf].

```{r discretizadogaussiano, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:discretizadogaussiano)', fig.align='center', out.width='85%'}
knitr::include_graphics(rep('imagens/06-segmentacao/discretizadogaussiano.png'))
```

Chamamos as derivadas realizadas na imagem de $D_{xx}$, $D_{yy}$, $D_{xy}$. Essas derivadas não são realizadas com somente um valor de $\sigma$, seguem o mesmo raciocínio que os detectores anteriores, usam uma sequência de valores para, assim, criar um espaço de escalas e conseguir detectar *blobs* de diferentes tamanhos. 

A determinante da Hessiana é dada por \@ref(eq:detHeussiana):

$$det(H_{\text{aprox}}) = D_{xx}D_{yy}-(0.9D_{xy})^2
(\#eq:detHeussiana)$$

O valor $0.9$ é um peso introduzido pelos autores Bay, Hebert et al. para corrigir as respostas quando utilizamos várias escalas de sigma e obter uma invariância escalar. Na Figura \@ref(fig:dohhubble), tem-se o resultado de uma detecção de *blobs* realizada pela Determinante do Hessiano.

(ref:dohhubble) Resultado da detecção de *blobs* com DoH. 

```{r dohhubble, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:dohhubble)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/doh_hubble.jpg'))
```

## Limiarização
A limiarização, como próprio nome sugere, é um ou mais limiares, valores limites, que são responsáveis por segmentar uma imagem em regiões com base nos valores de intensidade e/ou propriedades desses valores [@gonzalez2010, p. 486]. Sua boa repercursão dada em segmentações de imagem é por sua simplicidade de implementação, velocidade computacional e propriedades intuitivas [@gonzalez2010, p. 486].

É importante salientar que a chance de sucesso da limiarização de intensidade é proporcional à largura e à profundidade do(s) vale(s) que separam os modos (ou classes) do histograma. E os principais fatores que afetam as propriedades do(s) vale(s) são [@gonzalez2010, p. 487]:

- A separação entre picos: quanto mais distantes forem os picos entre si, melhores as possibilidades de separação da imagem;

- Índice de ruído da imagem: os modos ficam mais largos com o aumento do ruído;

- O tamanho relativo dos objetos e do fundo;

- A uniformidade da fonte de iluminação;

- A uniformidade da reflexão da imagem.

Suponha os histogramas de intensidade de duas imagens composta por objetos claros sobre um fundo escuro, conforme Figura \@ref(fig:histograma4didatica), de tal forma que os pixels de seus objetos e do fundo tenham valores de intensidade agrupados em modos (ou grupos, ou classes), para segmentar as regiões da imagem, que também pode ser visto como segmentar os modos do histograma, devem ser encontrados os limiares entre os modos capazes de ter a melhor segmentação^[Esses limiares podem ser adquiridos a partir de diferentes métodos, como serão explicados nos próximos tópicos.]. Então, no histograma da Figura \@ref(fig:histograma4didatica)(a), usa-se um limiar, pois há um vale bem definido, já na Figura \@ref(fig:histograma4didatica)(b), há dois vales, logo é possível usar dois limiares para segmentar as regiões da imagem. 

A segmentação do objeto claro da imagem que possui o histograma da Figura \@ref(fig:histograma4didatica)(a) é dada por $g(x,y)$, sua imagem de saída:

$$g(x,y) =
\begin{cases}
1,\ se\ f(x,y) > T \\
0,\ se\ f(x,y) \leq T
\end{cases}
(\#eq:limOutput)$$

Note que se cria uma binarização, uma imagem preta e branca, que pode ser vista como uma máscara a ser aplicada na imagem do histograma, multiplicando a imagem pela máscara. E, analogamente ao caso anterior, após definido os limiares de uma imagem com mais modos, por exemplo, numa imagem com três modos, as regiões poderiam ser identificadas pelas cores branca, cinza e preta. 

(ref:histograma4didatica) Histogramas de intensidade que podem ser divididos por um limiar único, (a), e limiares duplos, (b).  [@gonzalez2010, p. 486]

```{r histograma4didatica, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:histograma4didatica)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/histograma4didatica.png'))
```
  
Quando $T$ é uma constante aplicável em uma imagem inteira, o processo é conhecido como limiarização global. Caso $T$ mude ao longo da imagem, usamos o termo limiarização variável. E quando $T$ denotar uma limiarização variável na qual o valor $T$ em qualquer ponto $(x,y)$ em uma imagem depende das propriedades de sua vizinhança, por exemplo, a intensidade média dos pixels da vizinhança, o chamamos de [limiarização local ou regional](#limiarização-variável-baseada-nas-propriedades-locais-da-imagem)^[O uso desses termos não é universal e é provável vê-los sendo utilizados indiferentemente na literatura de processamento de imagens.] [@gonzalez2010, p. 486].  

Os problemas de segmentação que exigem mais do que dois limiares são difíceis (muitas vezes impossíveis) de se resolver e seus melhores resultados, geralmente, são obtidos através dos métodos como a [limiarização variável](#limiarização-variável) ou [aumento da região](#particionamento-da-imagem) [@gonzalez2010, p. 486].


- **O papel do ruído da limiarização**

O ruído de uma imagem é capaz de fazer com que fique difícil achar um limiar ideal para segmentar a imagem sem processamentos adicionais, pois o(s) vale(s) da imagem podem desaparecer [@gonzalez2010, p. 487]. 

Observe que, conforme os exemplos da Figura \@ref(fig:imagemRuido) e seus respectivos histogramas, o aumento no desvio padrão nos níveis de intensidade do ruído gaussiano faz com que o vale que separava os dois modos desapareça, o que torna difícil a segmentação do fundo e do objeto.

(ref:imagemRuido) (a) Imagem de 8 bits livre de ruído, produção típica de uma Computação Gráfica. (b) Imagem com ruído gaussiano aditivo com $\mu = 0$ e $\sigma$ de 10 níveis de intensidade. (c) Imagem com ruído gaussiano aditivo com $\mu = 0$ e $\sigma$ de 50 níveis de intensidade. (d) a (f) Histogramas correspondentes [@gonzalez2010, p. 487].

```{r imagemRuido, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemRuido)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemRuido.png'))
```

- **O papel da iluminação e refletância**

O problema da iluminação é quando não é possível ter uma incidência uniforme de luz, causando um sombreamento. O mesmo efeito acontece quando o problema não é na iluminação, mas nas características da superfície do objeto; pois a iluminação e refletância produzem problemas equivalentes. Note que, pela Figura \@ref(fig:imagemRefletancia), o histograma deixou de ser bimodal. Logo não é simples de segmentar imagens com problemas de iluminação e refletância.

(ref:imagemRefletancia) (a) é a imagem ruidosa. (b) é a rampa de intensidade no intervalo $[0.2, 0.6]$. (c) é o produto de (a) e (b). (d) a (f) são os histogramas correspondentes [@gonzalez2010, p. 488].

```{r imagemRefletancia, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemRefletancia)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemRefletancia.png'))
```

Há três abordagens básicas para se resolver os problemas de iluminação e refletância para uma boa segmentação. Corrigir diretamente o padrão de sombreamento através de uma multiplicação com o comportamento inverso do sombreamento, por exemplo, uma iluminação não uniforme, porém fixa, como a da Figura \@ref(fig:imagemRefletancia), pode ser corrigida multiplicando a imagem pelo inverso do padrão de iluminação, que pode ser obtida na aquisição de uma imagem de uma superfície plana de intensidade constante. Outra alternativa é corrigí-lo por meio do processamento, por exemplo, utilizando a transformada *top-hat*. E a terceira abordagem é a de contornar isso utilizando a [limiarização variável](#limiarização-variável) [@gonzalez2010, p. 488].



### Limiarização Global Simples
A limiarização global simples é um método iterativo básico e que não é o mais eficiente. Ele é um processo iterativo que denomina o limiar ideal como aquele que produz menor diferença entre as médias de intensidade dos modos, o segmentado e o desprezado [@gonzalez2010, p. 488].

Ele consiste em:

1. Selecionar uma estimativa inicial para o limiar global, $T$.

2. Segmentar a imagem usando $T$. Isso dará origem a dois grupos de pixels: $G_{1}$, composto por todos os pixels com valores de intensidade $> T$, e $G_{2}$, composto pelos pixels com valores $\leq T$.

3. Calcular os valores de intensidade média dos grupos: $m_{1}$ e $m_{2}$.

4. Calcular um novo valor de limiar: $T = \frac{m_{1}+m_{2}}{2}$.

5. Repita as Etapas 2 a 4 até que a diferença entre os valores de $T$, com a  iterações sucessiva e a atual, seja menor que o parâmetro predefinido $\Delta T$.

A Figura \@ref(fig:imagemLimiarGlobalSimples) mostra um exemplo da aplicação de Limiarização Global Simples. A Figura \@ref(fig:imagemLimiarGlobalSimples)(a) é a imagem de uma digital com ruído. A Figura \@ref(fig:imagemLimiarGlobalSimples)(b) mostra que seu histograma possui um vale bem nítido e, pela aplicação do algoritmo, que usa $\Delta T = 0$ e inicia $T$ como a média de intensidade da imagem, após três iterações, encontra-se o limiar $T = 125.4$. A Figura \@ref(fig:imagemLimiarGlobalSimples)(c) mostra a digital segmentada pelo limiar encontrado, $T = 125$; como esperado, pelo nítido vale, foi satisfatório o resultado.

(ref:imagemLimiarGlobalSimples) (a) Impressão digital ruidosa. (b) Histograma. (c) Segmentação resultante usando um limiar global. [@gonzalez2010, p. 489]

```{r imagemLimiarGlobalSimples, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarGlobalSimples)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarGlobalSimples.png'))
```


### Limiarização pelo Método de Otsu

O método de Otsu é um método estatístico que produz o chamado limiar ótimo a partir do histograma. O limiar ótimo é denotado por aquele que maximiza a variância entre classes ou minimiza a variância intraclasse [@gonzalez2010, p. 489]. 

O primeiro passo é obter o histograma da imagem normalizado, isto é, no qual os pesos de cada intensidade são a probabilidade da ocorrência daquela intensidade na imagem. Segue abaixo a Equação \@ref(eq:histNormaliz) que representa um histograma normalizado, no qual $L$ representa a quantidade de níveis de intensidade e $p_{i}$, a probabilidade de ocorrência da intensidade $i$ na imagem [@gonzalez2010, p. 490]. 

$$\sum_{i=0}^{L-1}{p_{i} = 1,\ p_{i} \geq 0}
(\#eq:histNormaliz)$$

Para entender a equação principal de Otsu, Equação \@ref(eq:otsuMain), precisa-se compreender algumas equações que a compõe. A probabilidade de ocorrência do modo $1$ é dada pela Equação \@ref(eq:probModo1) [@gonzalez2010, p. 490]:
$$P_{1}(k) = \sum_{i=0}^{k}{p_{i}}
(\#eq:probModo1)$$

E o valor da intensidade média dos pixels da classe $1$, $C_{1}$, para dado limiar $k$ pode ser calculado pela Equação \@ref(eq:mediaClasse1) [@gonzalez2010, p. 490]

$$\begin{split}
m_{1}(k) & = \sum_{i=0}^{k}{iP(i/C_{1})}\\
& = \sum_{i=0}^{k}{iP(C_{1}/i)P(i)/P(C_{i})}\\
& = \frac{1}{P_{1}(k)}\sum_{i=0}^{k}{ip_{i}}\\
\end{split}
(\#eq:mediaClasse1)$$

E a média acumulada (intensidade média) até o nível $k$ ou da classe $C_{1}$ é dada pela Equação \@ref(eq:mediaAcumulada) [@gonzalez2010, p. 490]:
$$m(k) = \sum_{i=0}^{k}{ip_{i}}
(\#eq:mediaAcumulada)$$

Entendidas as equações anteriores, chegamos a equação principal, Equação \@ref(eq:otsuMain), que denota a variância entre classes.
$$\sigma_B^2(k) = \frac{[m_GP_{1}(k) - m(k)]^{2}}{P_1(k)[1 - P_1(k)]}
(\#eq:otsuMain)$$

Então, o limiar ótimo é o valor que maximiza a variância entre classes, denominado $k^*$, demonstrado pela Equação \@ref(eq:maxVarK) [@gonzalez2010, p. 491]. E conforme informado anteriormente, esse resultado é o mesmo que minimiza a variância dentro das classes; isso se deve a uma propriedade estatística que relaciona a variância global da intensidade da imagem, a variância interclasse e a variância intraclasse.
$$\sigma_B^2(k^*) = \max_{0 \leq k \leq L-1} \sigma_B^2(k)
(\#eq:maxVarK)$$

Se a máxima variância entre classes existir para mais de um valor, é habitual se calcular a média desses valores $k$ [@gonzalez2010, p. 491].

Uma métrica adimensional, $\eta$, pode ser usada para obter uma estimativa quantitativa da separabilidade das classes, o que dá uma idéia da facilidade de segmentação e do resultado esperado. Seu cálculo é demonstrado na seguinte Equação \@ref(eq:metricaAdimensional). Para o cálculo de $\eta$, é necessário conhecer a variância global da intensidades da imagem, que pode ser calculada por \@ref(eq:varGlobal).

$$\eta = \frac{\sigma_B^2(k^*)}{\sigma_G^2}
(\#eq:metricaAdimensional)$$

$$\sigma_G^2 = \sum_{i=0}^{L-1}{(i - m_G)}^2p_i
(\#eq:varGlobal)$$

Tendo o limiar ótimo, $k^*$, segmentamos a imagem como já visto na introdução desta seção, [Limiarização](#limiarização).

Resumo do algoritmo de Otsu [@gonzalez2010, p. 492]:

1. Calcular o histograma normalizado da imagem de entrada. Designar os componentes do histograma como $p_i, i = 0, 1, 2, ..., L-1$;
2. Calcular as somas acumuladas, $P_1(k)$, para $k = 0, 1, 2, ..., L-1$;
3. Calcular as médias acumuladas $m(k)$, para $k = 0, 1, 2, ..., L-1$;
4. Calcular a intensidade média global, $m_G$;
5. Calcular a variância entre classes, $\sigma_B^2(k)$, para $k = 0, 1, 2, ..., L-1$;
6. Obter o limiar ideal de Otsu, $k^*$, caso haja mais de um, faz-se a média dos valores;
7. Obter a medida de separabilidade, $\eta^*$, a fim de estimar a qualidade da segmentação.

A Figura \@ref(fig:imagemOtsu)(a) mostra uma imagem de microscópio ótico de células polimerosomas e a Figura \@ref(fig:imagemOtsu)(b), seu histograma. O objetivo deste exemplo é segmentar as moléculas do fundo. A Figura \@ref(fig:imagemOtsu)(c) é o resultado pela limiarização global simples. Como o histograma não tem vales distintos e a diferença de intensidade entre o fundo e os objetos é pequena, o algoritmo não conseguiu alcançar a segmentação desejada. A Figura \@ref(fig:imagemOtsu)(d) mostra o resultado obtido pelo método de Otsu. Esse resultado, obviamente, é superior ao da Figura \@ref(fig:imagemOtsu)(c). O valor do limiar calculado pelo algoritmo simples foi o de $169$, enquanto o limiar calculado pelo método de Otsu era o de $181$, que está mais próximo das áreas mais claras da imagem que define as células. A medida de separabilidade $\eta$ foi $0.467$.

(ref:imagemOtsu) (a) Imagem original. (b) Histograma (os picos elevados foram cortados para realçar os detalhes nos valores mais baixos). (c) Resultado da segmentação pela limiarização global simples. (d) Resultado da segmentação pelo método de Otsu. [@gonzalez2010, p. 492]

```{r imagemOtsu, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemOtsu)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemOtsu.png'))
```


### Uso de suavização para limiarização
O objetivo da suavização é tentar separar os histogramas de imagens ruidosas, que tendem a ser unimodais, em modos com vales mais profundos; pois, quanto mais profundo o vale, melhor será a segmentação da imagem. 

Atente-se ao tipo de média e ao tamanho do *kernel*, aconselha-se o filtro gaussiano, pois ele minimiza o borramento de fronteira, e suaviza o ruído ainda que de maneira mais branda do que um filtro de média.

A Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(a) mostra uma imagem ruidosa, a Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(b) mostra seu histograma, a Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(c) mostra o resultado do método de Otsu. Já a Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(d) mostra a imagem da Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(a) suavizada usando uma máscara de média de tamanho 5x5 e a Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(e) é seu histograma e a Figura \@ref(fig:imagemSuavizacaoLimiarizacao)(f) é resultado da limiarização pelo método de Otsu.

(ref:imagemSuavizacaoLimiarizacao) Exemplo de suavização antes da aplicação do método de Otsu [@gonzalez2010, p. 493].

```{r imagemSuavizacaoLimiarizacao, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemSuavizacaoLimiarizacao)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemSuavizacaoLimiarizacao.png'))
```


Apesar do filtro de média poder nos ajudar, nem sempre será capaz disso. A Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem)(a) mostra uma imagem ruidosa e a Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem)(b) mostra o seu histograma, observe que o pontinho branco parece nem estar presente no histograma. E após aplicado o método de Otsu, a Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem)(c), observe que não foi obtida a segmentação desejada. Então, tentou-se um filtro de média 5x5, que reduz o ruído, Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem)(d). O resultado no histograma foi a redução do espalhamento do histograma, Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem)(e), mas a distribuição ainda é unimodal, resultando em falha na segmentação, o que é visto na Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem)(f).

(ref:ImagemSuavizacaoLimiarizacaoProblem) Exemplo de insucesso na segmentação por Otsu, mesmo com prévia suavização [@gonzalez2010, p. 493].

```{r ImagemSuavizacaoLimiarizacaoProblem, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:ImagemSuavizacaoLimiarizacaoProblem)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/ImagemSuavizacaoLimiarizacaoProblem.png'))
```

Portanto, note que, se a região que deseja segmentar for muito pequena em relação ao *background* e houver ruído, o que pode surgir na captura da imagem, a chance de não dar certo pelos métodos vistos é grande; pois, como os métodos que até agora vimos operam apenas no histograma da imagem, sem uso de maiores recursos. Como visto, imagens com essa característica, um mínimo ruído persiste e nem foi obtido um vale considerável entre as duas regiões. Isso pode ser atribuído ao fato de que a região é tão pequena que sua contribuição para o histograma é insignificante em comparação à intensidade da propagação causada pelo ruído [@gonzalez2010, p. 493]. A solução para isso é o uso de máscaras de borda, que será detalhado a seguir. 

### Uso de bordas para limiarização
Em uma imagem com ruído na qual a região a ser segmentada é muito pequena, é como se não houvesse aquela região e houvesse apenas o *background*. Isso é observado na aparência unimodal do histograma.

Portanto, fica difícil estimar um limiar ideal pelos algoritmos supracitados. E, como visto anteriormente, é preciso uma aparência bimodal para uma boa segmentação, então, precisamos de um histograma equilibrado; para isso, tomamos o histograma das bordas mais destacadas da imagem. Isso pode ser resumido em gerar uma máscara de gradiente ou laplaciano da imagem, limiarizá-la com um valor alto e usar como máscara para imagem original e prosseguir com o processo de segmentação do objeto a partir dessa amostra, pois, dessa forma, é gerado um histograma simétrico e com um vale destacado, porque, com a máscara de borda, a probabilidade de um píxel estar no *background* ou *foreground* tende a ser equilibrada [@gonzalez2010, p. 494]. 

O que se espera com os tipos de máscaras de borda, conforme visto no estudo detecção de bordas, é que a de gradiente produzirá bordas mais grossas e menor detecção aos ruídos da imagem, e a de laplace, bordas mais finas e maior detecção de ruídos, além de apresentar melhor custo computacional. Entretanto, é possível modificar este algoritmo para que tanto a magnitude do gradiente quanto o valor absoluto das imagens laplacianas sejam utilizadas; nesse caso, poderíamos especificar um limiar para cada imagem e formar a lógica OU dos dois resultados para obter a imagem marcadora, essa abordagem é útil quando se deseja ter mais controle sobre os pontos que foram considerados como sendo pontos válidos de borda [@gonzalez2010, p. 494].

Resumo das etapas de segmentação pela identificação de bordas do objeto [@gonzalez2010, p. 494]:

1. Calcular uma imagem de borda da imagem capturada, $f(x,y)$, ora como a magnitude do gradiente, ora como o valor absoluto do laplaciano, usando qualquer um dos métodos;

2. Especificar um valor de limiar, $T$;

3. Limiarizar a imagem a partir da Etapa 1, utilizando o limiar estabelecido na Etapa 2 para produzir uma imagem binária, $g_{T}(x,y)$. Esta imagem é usada como uma imagem de máscara na etapa seguinte para selecionar os pixels de $f(x,y)$ que correspondem aos pixels “fortes” da borda;

4. Calcular um histograma utilizando apenas os pixels de $f(x,y)$, que correspondem aos endereços de pixel avaliados com o número $1$ em $g_{T}(x,y)$;

5. Use o histograma da Etapa 4 para segmentar $f(x,y)$ globalmente, utilizando, por exemplo, o método de Otsu.

A Figura \@ref(fig:imagemLimiarizGradiente)(a) e (b) mostram as mesmas imagens da Figura \@ref(fig:ImagemSuavizacaoLimiarizacaoProblem) e seu histograma. Vimos que essa imagem não adianta ser suavizada. Entretanto, usamos a estratégia de máscara de borda que obteve um ótimo resultado. A Figura \@ref(fig:imagemLimiarizGradiente)(c) mostra o gradiente já limiarizado, A Figura \@ref(fig:imagemLimiarizGradiente)(d) e (e) mostra a máscara multiplicada a imagem original, que tem um histograma mais relevante à segmentação. E a Figura \@ref(fig:imagemLimiarizGradiente)(f) mostra o resultado da segmentação pelo novo histograma, \@ref(fig:imagemLimiarizGradiente)(e), através do Método de Otsu. O limiar foi de $134$, que fica aproximadamente a meio caminho entre os picos no histograma.

(ref:imagemLimiarizGradiente) Exemplo de limiarização por meio da máscara de borda do gradiente [@gonzalez2010, p. 495].

```{r imagemLimiarizGradiente, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizGradiente)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizGradiente.png'))
```



Já a Figura \@ref(fig:imagemLimiarizLaplace)(a) e (b) mostra uma imagem de 8 bits de células de levedura e seu histograma. A tentativa em detectar em segmentar os pontos claros pelo método de Otsu sem prévia etapa não foi sucedida, embora o método seja capaz de isolar algumas das regiões das células muitas da regiões segmentadas à direita não estão separadas. O limiar calculado foi de $42$ e a medida de separabilidade foi de $0.636$.  
A Figura \@ref(fig:imagemLimiarizLaplace) (d) mostra a imagem $g_T(x,y)$ obtida pelo cálculo do valor absoluto da imagem laplaciana e a limiarização com $T$ definido a $115$ em uma escala de intensidade no intervalo $[0, 255]$. Este valor de $T$ corresponde aproximadamente ao percentil $99.5$ dos valores da imagem laplaciana absoluta; assim, a limiarização a este nível deve resultar em um conjunto de *pixels* reduzido, como mostra esta Figura. A Figura \@ref(fig:imagemLimiarizLaplace) (e) é o histograma dos *pixels* diferentes a zero no produto de (a) e (d). Finalmente a Figura \@ref(fig:imagemLimiarizLaplace) (f) mostra o resultado da segmentação global da imagem original utilizando o método de Otsu baseado no histograma da Figura \@ref(fig:imagemLimiarizLaplace) (e). Este resultado está de acordo com as localizações dos pontos claros na imagem. O limiar calculado pelo método de Otsu foi $115$ e a medida de separabilidade foi de $0.762$, sendo que ambos são superiores aos valores obtidos utilizando o histograma original [@gonzalez2010, p. 495].

(ref:imagemLimiarizLaplace) Exemplo de limiarização por meio da máscara de borda laplaciana [@gonzalez2010, p. 496].

```{r imagemLimiarizLaplace, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizLaplace)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizLaplace.png'))
```



### Limiares Múltiplos

A diferença entre os limiares múltiplos e o que vimos até agora é que se usa mais de um limiar para segmentar a imagem a fim de produzir uma melhor medida de separabilidade entre as classes, por conseguinte, melhor segmentação.
Entretanto, como as aplicações que requerem mais de dois limiares, geralmente, são resolvidas com mais do que apenas valores de intensidade. Ao invés disso, o caminho é usar descritores adicionais (por exemplo, cor) e o problema é moldado para reconhecimento de padrões, como explicado a seguir em [limiarização baseada em diversas variáveis](#limiarização-baseada-em-diversas-variáveis) [@gonzalez2010, p. 497].

No caso das classes $K, C_1, C_2, ..., C_K$, a variância entre classes se generaliza pela expressão \@ref(eq:varEntreClasses)
$$\sigma_{B}^{2} = \sum_{k=1}^K{P_k(m_k-m_G)^2}
(\#eq:varEntreClasses)$$
na qual
$$P_k = \sum_{i\in C_k}{p_i}
(\#eq:pK)$$
$$m_k = \frac{1}{P_k} \sum_{i \in C_k}{ip_i}
(\#eq:mediaAcumuladaToK)$$
As classes $K$ são separadas por $K-1$ limiares cujos valores, $k^*_1, k^*_2, ..., k^*_k-1$:
$$
\sigma_{B}^{2}(k^*_1, k^*_2, ..., k^*_{K-1}) =
\max_{0<k_1<k_2<...k_{n-1}<L-1}{\sigma_{B}^{2}(k_1, k_2, ..., k_{K-1})}
(\#eq:variosLimiares)$$

Como observado na Equação \@ref(eq:variosLimiares), o valor máximo é obtido por testes com todas as possibilidades de valores para cada limiar, mas não faz sentido assumir limiares para $0$ e $L-1$, pois são os extremos da faixa de intensidade.

Também pode ser feito a avaliação de sua medida de separabilidade, Equação \@ref(eq:separabilidadeLimiaresMult). Como exemplo, tomemos um histograma com três classes. [@gonzalez2010, p. 497] 

$$\eta(k^*_1, k^*_2) = \frac{\sigma^2_{B}(k^*_1,k^*_2)}{\sigma^2_{G}}
(\#eq:separabilidadeLimiaresMult)$$

A Figura \@ref(fig:imagemLimiarizacaoMult)(a) mostra a imagem de um *iceberg*. É notório que será possível dividí-la com dois limiares^[A limiarização com dois limiares às vezes é chamada histerese de limiarização.] a partir das predominâncias de três grupos de intensidade. Olhando no histograma, \@ref(fig:imagemLimiarizacaoMult)(b), pelos vales bem destacados também é observado isso. Encontra-se pelo método de Otsu dois limiares, $80$ e $177$, com uma excelente medida de separabilidade de $0.954$. Limiarizando a Figura \@ref(fig:imagemLimiarizacaoMult)(a) o resultado que se obtém é uma segmentação muito boa, Figura \@ref(fig:imagemLimiarizacaoMult)(c) [@gonzalez2010, p. 498].

(ref:imagemLimiarizacaoMult) (a) Imagem de um *iceberg*. (b) Histograma. (c) Imagem segmentada em três regiões usando os limiares duplos de Otsu. [@gonzalez2010, p. 496]

```{r imagemLimiarizacaoMult, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizacaoMult)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizacaoMult.png'))
```

### Limiarização variável
Vimos perante subseções anteriores, que fatores como ruído e iluminação são impecílios para uma boa segmentação. Também foi visto que suavização e informações das bordas podem ser usadas para resolver isto. No entanto, é frequente o caso que essas estratégias são ineficientes ou nem possíveis. Como solução para tal, usamos limiares variáveis.

#### Particionamento da imagem
O particionamento da imagem consiste em fracionar a imagem em retângulos suficientemente pequenos de maneira que eles tenham iluminação e refletância uniformes e aplicar o método de Otsu em cada um deles. O sucesso do método é análogo ao da máscara de bordas, ele produz, para cada fração, histogramas simétricos com vales profundos [@gonzalez2010, p. 498].

A Figura \@ref(fig:imagemLimiarizacaoVariavel)(a) e (b) mostra uma imagem e seu histograma. Pelo seu histograma é plausível que não resultaria em uma boa segmentação, seja pelo método de Otsu, Figura \@ref(fig:imagemLimiarizacaoVariavel)(c) ou pelo método iterativo, Figura \@ref(fig:imagemLimiarizacaoVariavel)(d). Após fracionada a imagem, Figura \@ref(fig:imagemLimiarizacaoVariavel)(e), a segmentação por Otsu teve sucesso, Figura \@ref(fig:imagemLimiarizacaoVariavel)(f). [@gonzalez2010, p. 498]

(ref:imagemLimiarizacaoVariavel) Exemplo da técnica de particionamento da imagem [@gonzalez2010, p. 498].

```{r imagemLimiarizacaoVariavel, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizacaoVariavel)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizacaoVariavel.png'))
```


(ref:imagemHistoVari) Representa o histograma das subimagens da Figura \@ref(fig:imagemLimiarizacaoVariavel)(e) [@gonzalez2010, p. 498].

```{r imagemHistoVari, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemHistoVari)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemHistoVari.png'))
```

#### Limiarização variável baseada nas propriedades locais da imagem
A limiarização variável baseada nas propriedades locais da imagem é uma técnica em que se calcula um limiar para cada ponto, $(x,y)$, com base em uma ou mais propriedades calculadas em sua vizinhança. Apesar disso parecer trabalhoso, os algoritmos e hardwares modernos permitem o processamento rápido da vizinhança, especialmente para as funções comuns, como as operações lógicas e aritméticas [@gonzalez2010, p. 499].
Utilizaremos como abordagem básica duas propriedades, $\sigma_{xy}(x,y)$ e $m_{xy}(x,y)$, já que indicam o grau de contraste e intensidade média na vizinhança.

Seguem cálculos da limiarização usando apenas a intensidade do ponto, sendo $T_{xy}$, o limiar local. As equações seguintes, \@ref(eq:limLocal) e \@ref(eq:limLocalGlobal) são formas comuns de limiares variáveis locais [@gonzalez2010, p. 499]:

$$T_{xy} = a\sigma_{xy} + bm_{xy}
(\#eq:limLocal)$$
em que $a$ e $b$ são constantes não negativas, e
$$T_{xy} = a\sigma_{xy} + bm_{G}
(\#eq:limLocalGlobal)$$
na qual $m_G$ é a média global da imagem.

Também pode ser usado predicados a fim de determinar o limiar, $T_{xy}$, de segmentação. No entanto, o preço dessa limiarização mais rebuscada é um aumento no custo computacional [@gonzalez2010, p. 499]. E a imagem de saída, $g_{xy}$, pode ser representada como a Equação \@ref(eq:outputLimLocal):

$$g(x,y) =
\begin{cases}
  1,\ se\ f(x,y) > a\sigma_{xy}\ \ E\ \ f(x,y) > bm_{xy}\\
  0,\ caso\ contrário
\end{cases}
(\#eq:outputLimLocal)$$


A Figura \@ref(fig:imagemLimiarizVariavel)(a) é a imagem de células de levedura da Figura anterior \@ref(fig:imagemLimiarizLaplace)(a). A Figura \@ref(fig:imagemLimiarizVariavel)(b) é um exemplo da segmentação da Figura \@ref(fig:imagemLimiarizVariavel)(a) com dois limiares. Entretanto, note que as células do canto superior direito foram segmentadas de forma unida. A Figura \@ref(fig:imagemLimiarizVariavel)(c) é a imagem dos desvios padrão locais da vizinhança de tamanho 3x3 de cada píxel. E foi escolhida a média global ao invés da local, pois geralmente produz melhores resultados quando o fundo é quase constante e todas as intensidades de objeto estão acima ou abaixo da intensidade do fundo. Os pesos $a=30$ e $b=1.5$ foram assumidos. E, por fim, foi limiarizada pelo predicado exemplificado na Equação \@ref(eq:limLocalGlobal) e não pela intensidade de um ponto, Figura \@ref(fig:imagemLimiarizVariavel)(d). 

(ref:imagemLimiarizVariavel) Exemplo de limiarização variável baseada nas propriedades locais [@gonzalez2010, p. 500].

```{r imagemLimiarizVariavel, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizVariavel)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizVariavel.png'))
```


#### Usando média de movimento
O método de médias móveis é usado geralmente quando os objetos de interesse são pequenos (ou finos) em relação ao tamanho da imagem, uma condição que as imagens de texto digitado ou manuscrito possuem [@gonzalez2010, p. 501]. Segundo Gonzalez, essa aplicação é muito útil no processamento de documentos [@gonzalez2010, p. 500]. O procedimento consiste em um *kernel* 1D que percorre a imagem linha por linha e calcula média móvel com base em um intervalo de um dado tamanho fixo. A regra inicial é usar um intervalo de tamanho cinco vezes maior que a largura média do objeto que deseja limiarizar [@gonzalez2010, p. 501].

Digamos que $z_{k+1}$ denota a intensidade do ponto encontrado na sequência de digitalização na Etapa $k+1$. A média móvel (intensidade média) com este novo ponto é dada pela Equação \@ref(eq:mediasMoveis)
$$\begin{split}
m(k+1) 
& = \frac{1}{n} \sum_{i = k+2-n}^{k+1}{z_i}\\
& = m(k) + \frac{1}{n}(z_{k+1} - z_{k-n})
\end{split}
(\#eq:mediasMoveis)$$

na qual $n$ é o tamanho do intervalo ou número de pixels utilizados no cálculo da média e $m(1)=\frac{z_1}{n}$. Este valor inicial não é rigorosamente correto porque a média de um único ponto é o valor do ponto em si. No entanto, o usamos para que cálculos especiais não sejam necessários quando é executada pela primeira vez. Já que a média móvel é calculada para cada ponto da imagem, a segmentação é baseada no limiar $T_{xy}=bm_{xy}$, em que $b$ é constante e $m_{xy}$ é a média móvel no ponto $(x,y)$ na imagem de entrada [@gonzalez2010, p. 500]. A diferença desse método ao explicado anteriormente, [limiarização variável baseada nas propriedades locais da imagem]^(limiarização-variável-baseada-nas-propriedades-locais-da-imagem), é que, neste, usa-se  um *kernel* 1D que avalia linha por linha da imagem pegando amostras de uma certa quantidade de pixels, na qual, conforme mencionado anteriormente neste tópico, a quantidade de pixels tem que ser cinco vezes mais larga que a largura do objeto que se deseja segmentar.

Na Figura \@ref(fig:imagemMediaMovel1)(a) mostra uma imagem de texto escrito à mão sombreada por um padrão de intensidade. Esta forma de sombreamento de intensidade é típica de imagens obtidas com um *flash* fotográfico. A Figura \@ref(fig:imagemMediaMovel1)(b) é o resultado da segmentação pela limiarização global de Otsu. A Figura \@ref(fig:imagemMediaMovel1)(b) mostra uma segmentação bem sucedida com limiarização local usando médias móveis, usando $n=20$, já que a largura média do traço era de $4$ pixels, e $b=0.5$.

(ref:imagemMediaMovel1) Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de flash fotográfico. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. [@gonzalez2010, p. 501].

```{r imagemMediaMovel1, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemMediaMovel1)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemMediaMovel1.png'))
```


Já na Figura \@ref(fig:imagemMediaMovel2)(a) mostra uma imagem de texto escrito à mão corrompida por um sombreamento senoidal. Esta forma de sombreamento de intensidade é típica de quando o fornecimento de energia em um digitalizador de documentos não é apropriado. A Figura \@ref(fig:imagemMediaMovel2)(a) é a imagem original, a Figura \@ref(fig:imagemMediaMovel2)(b) é o resultado da limiarização por Otsu e a Figura \@ref(fig:imagemMediaMovel2)(c) é o resultado pela  média móvel. Os parâmetros utilizados foram o mesmo do anterior, sendo $n=20$ e $b=0.5$, o que mostra relativa robustez do método.

(ref:imagemMediaMovel2) Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de problemas em *scanner* em que o fornecimento de energia não é o apropriado. (a) Imagem original. (b) Imagem original aplicado o método de Otsu. (c) Imagem original aplicado método de médias móveis. [@gonzalez2010, p. 502].

```{r imagemMediaMovel2, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemMediaMovel2)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemMediaMovel2.png'))
```

### Limiarização baseada em diversas variáveis
Até agora, falamos apenas da limiarização baseada em uma única variável: intensidade dos tons de cinza. Em alguns casos, um sensor pode disponibilizar mais de uma variável para identificar cada pixel em uma imagem e, assim, permitir uma limiarização multivariada.
Um exemplo notável é a imagem em cores, na qual os componentes são vermelho (R), verde (G) e azul (B). Neste caso, cada “pixel” é identificado por três
valores e pode ser representado como um vetor 3-D, $z = (z_1+z_2+z_3)^T$, cujos componentes são as cores RGB em um ponto. Estes pontos 3-D são frequentemente chamados de voxels para denotar elementos volumétricos em oposição aos elementos de imagem [@gonzalez2010, p. 501].

Numa limiarização focada na intensidade de cinza, de apenas uma variável, avaliamos apenas a intensidade, um gráfico de duas variáveis (histograma convencional). A sua limiarização é simples. Já no R, G, B, gráfico tridimensional, avaliamos a distância dos pixels da imagem a um píxel de referência, e o limiar é representado pelo contorno de uma figura geométrica simétrica, como a esfera abaixo, na qual contém os pixels segmentados e tem como seu centro o pixel de referência. Conforme demonstrado na Figura \@ref(fig:imagemLimiarizMultiv).

(ref:imagemLimiarizMultiv) Segmentação multivariada no RGB. Gráfico 3-D [@gonzalez2010, p. 295].

```{r imagemLimiarizMultiv, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizMultiv)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizMultiv.png'))
```



Suponha que queiramos extrair de uma imagem colorida todas as regiões com uma faixa de cor específica: por exemplo, tons avermelhados da Figura \@ref(fig:imagemLimiarizMultiv2)(a). Vamos denotar a cor avermelhada média em que estamos interessados, a amostra da imagem é demarcada pelo retângulo de bordas claras e finais em Figura \@ref(fig:imagemLimiarizMultiv2) (a). Uma forma de segmentar uma imagem colorida com base neste parâmetro é calcular uma medida de distância, $D(z, a)$, entre um ponto de cor arbitrária, $z$, e a cor média, $a$ para assim segmentar. A Figura \@ref(fig:imagemLimiarizMultiv2)(b) mostra o resultado desse algoritmo.

$$ g=
\begin{cases}
  1,\ se\ D(z,a)\ <\ T\\
  0,\ caso\ contrário
\end{cases}
(\#eq:limVariaveisOutput)$$

(ref:imagemLimiarizMultiv2) Exemplo de segmentação multivariada no RGB [@gonzalez2010, p. 295].

```{r imagemLimiarizMultiv2, echo=FALSE, fig.asp=.7, fig.width= 4, fig.cap='(ref:imagemLimiarizMultiv2)', fig.align='center', out.width='55%'}
knitr::include_graphics(rep('imagens/06-segmentacao/imagemLimiarizMultiv2.png'))
```

Porém, esse cálculo de distância dos pontos ao centro em formato esférico é trabalhoso para o computador. Uma maneira mais eficiente é usar um delimitador cúbico. Nessa metodologia, o cubo é centralizado em $a$ e suas dimensões ao longo de cada um dos eixos de cor são escolhidas em proporção ao desvio padrão das amostras da imagem ao longo de cada um dos eixos (R, G e B).

Portanto, o procedimento da Figura \@ref(fig:imagemLimiarizMultiv2)(a) consistiu em calcular o vetor médio $a$ utilizando os pontos de cor contidos no retângulo. Em seguida, calculou-se o desvio padrão dos componentes vermelho, verde e azul dessas amostras. Um cubo foi centralizado em $a$, e as dimensões ao longo de cada um dos eixos RGB são o valor de $1.25$ multiplicado pelo $\sigma$ ao longo dos eixos correspondentes, por exemplo, no eixo $R$, vermelho, a dimensão do cubo é de $(a_R - 1.25\sigma_R)$ até $(a_R + 1.25\sigma_R)$, no qual $a_R$ indica o valor do componente vermelho de $a$. E, por fim, limiarizou-se a Figura.
