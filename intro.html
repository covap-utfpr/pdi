<!DOCTYPE html>
<html lang="pt-BR" xml:lang="pt-BR">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 1 Introdução | Material introdutório de Processamento Digital de Imagens e Visão Computacional</title>
  <meta name="description" content="Capítulo 1 Introdução | Material introdutório de Processamento Digital de Imagens e Visão Computacional" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 1 Introdução | Material introdutório de Processamento Digital de Imagens e Visão Computacional" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 1 Introdução | Material introdutório de Processamento Digital de Imagens e Visão Computacional" />
  
  
  

<meta name="author" content="" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="formacaoImagem.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="logo"><a href="./"><img src="imagens/logo.jpeg"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Início</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#relação-entre-processamento-digital-de-imagem-visão-computacional-e-computação-gráfica"><i class="fa fa-check"></i><b>1.1</b> Relação entre Processamento Digital de Imagem, Visão Computacional e Computação Gráfica</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#etapas-do-processamento-de-imagens-visão-computacional-e-aprendizado-de-máquina"><i class="fa fa-check"></i><b>1.2</b> Etapas do Processamento de Imagens, Visão Computacional e Aprendizado de Máquina</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#áreas-de-aplicações"><i class="fa fa-check"></i><b>1.3</b> Áreas de Aplicações</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="formacaoImagem.html"><a href="formacaoImagem.html"><i class="fa fa-check"></i><b>2</b> Formação da imagem</a><ul>
<li class="chapter" data-level="2.1" data-path="formacaoImagem.html"><a href="formacaoImagem.html#câmera-pinhole-e-geometria"><i class="fa fa-check"></i><b>2.1</b> Câmera <em>pinhole</em> e geometria</a></li>
<li class="chapter" data-level="2.2" data-path="formacaoImagem.html"><a href="formacaoImagem.html#lentes-finas"><i class="fa fa-check"></i><b>2.2</b> Lentes Finas</a></li>
<li class="chapter" data-level="2.3" data-path="formacaoImagem.html"><a href="formacaoImagem.html#sensor"><i class="fa fa-check"></i><b>2.3</b> Sensor</a></li>
<li class="chapter" data-level="2.4" data-path="formacaoImagem.html"><a href="formacaoImagem.html#amostragem-e-quantização"><i class="fa fa-check"></i><b>2.4</b> Amostragem e Quantização</a><ul>
<li class="chapter" data-level="2.4.1" data-path="formacaoImagem.html"><a href="formacaoImagem.html#amostragem"><i class="fa fa-check"></i><b>2.4.1</b> Amostragem</a></li>
<li class="chapter" data-level="2.4.2" data-path="formacaoImagem.html"><a href="formacaoImagem.html#quantização"><i class="fa fa-check"></i><b>2.4.2</b> Quantização</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="formacaoImagem.html"><a href="formacaoImagem.html#formacaoImg"><i class="fa fa-check"></i><b>2.5</b> Definição de imagem digital</a></li>
<li class="chapter" data-level="2.6" data-path="formacaoImagem.html"><a href="formacaoImagem.html#resolução-espacial-e-de-intensidade"><i class="fa fa-check"></i><b>2.6</b> Resolução espacial e de intensidade</a></li>
<li class="chapter" data-level="2.7" data-path="formacaoImagem.html"><a href="formacaoImagem.html#pixels"><i class="fa fa-check"></i><b>2.7</b> Pixels</a><ul>
<li class="chapter" data-level="2.7.1" data-path="formacaoImagem.html"><a href="formacaoImagem.html#vizin"><i class="fa fa-check"></i><b>2.7.1</b> Vizinhança</a></li>
<li class="chapter" data-level="2.7.2" data-path="formacaoImagem.html"><a href="formacaoImagem.html#contiv"><i class="fa fa-check"></i><b>2.7.2</b> Conectividade</a></li>
<li class="chapter" data-level="2.7.3" data-path="formacaoImagem.html"><a href="formacaoImagem.html#adja"><i class="fa fa-check"></i><b>2.7.3</b> Adjacência</a></li>
<li class="chapter" data-level="2.7.4" data-path="formacaoImagem.html"><a href="formacaoImagem.html#camin"><i class="fa fa-check"></i><b>2.7.4</b> Caminho</a></li>
<li class="chapter" data-level="2.7.5" data-path="formacaoImagem.html"><a href="formacaoImagem.html#componente-conexa"><i class="fa fa-check"></i><b>2.7.5</b> Componente Conexa</a></li>
<li class="chapter" data-level="2.7.6" data-path="formacaoImagem.html"><a href="formacaoImagem.html#borda-e-interior"><i class="fa fa-check"></i><b>2.7.6</b> Borda e Interior</a></li>
<li class="chapter" data-level="2.7.7" data-path="formacaoImagem.html"><a href="formacaoImagem.html#medidas-de-distância"><i class="fa fa-check"></i><b>2.7.7</b> Medidas de Distância</a></li>
<li class="chapter" data-level="2.7.8" data-path="formacaoImagem.html"><a href="formacaoImagem.html#operações-lógico-aritméticas"><i class="fa fa-check"></i><b>2.7.8</b> Operações Lógico-aritméticas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html"><i class="fa fa-check"></i><b>3</b> Transformacões geométricas</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#definição"><i class="fa fa-check"></i><b>3.1</b> Definição</a></li>
<li class="chapter" data-level="3.2" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#sistema-de-coordenadas-objetos-2d-e-3d"><i class="fa fa-check"></i><b>3.2</b> Sistema de coordenadas objetos (2D e 3D)</a></li>
<li class="chapter" data-level="3.3" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#representação-vetorial-e-matricial-de-imagens-digitalizadas"><i class="fa fa-check"></i><b>3.3</b> Representação Vetorial e Matricial de Imagens digitalizadas</a></li>
<li class="chapter" data-level="3.4" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#matrizes-em-computação-gráfica"><i class="fa fa-check"></i><b>3.4</b> Matrizes em Computação gráfica</a></li>
<li class="chapter" data-level="3.5" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#transformações-em-pontos-e-objetos"><i class="fa fa-check"></i><b>3.5</b> Transformações em Pontos e Objetos</a></li>
<li class="chapter" data-level="3.6" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#transformação-de-translação"><i class="fa fa-check"></i><b>3.6</b> Transformação de Translação</a></li>
<li class="chapter" data-level="3.7" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#transformação-de-escala"><i class="fa fa-check"></i><b>3.7</b> Transformação de Escala</a></li>
<li class="chapter" data-level="3.8" data-path="transformacoesGeometricas.html"><a href="transformacoesGeometricas.html#transformação-de-rotação"><i class="fa fa-check"></i><b>3.8</b> Transformação de Rotação</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html"><i class="fa fa-check"></i><b>4</b> Transformações radiométricas</a><ul>
<li class="chapter" data-level="4.1" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html#transformação-linear"><i class="fa fa-check"></i><b>4.1</b> Transformação Linear</a></li>
<li class="chapter" data-level="4.2" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html#transformação-logarítmica"><i class="fa fa-check"></i><b>4.2</b> Transformação Logarítmica</a></li>
<li class="chapter" data-level="4.3" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html#transformação-de-potência"><i class="fa fa-check"></i><b>4.3</b> Transformação de Potência</a></li>
<li class="chapter" data-level="4.4" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html#processamento-de-histograma"><i class="fa fa-check"></i><b>4.4</b> Processamento de histograma</a></li>
<li class="chapter" data-level="4.5" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html#equalização-do-histograma"><i class="fa fa-check"></i><b>4.5</b> Equalização do histograma</a></li>
<li class="chapter" data-level="4.6" data-path="transformacoesRadiometricas.html"><a href="transformacoesRadiometricas.html#especificação-de-histograma"><i class="fa fa-check"></i><b>4.6</b> Especificação de histograma</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="filtros.html"><a href="filtros.html"><i class="fa fa-check"></i><b>5</b> Filtros Digitais</a><ul>
<li class="chapter" data-level="5.1" data-path="filtros.html"><a href="filtros.html#convolução"><i class="fa fa-check"></i><b>5.1</b> Convolução</a><ul>
<li class="chapter" data-level="5.1.1" data-path="filtros.html"><a href="filtros.html#definção-matemática-da-convolução"><i class="fa fa-check"></i><b>5.1.1</b> Definção matemática da convolução</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="filtros.html"><a href="filtros.html#filtro-da-média"><i class="fa fa-check"></i><b>5.2</b> Filtro da Média</a></li>
<li class="chapter" data-level="5.3" data-path="filtros.html"><a href="filtros.html#filtro-da-mediana"><i class="fa fa-check"></i><b>5.3</b> Filtro da Mediana</a></li>
<li class="chapter" data-level="5.4" data-path="filtros.html"><a href="filtros.html#filtro-gaussiano"><i class="fa fa-check"></i><b>5.4</b> Filtro Gaussiano</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="segmentacao.html"><a href="segmentacao.html"><i class="fa fa-check"></i><b>6</b> Segmentação</a><ul>
<li class="chapter" data-level="6.1" data-path="segmentacao.html"><a href="segmentacao.html#detecção-por-descontinuidade"><i class="fa fa-check"></i><b>6.1</b> Detecção por descontinuidade</a><ul>
<li class="chapter" data-level="6.1.1" data-path="segmentacao.html"><a href="segmentacao.html#detecção-de-pontos-isolados"><i class="fa fa-check"></i><b>6.1.1</b> Detecção de pontos isolados</a></li>
<li class="chapter" data-level="6.1.2" data-path="segmentacao.html"><a href="segmentacao.html#detecção-de-linhas"><i class="fa fa-check"></i><b>6.1.2</b> Detecção de linhas</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="segmentacao.html"><a href="segmentacao.html#detecção-de-bordas"><i class="fa fa-check"></i><b>6.2</b> Detecção de Bordas</a><ul>
<li class="chapter" data-level="6.2.1" data-path="segmentacao.html"><a href="segmentacao.html#modelos-de-bordas"><i class="fa fa-check"></i><b>6.2.1</b> Modelos de Bordas</a></li>
<li class="chapter" data-level="6.2.2" data-path="segmentacao.html"><a href="segmentacao.html#método-do-gradiente-roberts-prewitt-sobel"><i class="fa fa-check"></i><b>6.2.2</b> Método do gradiente (Roberts, Prewitt, Sobel)</a></li>
<li class="chapter" data-level="6.2.3" data-path="segmentacao.html"><a href="segmentacao.html#método-de-marr-hildreth"><i class="fa fa-check"></i><b>6.2.3</b> Método de Marr-Hildreth</a></li>
<li class="chapter" data-level="6.2.4" data-path="segmentacao.html"><a href="segmentacao.html#método-de-canny"><i class="fa fa-check"></i><b>6.2.4</b> Método de Canny</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="segmentacao.html"><a href="segmentacao.html#transformada-de-hough"><i class="fa fa-check"></i><b>6.3</b> Transformada de Hough</a><ul>
<li class="chapter" data-level="6.3.1" data-path="segmentacao.html"><a href="segmentacao.html#transformada-de-hough-para-detecção-de-linhas"><i class="fa fa-check"></i><b>6.3.1</b> Transformada de Hough para detecção de linhas</a></li>
<li class="chapter" data-level="6.3.2" data-path="segmentacao.html"><a href="segmentacao.html#transformada-de-hough-para-detecção-de-círculos"><i class="fa fa-check"></i><b>6.3.2</b> Transformada de Hough para detecção de círculos</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="segmentacao.html"><a href="segmentacao.html#detecção-de-quinas"><i class="fa fa-check"></i><b>6.4</b> Detecção de Quinas</a><ul>
<li class="chapter" data-level="6.4.1" data-path="segmentacao.html"><a href="segmentacao.html#detector-de-quinas-de-moravec"><i class="fa fa-check"></i><b>6.4.1</b> Detector de Quinas de Moravec</a></li>
<li class="chapter" data-level="6.4.2" data-path="segmentacao.html"><a href="segmentacao.html#detector-de-quinas-de-harris"><i class="fa fa-check"></i><b>6.4.2</b> Detector de Quinas de Harris</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="segmentacao.html"><a href="segmentacao.html#detecção-de-blobs"><i class="fa fa-check"></i><b>6.5</b> Detecção de <em>Blobs</em></a><ul>
<li class="chapter" data-level="6.5.1" data-path="segmentacao.html"><a href="segmentacao.html#log"><i class="fa fa-check"></i><b>6.5.1</b> LoG</a></li>
<li class="chapter" data-level="6.5.2" data-path="segmentacao.html"><a href="segmentacao.html#dog"><i class="fa fa-check"></i><b>6.5.2</b> DoG</a></li>
<li class="chapter" data-level="6.5.3" data-path="segmentacao.html"><a href="segmentacao.html#doh"><i class="fa fa-check"></i><b>6.5.3</b> DoH</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="segmentacao.html"><a href="segmentacao.html#limiarização"><i class="fa fa-check"></i><b>6.6</b> Limiarização</a><ul>
<li class="chapter" data-level="6.6.1" data-path="segmentacao.html"><a href="segmentacao.html#limiarização-global-simples"><i class="fa fa-check"></i><b>6.6.1</b> Limiarização Global Simples</a></li>
<li class="chapter" data-level="6.6.2" data-path="segmentacao.html"><a href="segmentacao.html#limiarização-pelo-método-de-otsu"><i class="fa fa-check"></i><b>6.6.2</b> Limiarização pelo Método de Otsu</a></li>
<li class="chapter" data-level="6.6.3" data-path="segmentacao.html"><a href="segmentacao.html#uso-de-suavização-para-limiarização"><i class="fa fa-check"></i><b>6.6.3</b> Uso de suavização para limiarização</a></li>
<li class="chapter" data-level="6.6.4" data-path="segmentacao.html"><a href="segmentacao.html#uso-de-bordas-para-limiarização"><i class="fa fa-check"></i><b>6.6.4</b> Uso de bordas para limiarização</a></li>
<li class="chapter" data-level="6.6.5" data-path="segmentacao.html"><a href="segmentacao.html#limiares-múltiplos"><i class="fa fa-check"></i><b>6.6.5</b> Limiares Múltiplos</a></li>
<li class="chapter" data-level="6.6.6" data-path="segmentacao.html"><a href="segmentacao.html#limiarização-variável"><i class="fa fa-check"></i><b>6.6.6</b> Limiarização variável</a></li>
<li class="chapter" data-level="6.6.7" data-path="segmentacao.html"><a href="segmentacao.html#limiarização-baseada-em-diversas-variáveis"><i class="fa fa-check"></i><b>6.6.7</b> Limiarização baseada em diversas variáveis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="deepLearning.html"><a href="deepLearning.html"><i class="fa fa-check"></i><b>7</b> Deep Learning em visão computacional</a><ul>
<li class="chapter" data-level="7.1" data-path="deepLearning.html"><a href="deepLearning.html#caracterização-de-ia-machine-learning-e-deep-learning"><i class="fa fa-check"></i><b>7.1</b> Caracterização de IA, Machine Learning e Deep Learning</a><ul>
<li class="chapter" data-level="7.1.1" data-path="deepLearning.html"><a href="deepLearning.html#aprendizado-supervisionado-e-não-supervisionado"><i class="fa fa-check"></i><b>7.1.1</b> Aprendizado supervisionado e não supervisionado</a></li>
<li class="chapter" data-level="7.1.2" data-path="deepLearning.html"><a href="deepLearning.html#redes-neurais-artificiais"><i class="fa fa-check"></i><b>7.1.2</b> Redes Neurais Artificiais</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="deepLearning.html"><a href="deepLearning.html#cnn"><i class="fa fa-check"></i><b>7.2</b> Redes neurais convolucionais (CNN)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="deepLearning.html"><a href="deepLearning.html#blocos-de-construção-de-uma-cnn"><i class="fa fa-check"></i><b>7.2.1</b> Blocos de construção de uma CNN</a></li>
<li class="chapter" data-level="7.2.2" data-path="deepLearning.html"><a href="deepLearning.html#por-que-usar-convoluções"><i class="fa fa-check"></i><b>7.2.2</b> Por que usar convoluções</a></li>
<li class="chapter" data-level="7.2.3" data-path="deepLearning.html"><a href="deepLearning.html#redes-cnns-clássicas"><i class="fa fa-check"></i><b>7.2.3</b> Redes CNN’s clássicas</a></li>
<li class="chapter" data-level="7.2.4" data-path="deepLearning.html"><a href="deepLearning.html#aprendizado-por-transferência"><i class="fa fa-check"></i><b>7.2.4</b> Aprendizado por transferência</a></li>
<li class="chapter" data-level="7.2.5" data-path="deepLearning.html"><a href="deepLearning.html#redes-neurais-na-prática"><i class="fa fa-check"></i><b>7.2.5</b> Redes neurais na prática</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="deepLearning.html"><a href="deepLearning.html#redes-neurais-siamesas"><i class="fa fa-check"></i><b>7.3</b> Redes Neurais Siamesas</a><ul>
<li class="chapter" data-level="7.3.1" data-path="deepLearning.html"><a href="deepLearning.html#arquitetura"><i class="fa fa-check"></i><b>7.3.1</b> Arquitetura</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="separacaoFundo.html"><a href="separacaoFundo.html"><i class="fa fa-check"></i><b>8</b> Separação Plano de Fundo</a><ul>
<li class="chapter" data-level="8.1" data-path="separacaoFundo.html"><a href="separacaoFundo.html#fixo"><i class="fa fa-check"></i><b>8.1</b> Fixo</a></li>
<li class="chapter" data-level="8.2" data-path="separacaoFundo.html"><a href="separacaoFundo.html#média-temporal"><i class="fa fa-check"></i><b>8.2</b> Média Temporal</a></li>
<li class="chapter" data-level="8.3" data-path="separacaoFundo.html"><a href="separacaoFundo.html#mediana-temporal"><i class="fa fa-check"></i><b>8.3</b> Mediana Temporal</a></li>
<li class="chapter" data-level="8.4" data-path="separacaoFundo.html"><a href="separacaoFundo.html#exemplos-comparativos-da-média-temporal-média-espaço-temporal-e-mediana-temporal"><i class="fa fa-check"></i><b>8.4</b> Exemplos comparativos da Média Temporal, Média Espaço-Temporal e Mediana Temporal</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="espaco3D.html"><a href="espaco3D.html"><i class="fa fa-check"></i><b>9</b> Espaço 3D</a><ul>
<li class="chapter" data-level="9.1" data-path="espaco3D.html"><a href="espaco3D.html#geometria-projetiva"><i class="fa fa-check"></i><b>9.1</b> Geometria projetiva</a><ul>
<li class="chapter" data-level="9.1.1" data-path="espaco3D.html"><a href="espaco3D.html#homogenea"><i class="fa fa-check"></i><b>9.1.1</b> Coordenadas homogêneas</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="espaco3D.html"><a href="espaco3D.html#homografia"><i class="fa fa-check"></i><b>9.2</b> Homografia</a><ul>
<li class="chapter" data-level="9.2.1" data-path="espaco3D.html"><a href="espaco3D.html#transformação-linear-direta-dlt"><i class="fa fa-check"></i><b>9.2.1</b> Transformação Linear Direta (DLT)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="espaco3D.html"><a href="espaco3D.html#transformações-de-câmera"><i class="fa fa-check"></i><b>9.3</b> Transformações de câmera</a></li>
<li class="chapter" data-level="9.4" data-path="espaco3D.html"><a href="espaco3D.html#distorção-das-lentes"><i class="fa fa-check"></i><b>9.4</b> Distorção das lentes</a></li>
<li class="chapter" data-level="9.5" data-path="espaco3D.html"><a href="espaco3D.html#calibração"><i class="fa fa-check"></i><b>9.5</b> Calibração</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="refêrencias.html"><a href="refêrencias.html"><i class="fa fa-check"></i>Refêrencias</a></li>
<li class="divider"></li>
<li><center>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
<img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" />
</a></li></center>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Material introdutório de Processamento Digital de Imagens e Visão Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Capítulo 1</span> Introdução</h1>
<div id="relação-entre-processamento-digital-de-imagem-visão-computacional-e-computação-gráfica" class="section level2">
<h2><span class="header-section-number">1.1</span> Relação entre Processamento Digital de Imagem, Visão Computacional e Computação Gráfica</h2>
<p>A visão desempenha um papel importante na vida das pessoas, pois com ela é possível uma percepção incrivelmente rica do mundo ao seu redor. Para tentar reproduzir as capacidades visuais humanas por sistemas autônomos manipulados por computadores foram desenvolvidas pelo menos três grandes áreas <span class="citation">[<a href="#ref-velho2009" role="doc-biblioref">1</a>, p. 2]</span>: <em>Processamento Digital de Imagens</em> (PDI), <em>Visão Computacional</em> (VC) e a <em>Computação Gráfica</em>(CG), apresentados na Figura <a href="intro.html#fig:areasPDI">1.1</a>. Essas áreas, apesar de serem correlacionadas, têm objetivos e métodos diferentes o que justifica a importância de distingui-las.</p>

<div class="figure" style="text-align: center"><span id="fig:areasPDI"></span>
<img src="imagens/01-introducao/areasPDI.png" alt="Processos Computacionais com Imagens - O processamento de imagem, a visão computacional e a computação gráfica são áreas que operam com imagens digitais. Estas áreas têm propósitos diferentes, mas podem ser relacionadas, pois a saída do processamento de uma pode ser a entrada de outra. [1, p. 2]." width="40%" />
<p class="caption">
Figura 1.1: Processos Computacionais com Imagens - O processamento de imagem, a visão computacional e a computação gráfica são áreas que operam com imagens digitais. Estas áreas têm propósitos diferentes, mas podem ser relacionadas, pois a saída do processamento de uma pode ser a entrada de outra. <span class="citation">[<a href="#ref-velho2009" role="doc-biblioref">1</a>, p. 2]</span>.
</p>
</div>
<p>O <em>Processamento Digital de Imagens</em> (PDI) busca realizar o pré-processamento das imagens, utilizando para isso técnicas de tratamento, como a correção da iluminação, eliminação de ruído, e a segmentação. Geralmente, no PDI tanto a entrada quanto a saída do processo são imagens. O foco da <em>Visão Computacional</em> (VC) é a análise das imagens, identificando os seus componentes e obtendo informações de modelos gerados, principalmente do mundo 3D. Diferente da VC, em que as imagens representam o objeto de estudo, na <em>Computação Gráfica</em> (CG), as imagens são o resultado do processo. Na CG são geradas representações visuais seguindo descrições e especificações geométricas de modelos de entrada <span class="citation">[<a href="#ref-velho2009" role="doc-biblioref">1</a>, p. 3]</span>.</p>
<p>A Tabela <a href="intro.html#tab:processos">1.1</a> apresenta de forma resumida as diferenças entre PDI, VC e CG. Na segunda linha da tabela está uma descrição simples de cada área, e na terceira linha um esquema identificando o objeto e o produto de cada processo.</p>
<table>
<caption><span id="tab:processos">Tabela 1.1: </span> Processos Computacionais com Imagens - Descrição da aplicação das áreas de Computação Gráfica (CG), Visão Computacional (VC) e Processamento Digital. Na última linha está um esquema simplificado da entrada e saída de cada aplicação.</caption>
<colgroup>
<col width="34%" />
<col width="31%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Computação Gráfica (CG)</th>
<th align="center">Visão Computacional (VC)</th>
<th align="center">Processamento Digital de Imagens (PDI)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Cria e altera imagens a partir de dados.</td>
<td align="center">Análise de imagem para criação de modelos.</td>
<td align="center">Transformação de imagem (tratamento).</td>
</tr>
<tr class="even">
<td align="center">modelo → imagem</td>
<td align="center">imagem → modelo</td>
<td align="center">imagem → imagem</td>
</tr>
</tbody>
</table>
<p>As imagens tratadas em PDI têm como forte potencial servir de material para a Visão Computacional, como pode ser percebido
na Figura <a href="intro.html#fig:areasPDI">1.1</a>. Muitas vezes as áreas de Visão Computacional e PDI são confundidas devido a dificuldade em se definir em que ponto uma termina e a outra começa. Mesmo não existindo uma linha clara entre os limites destas duas áreas é possível utilizar um paradigma que considera três níveis de processamento <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 2]</span>:</p>
<ul>
<li><p><strong>Baixo nível</strong></p>
<p>A nível de pixel, realiza operações de pré-processamento, sendo utilizada, por exemplo, na redução de ruído, aumento de contraste e restauração. Nesta etapa tanto a entrada quanto a saída são imagens.</p></li>
<li><p><strong>Médio nível</strong></p>
<p>Operações mais complexas, como segmentação, partição e reconhecimento de objetos individuais. A entrada é uma imagem mas a saída pode ser um conjunto contendo os atributos extraídos das imagens, como formas, bordas e objetos individuais.</p></li>
<li><p><strong>Alto nível</strong></p>
<p>Interpretação do conteúdo da imagem e análise, muitas vezes processos associados com as funções da visão, como a classificação, o reconhecimento e o rastreamento de objetos.</p></li>
</ul>
<p>Baseado nesses níveis, iremos considerar que o processamento de imagem atua nos primeiros dois níveis, ou seja, envolve o pré-processamento e processos de extração de elementos de imagens até o reconhecimento de componentes individuais. O campo da Visão Computacional, mesmo associado com os níveis mais baixos, se torna mais evidente a partir das técnicas de alto nível de processamento, que utilizam informações extraídas das imagens para processos de inferências ou aprendizados, resultando em aplicações em diferentes áreas.</p>
<p>A VC por ser uma área que tenta emular as funções cognitivas associadas à visão se enquadra como um ramo da inteligência artificial (AI). O processo de aprendizado necessário para as diferentes vertentes da AI - Visão Computacional, Reconhecimento de Voz, Aprendizado Natural de Linguagem, Robótica, entre outros - dependem em grande parte da vertente do Aprendizado de Máquina ou <em>Machine Learning</em>. Assim, muitas técnicas de aprendizado de máquina são associadas com etapas de processamento de imagens dentro da Visão Computacional.</p>
<p>Com o avanço do aprendizado de máquina (<em>Machine Learning</em>), principalmente com o desenvolvimento do aprendizado profundo (<em>Deep Learning</em>), surgiu um novo paradigma na Visão Computacional. Anteriormente, as etapas da VC envolviam uma sequência de algoritmos de processamento de imagens construídos em diferentes softwares, específicos para um determinado fim, e que dificilmente se enquadravam em outros problemas. Com a adaptação de modelos de aprendizado profundo foi possível englobar todas as etapas de processamento e aprendizado em um único programa, e que muitas vezes pode ser estendido para diferentes aplicações.</p>
</div>
<div id="etapas-do-processamento-de-imagens-visão-computacional-e-aprendizado-de-máquina" class="section level2">
<h2><span class="header-section-number">1.2</span> Etapas do Processamento de Imagens, Visão Computacional e Aprendizado de Máquina</h2>
<p>Um dos objetivos deste material é servir de referência para o estudo inicial da Visão Computacional, assim, para compreender as relações entre os três temas discutidos no final do tópico anterior - Processamento de Imagens, Visão Computacional e Aprendizado de Máquina - indicamos um guia para o presente material de estudo, em que se descreve como os capítulos foram organizados dentro destes três temas mais amplos.</p>
<p>Com base na abordagem adotada no diagrama da Figura <a href="intro.html#fig:capitulos">1.2</a>, as principais etapas para o tratamento de problemas envolvem: aquisição da imagem; pré-processamento; segmentação; e análise da informação visual. Dentro de cada um destes níveis é possível subdividir vários outros subtópicos dependendo da aplicação de interesse, e neste material apresentamos algumas de usos mais gerais, que estão organizadas em capítulos.</p>

<div class="figure" style="text-align: center"><span id="fig:capitulos"></span>
<img src="imagens/01-introducao/capitulos.png" alt="Etapas para o desenvolvimento de aplicações na Visão Computacional - Diagrama com a distribuição dos capítulos com base nas principais etapas dentro do processamento de imagem e do aprendizado de máquina orientados à visão computacional." width="60%" />
<p class="caption">
Figura 1.2: Etapas para o desenvolvimento de aplicações na Visão Computacional - Diagrama com a distribuição dos capítulos com base nas principais etapas dentro do processamento de imagem e do aprendizado de máquina orientados à visão computacional.
</p>
</div>
<p>As primeiras etapas - Aquisição de imagens, Pré-Processamento e Segmentação - são temas que a área de Processamento de Imagem tem apresentado forte contribuição durante muito tempo, em que vários algoritmos, técnicas e conceitos continuam sendo a base para a Visão Computacional. Antigamente, os resultados do processamento de imagens que eram as informações de maior interesse da VC, eram dados tratados que podiam ser avaliados e aplicados em modelos estatísticos, possibilitando a análise e resolução do problema.</p>
<p>Com o surgimento de outros paradigmas, todas estas etapas que eram tratadas separadamente, com técnicas e softwares diferentes, passaram a ser tratadas dentro de um único sistema, utilizando modelos de aprendizado de máquina, como as redes neurais. Nesta nova abordagem, as imagens brutas também podem ser vistas como entradas diretas das aplicações. Por esta razão, tanto a Visão Computacional quanto o Aprendizado de Máquina tem as suas fronteiras na Figura <a href="intro.html#fig:capitulos">1.2</a> demarcando do início ao fim todos os processos.</p>
<p>Para destacar como os capítulos se relacionam com estas etapas será apresentado uma breve descrição de cada uma e alguns exemplos de conteúdos que serão abordados ao longo do material.</p>
<ul>
<li>Aquisição da imagem</li>
</ul>
<p>Captura a imagem por meio de um dispositivo ou sensor e a converte em uma imagem digitalizada <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 3]</span>. Podemos citar como exemplo as câmeras fotográficas, tomógrafos médicos, satélites e scanners. Na figura @ref(fig:componentes_2), temos um exemplo de imagem colorida separadas em suas três componentes, e mais detalhes sobre a aquisição e formação deste tipo de imagem e de outras são abordados no Capítulo <a href="formacaoImagem.html#formacaoImagem">Formação de Imagem</a>. Como será discutido no Capítulo <a href="espaco3D.html#espaco3D">Espaço 3D</a>, algumas aplicações da Visão computacional dependem de parâmetros determinados pelo equipamento e das condições durante a aquisição das imagens.</p>
<p>(ref:componentes_2) Imagem colorida - Imagem separada em seus três componentes, em que <em>Red</em> é a vermelha, <em>Green</em> é a verde e <em>Blue</em> é a azul <span class="citation">[<a href="#ref-moeslund2012" role="doc-biblioref">4</a>, p. 28]</span>.</p>
<div class="figure" style="text-align: center">
<img src="imagens/02-formacao/componentes.png" alt="(ref:componentes_2)" width="65%" />
<p class="caption">
(#fig:componentes_2)(ref:componentes_2)
</p>
</div>
<ul>
<li>Pré processamento</li>
</ul>
<p>Essa etapa busca realizar mudanças e ajustes na imagem visando melhorar seu uso nas etapas futuras <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 3]</span>. Como exemplo temos casos onde não precisamos das cores de uma imagem, podendo então realizar a conversão para <em>grayscale</em> (tons de cinza), ou precisamos gerar imagens coloridas. Além disso, podemos realizar cortes ou realces, isolando somente a parte de maior interesse na imagem utilizando algumas das técnicas apresentadas no Capítulo <a href="transformacoesGeometricas.html#transformacoesGeometricas">Transformações Geométricas</a> e no Capítulo <a href="transformacoesRadiometricas.html#transformacoesRadiometricas">Transformações Radiométricas</a>. Na Figura @ref(fig:placaEletronicaMediana_2) se destaca uma das abordagens recorrentes no tratamento de imagem, a atenuação de ruídos e a suavização, utilizando principalmente alguns dos filtros do Capítulo <a href="filtros.html#filtros">Filtros Digitais</a>.</p>
<p>(ref:placaEletronicaMediana_2) Remoção de ruído sal e pimenta por meio do filtro de Mediana - No Capítulo <a href="filtros.html#filtros">Filtros Digitais</a> serão apresentados alguns filtros como este que tratam as imagens, por exemplo, revomendo ruídos, aumentando o realce ou suavizando<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 103]</span>.</p>
<div class="figure" style="text-align: center">
<img src="imagens/05-filtros/placaEletronicaMediana.png" alt="(ref:placaEletronicaMediana_2)" width="85%" />
<p class="caption">
(#fig:placaEletronicaMediana_2)(ref:placaEletronicaMediana_2)
</p>
</div>
<ul>
<li>Segmentação</li>
</ul>
<p>Nessa etapa, as informações de interesse são extraídas da imagem, geralmente, pela detecção de descontinuidades (bordas) ou de similaridades na imagem <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 4]</span> como abordaremos no Capítulo <a href="segmentacao.html#segmentacao">Segmentação</a>. Cada método abordado dentro da segmentação tem uma finalidade mais específica, buscando separar determinado elemento, partes ou objeto da imagem, por exemplo, na Figura <a href="intro.html#fig:cannyEOriginal">1.3</a> está o resultado de detecção de bordas pelo método de Canny descrito no Capítulo <a href="segmentacao.html#segmentacao">Segmentação</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:cannyEOriginal"></span>
<img src="imagens/01-introducao/cannyEOriginal.png" alt="Resultado final da detecção de bordas de Canny. (a) Imagem Original. (b) Resultado da detecção de borda - Com o método Canny entre outros apresentados no Capítulo Segmentação é possível partir de uma imagem como em (a) e determinar as bordas, tendo como resultado (b)." width="60%" />
<p class="caption">
Figura 1.3: Resultado final da detecção de bordas de Canny. (a) Imagem Original. (b) Resultado da detecção de borda - Com o método Canny entre outros apresentados no Capítulo <a href="segmentacao.html#segmentacao">Segmentação</a> é possível partir de uma imagem como em (a) e determinar as bordas, tendo como resultado (b).
</p>
</div>
<p>Ao individualizar estes componentes da imagem por meio de diferentes detectores, como na Figura @ref(fig:doghubble_2) em que se utilizou um detector de Blob, as informações assumem um formato mais adequado para o processamento computacional.</p>
<p>(ref:doghubble_2) Resultado da detecção de <em>blobs</em> com DoG para identificação de estrelas - Outros detectores no Capítulo <a href="segmentacao.html#segmentacao">Segmentação</a> podem identificar pontos, linhas, quinas, círculos, e objetos de outros formatos como estas estrelas.</p>
<div class="figure" style="text-align: center">
<img src="imagens/06-segmentacao/dog_hubble.jpg" alt="(ref:doghubble_2)" width="35%" />
<p class="caption">
(#fig:doghubble_2)(ref:doghubble_2)
</p>
</div>
<p>Outro exemplo da separação de elementos de uma imagem também está no Capítulo <a href="separacaoFundo.html#separacaoFundo">Separação de Fundo</a>, em que modelos são utilizados para detectar o que é o <em>background</em>, ou plano de fundo, e o que é o objeto de interesse (<em>foreground</em>) como na Figura @ref(fig:indoorBGmodeling_2).</p>
<p>(ref:indoorBGmodeling_2) As imagens A, B, …, E são os <em>frames</em> capturados por uma câmera em um ambiente interno. As imagens F, G e H são os <em>backgrounds</em> estimados. E as imagens I, J e K são os <em>foregrounds</em> produzidos, as detecções de movimento estimadas. Adaptado de <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">5</a>, p. 435]</span> e <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">5</a>, p. 436]</span>.</p>
<div class="figure" style="text-align: center">
<img src="imagens/08-modelagemBackground/indoorBGmodeling.png" alt="(ref:indoorBGmodeling_2)" width="50%" />
<p class="caption">
(#fig:indoorBGmodeling_2)(ref:indoorBGmodeling_2)
</p>
</div>
<ul>
<li>Análise</li>
</ul>
<p>À parte de Análise atribuímos todos os processos que fazem uso da informação visual para compor um sistema de aplicação na área de Visão Computacional. Atualmente é mais comum ver estes processos englobados dentro de modelos de aprendizado de máquina mais genéricos como em redes neurais, capazes por exemplo, de classificar, identificar e rastrear objetos em diferentes situações. No Capítulo <a href="deepLearning.html#deepLearning">Deep Learning em Visão Computacional</a>, assim como na Figura @ref(fig:differentscnn_2) é possível se ter uma pequena noção de como as redes neurais, em particular as redes convolucionais (CNN), enxergam as imagens e como desagregam suas informações para disponibilizar resultados satisfatórios no campo da VC.</p>
<p>(ref:differentscnn_2) Diferentes CNN’s e seus mapas de características em diferentes camadas - Na primeira coluna temos as características aprendidas por uma rede especializada no trabalho com rostos humanos, na segunda coluna com carros, na terceira com elefantes e na quarta com cadeiras <span class="citation">[<a href="#ref-elgendy2020" role="doc-biblioref">6</a>, p. 253]</span></p>
<div class="figure" style="text-align: center">
<img src="imagens/07-deepLearning/differentscnn.png" alt="(ref:differentscnn_2)" width="80%" />
<p class="caption">
(#fig:differentscnn_2)(ref:differentscnn_2)
</p>
</div>
</div>
<div id="áreas-de-aplicações" class="section level2">
<h2><span class="header-section-number">1.3</span> Áreas de Aplicações</h2>
<p>Visto de forma geral como funcionam as etapas da Visão Computacional e do processamento de imagem é interessante elencar algumas das possíveis áreas em que estes dois campos podem ter atuação. Partindo do que já foi produzido se levanta que as primeiras tarefas de processamento de imagens tiveram aplicações significativas por volta da década de 1960, quando se desenvolveram computadores com potencial suficiente para realizá-las. O programa espacial americano também foi um forte impulso para o contínuo desenvolvimento e aprimoramento das técnicas de PDI, já que imagens, como as obtidas da Lua através de sondas e transmitidas à terra, continham distorções provenientes das câmeras utilizadas. Era necessário então, a utilização de métodos para corrigir essas alterações <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 4]</span>.</p>
<p>Outra área que também faz uso extensivo do processamento de imagens e impulsionou seu desenvolvimento é a área médica. Nessa área, o uso de imagens auxiliou no diagnóstico de doenças através de exames visuais como os de raio-x <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 4]</span>.</p>
<p>A utilização do processamento de imagens para melhorar informações visuais, ajudando na interpretação humana, expandiu-se para diferentes setores. No sensoriamento remoto, o pré-processamento contribui para uma melhor análise de imagens aéreas e de satélite, aumentando a compreensão da superfície terrestre. Na arqueologia e nas artes, métodos de processamento de imagens podem restaurar fotografias com registros únicos de objetos raros, pinturas, documentos antigos e conteúdos em vídeos <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 2]</span>. Na física e em áreas da biologia, técnicas computacionais realçam imagens de experimentos em áreas como plasmas de alta energia e microscopia eletrônica <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 5]</span>.</p>
<p>Com o aumento da automatização de tarefas, o processamento de imagens tem se destacado na aquisição de dados de imagens visando a percepção automática por máquinas <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 3]</span>. Técnicas de identificação de padrões podem ser aplicados no reconhecimento automático de caracteres, de impressões digitais, de faces, e de placas de veículos, contribuindo com setores de segurança. Na automação industrial tem sido utilizado no sistema de visão computacional para inspeção e montagem de produtos. Na área militar, pode ser aplicado na identificação e rastreamento de alvos em imagens de satélites, e na navegação de veículos autônomos. Nas áreas de medicina e biologia, rastreamentos automáticos em imagens radiográficas e amostras de sangue têm contribuído para os exames e testes <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 3]</span>. O processamento computacional de imagens aéreas e de satélites também é utilizado na previsão do tempo e em avaliações ambientais <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 5]</span>.</p>
<p>Este variado campo de aplicações pode ser justificado pela capacidade dos aparelhos de processamento de imagens trabalharem com imagens de diversas fontes. Diferentemente dos seres humanos, que são limitados à banda visual do espectro eletromagnético (EM), o processamento computacional cobre todo o EM, variando de ondas gama a ondas de rádio <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 1]</span>. No processamento digital ainda é possível trabalhar com imagens geradas por fontes que os humanos não estão acostumados a associar com imagens. Essas fontes incluem acústica, ultrassom, microscopia eletrônica e imagens geradas por computador <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 13]</span>.</p>
<p>Uma das formas mais fáceis de desenvolver uma compreensão básica da extensão das aplicações de PDI é categorizar as imagens de acordo com sua fonte. Na Figura <a href="intro.html#fig:espectro">1.4</a> ttemos uma representação do EM e iremos a seguir explorar cada uma dessas faixas, apresentando algumas das áreas onde podem ser utilizados:</p>

<div class="figure" style="text-align: center"><span id="fig:espectro"></span>
<img src="imagens/01-introducao/espectro.png" alt="Espectro eletromagnético - As imagens podem ser geradas a partir de diferentes fontes eletromagnéticas, incluindo raios gama, raio x, ultravioleta, visível, infravermelho, microondas e rádio [7]." width="90%" />
<p class="caption">
Figura 1.4: Espectro eletromagnético - As imagens podem ser geradas a partir de diferentes fontes eletromagnéticas, incluindo raios gama, raio x, ultravioleta, visível, infravermelho, microondas e rádio <span class="citation">[<a href="#ref-img:espectro" role="doc-biblioref">7</a>]</span>.
</p>
</div>
<ul>
<li><p><strong>Imagens formadas por raios gama</strong></p>
<p>As imagens formadas a partir de raios gama têm diferentes utilidades, sendo muito utilizadas na medicina e astronomia <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 6]</span>. Na medicina, existem procedimentos onde se injetam isótopos radioativos no paciente e por meio dos detectores de raio gama é formada uma imagem, como exemplo, escaneamento ósseo e tomografia por emissão de pósitrons (PET-scan). Na astronomia, ela pode ser utilizada para se conseguir ver detalhes astronômicos que estão presentes na faixa eletromagnética dos raios gama.</p></li>
<li><p><strong>Imagens formadas por raios X</strong></p>
<p>Imagens formadas a partir de raio X têm uma ampla gama de aplicações, desde seu uso na medicina até seu uso no meio industrial <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 6]</span>. Na indústria, pode ser utilizado para se encontrar defeitos de fabricação em produtos, e na medicina, vêm se utilizando muito o processamento de imagem e a visão computacional para ajudar no diagnóstico de doenças, como por exemplo, artérias obstruídas, fraturas e tumores.</p></li>
<li><p><strong>Imagens na banda ultravioleta</strong></p>
<p>O espectro ultravioleta também tem inúmeras aplicações, como a inspeção industrial, microscopia, imagens biológicas e observações astronômicas <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 8]</span>.</p></li>
<li><p><strong>Imagens na banda visível e infravermelho</strong></p>
<p>Essas duas bandas possuem uma gama extremamente ampla de aplicações, sendo utilizadas juntas ou separadas. Na banda visível, existem diversas aplicações, como em processos industriais, detecção de faces, detecção de placas de carros, etc <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 11]</span>. A banda infravermelho também possui inúmeras aplicações, sendo uma delas imagens a partir de satélites, onde o infravermelho nos permite ver inúmeros detalhes que somente com a banda visível não seria possível <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 9]</span>.</p></li>
<li><p><strong>Imagens na banda de micro-ondas e rádio</strong></p>
<p>Na banda de micro-ondas o melhor exemplo que temos é o radar. Essa banda tem uma peculiaridade de ser extremamente penetrante, podendo gerar imagens através de nuvens, vegetação, etc <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 12]</span>. Já a banda de rádio é muito utilizada na medicina, como exemplo na ressonância magnética e na astronomia <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 12]</span>.</p></li>
</ul>
<p>Como podemos observar, existem inúmeras maneiras de se conseguir imagens além da clássica imagem no espectro visível, isso nos dá a possibilidade de utilizar o PDI em inúmeras áreas e problemas. Na Figura <a href="intro.html#fig:aplicacoes">1.5</a> temos uma nebulosa observada a partir de diferentes bandas do EM, sendo possível observar detalhes que passariam despercebidos se usássemos somente alguma delas.</p>

<div class="figure" style="text-align: center"><span id="fig:aplicacoes"></span>
<img src="imagens/01-introducao/aplicacoes.png" alt="Nebulosa CRAB em diferentes frequências - Ao observar um mesmo objeto a partir de várias bandas do EM é possível avaliar diferentes aspectos [8]." width="90%" />
<p class="caption">
Figura 1.5: Nebulosa CRAB em diferentes frequências - Ao observar um mesmo objeto a partir de várias bandas do EM é possível avaliar diferentes aspectos <span class="citation">[<a href="#ref-img:nebulosa" role="doc-biblioref">8</a>]</span>.
</p>
</div>

</div>
</div>
<h3>Refêrencias</h3>
<div id="refs" class="references">
<div id="ref-velho2009">
<p>[1] L. Velho, A. C. Frery, e J. Gomes, <em>Image processing for computer graphics and vision</em>, 2º ed. London: Springer, 2009.</p>
</div>
<div id="ref-gonzalez2010">
<p>[2] R. C. Gonzalez e R. C. Woods, <em>Processamento digital de imagens</em>, 3º ed. São Paulo: Pearson Prentice Hall, 2010.</p>
</div>
<div id="ref-pedrini2008">
<p>[3] H. Pedrini e W. Robson Schwartz, <em>Analise de imagens digitais: principios, algoritmos e aplicações</em>, 3º ed. São Paulo: Thomson Learning Edicoes Ltda, 2007.</p>
</div>
<div id="ref-moeslund2012">
<p>[4] T. B. Moeslund, <em>Introduction to video and image processing: Building real systems and applications</em>. Springer Science &amp; Business Media, 2012.</p>
</div>
<div id="ref-nixon2019feature">
<p>[5] M. Nixon e A. Aguado, <em>Feature extraction and image processing for computer vision</em>. Academic press, 2019.</p>
</div>
<div id="ref-elgendy2020">
<p>[6] M. Elgendy, <em>Deep Learning for Vision Systems</em>. Manning Publications, 2020.</p>
</div>
<div id="ref-img:espectro">
<p>[7] B. E. da cor, “Imagem de um espectro eletromagnetico”. 2014, [Online]. Disponível em: <a href="https://estudodacor.files.wordpress.com/2014/08/espectro-eletromagnetico1.jpg">https://estudodacor.files.wordpress.com/2014/08/espectro-eletromagnetico1.jpg</a>.</p>
</div>
<div id="ref-img:nebulosa">
<p>[8] W. Commons, “Crab nebula in multiple wavelengths”. [Online]. Disponível em: <a href="%20https://commons.wikimedia.org/wiki/File:Crab_Nebula_in_Multiple_Wavelengths.png">https://commons.wikimedia.org/wiki/File:Crab_Nebula_in_Multiple_Wavelengths.png</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="formacaoImagem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": null
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/covap-utfpr/pdi/edit/master/01-introducao.Rmd",
"text": "Editar "
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"citation_package": "biblatex"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
