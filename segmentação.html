<!DOCTYPE html>
<html lang="pt-BR" xml:lang="pt-BR">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens(PDI)</title>
  <meta name="description" content="Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens(PDI)" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens(PDI)" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens(PDI)" />
  
  
  

<meta name="author" content="" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="filtros.html"/>
<link rel="next" href="refêrencias.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="logo"><a href="./"><img src="imagens/logo.jpeg"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Inicio</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#relação-de-processamento-digital-de-imagem-visão-computacional-e-computação-gráfica"><i class="fa fa-check"></i><b>1.1</b> Relação de Processamento Digital de Imagem, Visão Computacional e Computação Gráfica</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#aplicações-processamento-digital-de-imagens"><i class="fa fa-check"></i><b>1.2</b> Aplicações Processamento Digital de Imagens</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#etapas-do-processamento-e-análise-de-imagens"><i class="fa fa-check"></i><b>1.3</b> Etapas do Processamento e Análise de Imagens</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html"><i class="fa fa-check"></i><b>2</b> Formação da imagem</a><ul>
<li class="chapter" data-level="2.1" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#câmera-pinhole-e-geometria"><i class="fa fa-check"></i><b>2.1</b> Câmera pinhole e geometria</a></li>
<li class="chapter" data-level="2.2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#lentes"><i class="fa fa-check"></i><b>2.2</b> Lentes</a></li>
<li class="chapter" data-level="2.3" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#sensor"><i class="fa fa-check"></i><b>2.3</b> Sensor</a></li>
<li class="chapter" data-level="2.4" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#amostragem-e-quantização"><i class="fa fa-check"></i><b>2.4</b> Amostragem e Quantização</a><ul>
<li class="chapter" data-level="2.4.1" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#amostragem"><i class="fa fa-check"></i><b>2.4.1</b> Amostragem</a></li>
<li class="chapter" data-level="2.4.2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#quantização"><i class="fa fa-check"></i><b>2.4.2</b> Quantização</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#definição-de-imagem-digital"><i class="fa fa-check"></i><b>2.5</b> Definição de imagem digital</a></li>
<li class="chapter" data-level="2.6" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#resolução-espacial-e-de-intensidade"><i class="fa fa-check"></i><b>2.6</b> Resolução espacial e de intensidade</a></li>
<li class="chapter" data-level="2.7" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#pixels"><i class="fa fa-check"></i><b>2.7</b> Pixels</a><ul>
<li class="chapter" data-level="2.7.1" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#vizinhança"><i class="fa fa-check"></i><b>2.7.1</b> Vizinhança</a></li>
<li class="chapter" data-level="2.7.2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#conectividade"><i class="fa fa-check"></i><b>2.7.2</b> Conectividade</a></li>
<li class="chapter" data-level="2.7.3" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#adjacência"><i class="fa fa-check"></i><b>2.7.3</b> Adjacência</a></li>
<li class="chapter" data-level="2.7.4" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#componente-conexa"><i class="fa fa-check"></i><b>2.7.4</b> Componente Conexa</a></li>
<li class="chapter" data-level="2.7.5" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#medidas-de-distância"><i class="fa fa-check"></i><b>2.7.5</b> Medidas de Distância</a></li>
<li class="chapter" data-level="2.7.6" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#operações-lógico-aritméticas"><i class="fa fa-check"></i><b>2.7.6</b> Operações Lógico-aritméticas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html"><i class="fa fa-check"></i><b>3</b> Transformacões Geométricas</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#definição"><i class="fa fa-check"></i><b>3.1</b> Definição</a></li>
<li class="chapter" data-level="3.2" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#sistema-de-coordenadas-objetos-2d-e-3d"><i class="fa fa-check"></i><b>3.2</b> Sistema de coordenadas objetos (2D e 3D)</a></li>
<li class="chapter" data-level="3.3" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#representação-vetorial-e-matricial-de-imagens-digitalizadas"><i class="fa fa-check"></i><b>3.3</b> Representação Vetorial e Matricial de Imagens digitalizadas</a></li>
<li class="chapter" data-level="3.4" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#matrizes-em-computação-gráfica"><i class="fa fa-check"></i><b>3.4</b> Matrizes em Computação gráfica</a></li>
<li class="chapter" data-level="3.5" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformações-em-pontos-e-objetos"><i class="fa fa-check"></i><b>3.5</b> Transformações em Pontos e Objetos</a></li>
<li class="chapter" data-level="3.6" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformação-de-translação"><i class="fa fa-check"></i><b>3.6</b> Transformação de Translação</a></li>
<li class="chapter" data-level="3.7" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformação-de-escala"><i class="fa fa-check"></i><b>3.7</b> Transformação de Escala</a></li>
<li class="chapter" data-level="3.8" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformação-de-rotação"><i class="fa fa-check"></i><b>3.8</b> Transformação de Rotação</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html"><i class="fa fa-check"></i><b>4</b> Transformações radiométricas</a><ul>
<li class="chapter" data-level="4.1" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#transformação-linear"><i class="fa fa-check"></i><b>4.1</b> Transformação Linear</a></li>
<li class="chapter" data-level="4.2" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#transformação-logarítmica"><i class="fa fa-check"></i><b>4.2</b> Transformação Logarítmica</a></li>
<li class="chapter" data-level="4.3" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#transformação-de-potência"><i class="fa fa-check"></i><b>4.3</b> Transformação de Potência</a></li>
<li class="chapter" data-level="4.4" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#processamento-de-histograma"><i class="fa fa-check"></i><b>4.4</b> Processamento de histograma</a></li>
<li class="chapter" data-level="4.5" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#equalização-do-histograma"><i class="fa fa-check"></i><b>4.5</b> Equalização do histograma</a></li>
<li class="chapter" data-level="4.6" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#especificação-de-histograma"><i class="fa fa-check"></i><b>4.6</b> Especificação de histograma</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="filtros.html"><a href="filtros.html"><i class="fa fa-check"></i><b>5</b> Filtros</a><ul>
<li class="chapter" data-level="5.1" data-path="filtros.html"><a href="filtros.html#convolução"><i class="fa fa-check"></i><b>5.1</b> Convolução</a><ul>
<li class="chapter" data-level="5.1.1" data-path="filtros.html"><a href="filtros.html#definção-matemática-de-convolução"><i class="fa fa-check"></i><b>5.1.1</b> Definção matemática de convolução</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="filtros.html"><a href="filtros.html#média"><i class="fa fa-check"></i><b>5.2</b> Média</a></li>
<li class="chapter" data-level="5.3" data-path="filtros.html"><a href="filtros.html#mediana"><i class="fa fa-check"></i><b>5.3</b> Mediana</a></li>
<li class="chapter" data-level="5.4" data-path="filtros.html"><a href="filtros.html#gaussiano"><i class="fa fa-check"></i><b>5.4</b> Gaussiano</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="segmentação.html"><a href="segmentação.html"><i class="fa fa-check"></i><b>6</b> Segmentação</a><ul>
<li class="chapter" data-level="6.1" data-path="segmentação.html"><a href="segmentação.html#detecção-por-descontinuidade"><i class="fa fa-check"></i><b>6.1</b> Detecção por descontinuidade</a><ul>
<li class="chapter" data-level="6.1.1" data-path="segmentação.html"><a href="segmentação.html#detecção-de-ponto"><i class="fa fa-check"></i><b>6.1.1</b> Detecção de ponto</a></li>
<li class="chapter" data-level="6.1.2" data-path="segmentação.html"><a href="segmentação.html#detecção-de-linha"><i class="fa fa-check"></i><b>6.1.2</b> Detecção de linha</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="segmentação.html"><a href="segmentação.html#detecção-de-bordas"><i class="fa fa-check"></i><b>6.2</b> Detecção de bordas</a><ul>
<li class="chapter" data-level="6.2.1" data-path="segmentação.html"><a href="segmentação.html#modelos-de-bordas"><i class="fa fa-check"></i><b>6.2.1</b> Modelos de Bordas</a></li>
<li class="chapter" data-level="6.2.2" data-path="segmentação.html"><a href="segmentação.html#método-do-gradiente-roberts-prewitt-sobel."><i class="fa fa-check"></i><b>6.2.2</b> Método do gradiente ( Roberts, Prewitt, Sobel).</a></li>
<li class="chapter" data-level="6.2.3" data-path="segmentação.html"><a href="segmentação.html#método-de-marr-hildreth"><i class="fa fa-check"></i><b>6.2.3</b> Método de Marr-Hildreth</a></li>
<li class="chapter" data-level="6.2.4" data-path="segmentação.html"><a href="segmentação.html#método-de-canny"><i class="fa fa-check"></i><b>6.2.4</b> Método de Canny</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="segmentação.html"><a href="segmentação.html#transformada-de-hough"><i class="fa fa-check"></i><b>6.3</b> Transformada de Hough</a><ul>
<li class="chapter" data-level="6.3.1" data-path="segmentação.html"><a href="segmentação.html#transformada-de-hough-para-detecção-de-linhas"><i class="fa fa-check"></i><b>6.3.1</b> Transformada de Hough para detecção de linhas</a></li>
<li class="chapter" data-level="6.3.2" data-path="segmentação.html"><a href="segmentação.html#transformada-de-hough-para-detecção-de-círculos"><i class="fa fa-check"></i><b>6.3.2</b> Transformada de Hough para detecção de círculos</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="segmentação.html"><a href="segmentação.html#detecção-de-blobs"><i class="fa fa-check"></i><b>6.4</b> Detecção de blobs</a><ul>
<li class="chapter" data-level="6.4.1" data-path="segmentação.html"><a href="segmentação.html#log"><i class="fa fa-check"></i><b>6.4.1</b> LoG</a></li>
<li class="chapter" data-level="6.4.2" data-path="segmentação.html"><a href="segmentação.html#dog"><i class="fa fa-check"></i><b>6.4.2</b> DoG</a></li>
<li class="chapter" data-level="6.4.3" data-path="segmentação.html"><a href="segmentação.html#doh"><i class="fa fa-check"></i><b>6.4.3</b> DoH</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="segmentação.html"><a href="segmentação.html#detecção-de-junções-ou-cantos"><i class="fa fa-check"></i><b>6.5</b> Detecção de junções ou cantos</a></li>
<li class="chapter" data-level="6.6" data-path="segmentação.html"><a href="segmentação.html#segmentação-por-limiarização"><i class="fa fa-check"></i><b>6.6</b> Segmentação por limiarização</a></li>
<li class="chapter" data-level="6.7" data-path="segmentação.html"><a href="segmentação.html#método-de-otsu"><i class="fa fa-check"></i><b>6.7</b> método de Otsu</a></li>
<li class="chapter" data-level="6.8" data-path="segmentação.html"><a href="segmentação.html#segmentação-usando-watersheds-morfológicas"><i class="fa fa-check"></i><b>6.8</b> Segmentação usando watersheds morfológicas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="refêrencias.html"><a href="refêrencias.html"><i class="fa fa-check"></i>Refêrencias</a></li>
<li class="divider"></li>
<li><center>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
<img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" />
</a></li></center>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Material introdutório de Processamento Digital de Imagens(PDI)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="segmentação" class="section level1">
<h1><span class="header-section-number">Capítulo 6</span> Segmentação</h1>
<div id="detecção-por-descontinuidade" class="section level2">
<h2><span class="header-section-number">6.1</span> Detecção por descontinuidade</h2>
<div id="detecção-de-ponto" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Detecção de ponto</h3>
</div>
<div id="detecção-de-linha" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Detecção de linha</h3>
</div>
</div>
<div id="detecção-de-bordas" class="section level2">
<h2><span class="header-section-number">6.2</span> Detecção de bordas</h2>
<div id="modelos-de-bordas" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Modelos de Bordas</h3>
</div>
<div id="método-do-gradiente-roberts-prewitt-sobel." class="section level3">
<h3><span class="header-section-number">6.2.2</span> Método do gradiente ( Roberts, Prewitt, Sobel).</h3>
</div>
<div id="método-de-marr-hildreth" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Método de Marr-Hildreth</h3>
</div>
<div id="método-de-canny" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Método de Canny</h3>
<p>O algoritmo de Canny recebeu esse nome em alusão a John Canny, que o propôs em seu artigo, “A computational Approach to Edge Detection”<span class="citation">[<a href="#ref-canny1986computational" role="doc-biblioref">16</a>]</span>, publicado em 1986. Sua formulação se baseava em três pontos principais:</p>
<ul>
<li>Uma baixa taxa de erro, ou seja, todas as bordas presentes na imagem devem ser encontradas e não deve haver respostas espúrias.</li>
<li>O segundo critério diz que as bordas detectadas devem estar bem localizadas, em outras palavras, elas devem estar o mais próximo possível das bordas verdadeiras.</li>
<li>O terceiro e último critério diz que se deve minimizar o número de máximos locais em torno da borda verdadeira, para que não sejam encontrados múltiplos pixels de borda onde deve haver somente um.</li>
</ul>
<p>Em seu trabalho, Canny buscou encontrar soluções ótimas, matematicamente, que obedecessem os três critérios. Apesar disso, é muito difícil, ou impossível, encontrar uma solução que satisfaça completamente os objetivos descritos<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>. Todavia é possível utilizar uma aproximação por meio de otimização numérica com as bordas em degrau em um exemplo 1-D que contenham ruído branco gaussiano e mostrar que uma boa aproximação para um ótimo detector de bordas é a primeira derivada de uma gaussiana<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>:</p>
<p><span class="math display">\[\frac{\mathrm{d} }{\mathrm{d} x}e^{\frac{-x^2}{2\sigma^2}} = \frac{-x}{\sigma^2}e^{\frac{-x^2}{2\sigma^2}}\]</span></p>
<p>Canny demonstrou que a utilização dessa aproximação pode ser feita com uma taxa 20% inferior à solução numérica, o que a torna praticamente imperceptível para muitas das aplicações<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>.
A ideia anterior foi imaginada em um aspecto 1D, precisamos agora, expandir esse conceito para uma generalização 2D. Uma borda de degrau pode ser caracterizada pela sua posição, orientação e possível magnitude. Aplicar um filtro Gaussiano em uma imagem e depois diferenciá-la forma um simples e efetivo operador direcional<span class="citation">[<a href="#ref-sonka2014" role="doc-biblioref">17</a>, p. 145]</span>. Digamos então que <span class="math inline">\(f(x,y)\)</span> seja uma imagem e <span class="math inline">\(G(x,y)\)</span> a função gaussiana:</p>
<p><span class="math display">\[G(x,y) = e^{-\frac{x^2+y^2}{2\sigma^2}}\]</span></p>
<p>Temos como saída a imagem suavizada:</p>
<p><span class="math display">\[f_s(x,y)=G(x,y)*f(x,y)\]</span></p>
<p>E após isso realizamos o cálculo da magnitude e direção do gradiente:</p>
<p><span class="math display">\[M(x,y) = \sqrt{g_x^2+g_y^2}\]</span>
<span class="math display">\[\alpha(x,y)= \tan^{-1}\left ( \frac{g_y}{g_x} \right )\]</span></p>
<p>onde <span class="math inline">\(g_x=\partial f_s/\partial x\)</span> e <span class="math inline">\(g_y=\partial f_s/\partial y\)</span>. Para o cálculo das derivadas parciais podemos utilizar tanto Prewitt quanto Sobel. Como essa primeira etapa utiliza operadores que calculam as primeiras derivadas, acabamos com bordas grossas, e o terceiro objetivo da proposta de Canny é ter bordas com único ponto, por isso o próximo passo é a de afinar as bordas encontradas. O método que usaremos para isso é chamado supressão dos não máximos. Esse processo tem como base a discretização das direções da normal da borda(vetor gradiente), ou seja, em uma região 3x3 temos 4 direções possíveis, como pode ser visto na figura <a href="segmentação.html#fig:edgeorientation">6.1</a>(c), sendo que consideramos 4 pois é contando as duas direções, como exemplo, consideramos um borda de 45º se ela se encontra entre +157,5º e +112,5º ou -67,5º e -22,5º.
Na figura <a href="segmentação.html#fig:edgeorientation">6.1</a>(a) temos um exemplo de duas orientações que podem existir em uma borda horizontal, e na figura <a href="segmentação.html#fig:edgeorientation">6.1</a>(b) podemos ver a normal de uma borda horizontal e o intervalo de valores onde a direção do vetor gradiente pode existir.</p>

<div class="figure" style="text-align: center"><span id="fig:edgeorientation"></span>
<img src="imagens/06-segmentacao/edge_orientation.png" alt="Discretização das direções. (a)Borda horizontal. (b) Intervalo dos possíveis valores do ângulo, normal da borda, para uma borda horizontal. (c) Intervalo de valores do ângulo da normal para os diferentes tipos de borda. [2, p. 475]" width="70%" />
<p class="caption">
Figura 6.1: Discretização das direções. (a)Borda horizontal. (b) Intervalo dos possíveis valores do ângulo, normal da borda, para uma borda horizontal. (c) Intervalo de valores do ângulo da normal para os diferentes tipos de borda. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 475]</span>
</p>
</div>
<p>Se consideramos <span class="math inline">\(d1\)</span>, <span class="math inline">\(d2\)</span>, <span class="math inline">\(d3\)</span> e <span class="math inline">\(d4\)</span> como as direções possíveis em uma área 3x3, podemos formular o seguinte esquema de supressão de não máximos de uma região 3x3 centrada em todos os pontos <span class="math inline">\((x,y)\)</span> de <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 475]</span>:
- Encontrar a direção <span class="math inline">\(d_k\)</span> que está mais perto de <span class="math inline">\(\alpha (x,y)\)</span>.
- Se o valor de <span class="math inline">\(M(x,y)\)</span> for inferior a pelo menos um dos seus dois vizinhos ao logo de <span class="math inline">\(d_k\)</span>, deixe <span class="math inline">\(g_N(x,y)=0\)</span>(supressão); caso contrário, deixe <span class="math inline">\(g_N(x,y)=M(x,y)\)</span>.
Onde <span class="math inline">\(g_N(x,y)\)</span> é a imagem suprimida.
A última operação a ser realizada é a limiarização, para se remover os pontos de falsas bordas. Aqui usaremos a limiarização por histerese que utiliza dois limiares, um baixo(<span class="math inline">\(T_L\)</span>) e um alto (<span class="math inline">\(T_H\)</span>), sendo que Canny sugeriu, em seu trabalho, que a razão entre o limiar alto para o baixo deva ser de dois ou três para um.
Podemos imaginar essa limiarização da seguinte forma, criamos duas imagens adicionais:</p>
<p><span class="math display">\[g_{NH}(x,y) = g_N(x,y)\geq T_H\]</span> e <span class="math display">\[g_{NL}(x,y) = g_N(x,y)\geq T_L\]</span></p>
<p>Onde <span class="math inline">\(g_{NH}(x,y)\)</span> e <span class="math inline">\(g_{NL}(x,y)\)</span> são definidas inicialmente como <span class="math inline">\(0\)</span>. Temos então que <span class="math inline">\(g_{NH}(x,y)\)</span>conterá os pixels que são maiores que o nosso limiar e <span class="math inline">\(g_{NL}(x,y)\)</span> terá os pixels que estão acima do nosso limiar baixo, o que significa que ele contém os pixels que se encontram no meio dos dois limiares mais o que está acima do limiar alto, temos então que remover esses pixels, o que significa:
<span class="math display">\[g_{NL}(x,y)=g_{NL}(x,y)-g_{NH}(x,y)\]</span></p>
<p>Podemos chamar os pixels de <span class="math inline">\(g_{NH}(x,y)\)</span> de pixels fortes e os de <span class="math inline">\(g_{NL}(x,y)\)</span> de fracos. Ao final dessa limiarização todos os pixels fortes são classificados como borda válida, mas com falhas, que nos leva a outro processo:</p>
<ul>
<li>Localizar o próximo pixel borda a ser revisado em <span class="math inline">\(g_{NH}(x,y)\)</span>, chamaremos esse pixel de p.</li>
<li>Classificar todos os pixels fracos de <span class="math inline">\(g_{NL}(x,y)\)</span> que tenham conexão, como a conectividade-8, como bordas válidas.</li>
<li>Quando todos os pixels de <span class="math inline">\(g_{NL}(x,y)\)</span> Se forem analisados, pulamos para 4, senão voltamos para 1.</li>
<li>Zerar todos os pixels de <span class="math inline">\(g_{NL}(x,y)\)</span> que não são bordas válidas.</li>
</ul>
<p>Ao final desses processos teremos a imagem de saída do algoritmo de Canny. Como dito por <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 476]</span>, o uso de duas imagens <span class="math inline">\(g_{NH}(x,y)\)</span> e <span class="math inline">\(g_{NL}(x,y)\)</span> é uma boa maneira para se explicar o algoritmo de uma maneira simples, mas na prática isso pode ser feito diretamente na imagem <span class="math inline">\(g_N(x,y)\)</span>.
Por fim, sumarizando os passos do algoritmo, com um exemplo:</p>
<ol style="list-style-type: decimal">
<li>Imagem original</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:original"></span>
<img src="imagens/06-segmentacao/original.jpg" alt="Imagem original." width="50%" />
<p class="caption">
Figura 6.2: Imagem original.
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Aplicação do filtro gaussiano para suavizar a imagem.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:gaussian"></span>
<img src="imagens/06-segmentacao/gaussian.jpg" alt="Imagem filtrada com filtro gaussiano." width="50%" />
<p class="caption">
Figura 6.3: Imagem filtrada com filtro gaussiano.
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Cálculo da magnitude do gradiente e dos ângulos.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:derivadas"></span>
<img src="imagens/06-segmentacao/derivadas.jpg" alt="(a) Sobel na direção vertical. (b) Sobel na direção horizontal. (c) Gradiente. (d) Angulos. [8, p. 98]" width="75%" />
<p class="caption">
Figura 6.4: (a) Sobel na direção vertical. (b) Sobel na direção horizontal. (c) Gradiente. (d) Angulos. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li>Aplicação da supressão não máxima para afinar as bordas.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:supressao"></span>
<img src="imagens/06-segmentacao/supressao.jpg" alt="Resultado da supressão não máxima." width="50%" />
<p class="caption">
Figura 6.5: Resultado da supressão não máxima.
</p>
</div>
<ol start="6" style="list-style-type: decimal">
<li>Usar limiarização por histerese e análise de conectividade para detectar e conectar as bordas.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:threshold"></span>
<img src="imagens/06-segmentacao/threshold.jpg" alt="Resultado da histerese e conecção de bordas." width="50%" />
<p class="caption">
Figura 6.6: Resultado da histerese e conecção de bordas.
</p>
</div>
<ol start="7" style="list-style-type: decimal">
<li>Resultado final.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:canny"></span>
<img src="imagens/06-segmentacao/canny.jpg" alt="Resultado final da detecção de bordas de Canny." width="50%" />
<p class="caption">
Figura 6.7: Resultado final da detecção de bordas de Canny.
</p>
</div>
</div>
</div>
<div id="transformada-de-hough" class="section level2">
<h2><span class="header-section-number">6.3</span> Transformada de Hough</h2>
<p>A Transformada de Hough é uma técnica utilizada para detectar formas em imagens, sejam elas linhas, círculos ou elipses. Apesar de ela ser muito utilizada e ter sido criada para detecção principalmente de linhas, ela pode ser usada para a detecção de outras formas, como dito anteriormente.</p>
<div id="transformada-de-hough-para-detecção-de-linhas" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Transformada de Hough para detecção de linhas</h3>
<p>Para começar a entender essa transformada, imaginemos que temos um ponto <span class="math inline">\((x_i, y_i)\)</span> no plano <span class="math inline">\(xy\)</span> e a equação da reta <span class="math inline">\(y_i=ax_i+b\)</span>. Pelo ponto <span class="math inline">\((x_i, y_i)\)</span> passam infinitas retas e todas satisfazem a equação. Podemos escrever a equação anterior em relação a <span class="math inline">\(b\)</span>, ou seja, <span class="math inline">\(b=-x_ia+y_i\)</span>, o que nos leva ao plano <span class="math inline">\(ab\)</span>(espaço de parâmetros) onde essa nova equação gerará uma única reta.</p>
<p>Agora imaginemos um outro ponto <span class="math inline">\((x_j, y_j)\)</span> no plano <span class="math inline">\(xy\)</span>, podemos também levá-lo ao plano ab com a equação <span class="math inline">\(b=-x_ja+y_j\)</span>. Como podemos ver na figura <a href="segmentação.html#fig:planoxy">6.8</a>(b) as duas retas geradas no plano <span class="math inline">\(ab\)</span> se cruzam nas coordenadas <span class="math inline">\((a&#39;, b&#39;)\)</span>, e esse ponto de cruzamento representa a reta que cruza os dois pontos no plano <span class="math inline">\(xy\)</span>, como podemos ver na mesma representação <a href="segmentação.html#fig:planoxy">6.8</a>(b). Na realidade, todos os pontos pertencentes a reta definida por esses dois pontos em <span class="math inline">\(xy\)</span> tem sua reta respectiva em <span class="math inline">\(ab\)</span> e todas elas se cruzam no ponto <span class="math inline">\((a&#39;, b&#39;)\)</span>, isso nos dá uma maneira de realizar a detecção de bordas, pois podemos imaginar essa reta como nossa borda, assim, para achá-la basta localizar o ponto no espaço de parâmetros onde um grande número de retas se cruzam.</p>

<div class="figure" style="text-align: center"><span id="fig:planoxy"></span>
<img src="imagens/06-segmentacao/planoxy.png" alt="Plano xy e ab. [2, p. 483]" width="65%" />
<p class="caption">
Figura 6.8: Plano xy e ab. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 483]</span>
</p>
</div>
<p>Ocorre um pequeno problema nessa forma, pois quando a reta se aproxima da direção vertical, <span class="math inline">\(ab\)</span> se aproxima do infinito. Para resolver essa dificuldade, em vez de levarmos os pontos a retas no espaço <span class="math inline">\(ab\)</span> cartesiano utilizamos um espaço em coordenadas polares. Para isso utilizamos a seguinte equação:
<span class="math display">\[\rho=x\cos{\theta}+y\ sen{\ \theta}\]</span>
Na figura <a href="segmentação.html#fig:planoxyrhotheta">6.9</a>(a) podemos ver isso de maneira gráfica, temos que p corresponde à distância da origem até a reta. Cada uma das curvas senoidais da figura <a href="segmentação.html#fig:planoxyrhotheta">6.9</a>(b) representa um conjunto de linhas que cruzam os dois pontos da figura <a href="segmentação.html#fig:planoxyrhotheta">6.9</a>(a), sendo que na interseção das curvas temos a reta que cruza esses pontos.</p>

<div class="figure" style="text-align: center"><span id="fig:planoxyrhotheta"></span>
<img src="imagens/06-segmentacao/planoxyrhotheta.png" alt="Imagem de ônibus com filtro de aguçamento e de suavização [8, p. 98]" width="90%" />
<p class="caption">
Figura 6.9: Imagem de ônibus com filtro de aguçamento e de suavização <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>
<p>A figura <a href="segmentação.html#fig:planoxyrhotheta">6.9</a>(c) mostra como fazemos a representação do espaço , usamos uma matriz onde esse espaço é subdividido em várias células, chamadas células acumuladoras. Os valores de <span class="math inline">\(\theta_{\text{min}}\)</span> e <span class="math inline">\(\theta_{\text{max}}\)</span> são geralmente <span class="math inline">\(-90^{\circ}\leq \theta\leq90^{\circ}\)</span> e os valores de <span class="math inline">\(\rho_min\)</span> e <span class="math inline">\(\rho_max\)</span> são <span class="math inline">\(-D\leq\rho\leq D\)</span>, onde <span class="math inline">\(D\)</span> é o comprimento da diagonal da imagem, ou seja, <span class="math inline">\(D=\sqrt{vertical^2+horizontal^2}\)</span>. O que fazemos então é andar por todos os pontos de borda da imagem de entrada e calcular o valor de a partir da equação apresentada anteriormente usando o valor de <span class="math inline">\((x,y)\)</span> e variando o ângulo , com isso a cada valor do ângulo teremos um diferente e somamos mais um na célula correspondente da matriz acumuladora, que inicialmente é toda preenchida com zeros. Ao final de todo o processo termos determinadas células com valores mais altos, essas são conhecidas como picos e correspondem ao cruzamento de duas ou mais curvas senoidais do plano o que corresponde a uma linha ligando pontos no plano <span class="math inline">\(xy\)</span>.</p>
<p>A seguir temos um exemplo, que nos ajuda a entender e ver na prática o funcionamento da transformada de Hough. A figura <a href="segmentação.html#fig:houghumponto">6.10</a>(a) contém uma imagem de tamanho 101x101 com um ponto no centro, ou seja <span class="math inline">\((x,y)=(50,50)\)</span> e a figura <a href="segmentação.html#fig:houghumponto">6.10</a>(b) contém a matriz acumuladora da transformada, onde podemos ver a curva senóide formada pelo ponto. Verificando os valores nela vemos que para <span class="math inline">\(\rho=-90^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50 \cdot \cos(-90^{\circ})+50\cdot\text{sen}(-90^{\circ}) = -50\]</span>
para <span class="math inline">\(\theta=90^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50\cdot \cos(90^{\circ})+50\cdot\text{sen}(90^{\circ})=50\]</span>
para <span class="math inline">\(\theta=45^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50\cdot \cos(45^{\circ})+50\cdot \text{sen}(45^{\circ})\approx70,71\]</span>
e para <span class="math inline">\(\theta=-45^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50\cdot\cos(-45º)+50\cdot \text{sen}(-45º)=0\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:houghumponto"></span>
<img src="imagens/06-segmentacao/hough_um_ponto.jpg" alt="Transformada de Hough para um ponto." width="75%" />
<p class="caption">
Figura 6.10: Transformada de Hough para um ponto.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.11</a>(a) temos dois pontos, a e b, onde foi realizada a transformada de Hough que tem como espaço de saída a figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.11</a>(b). A reta que passa por esses dois pontos, chamada de reta c é representada por uma reta pontilhada na figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.11</a>(a) e na figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.11</a>(b) temos o ponto no plano que representa essa reta, ou seja, uma reta a uma distância <span class="math inline">\(\rho\approx70,71\)</span> da origem com ângulo de <span class="math inline">\(45^{\circ}\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:houghdoispontosesquerda"></span>
<img src="imagens/06-segmentacao/hough_dois_ponto_esquerda.png" alt="Transformada de Hough para um ponto em 45º." width="75%" />
<p class="caption">
Figura 6.11: Transformada de Hough para um ponto em 45º.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:houghdoispontosdireita">6.12</a>(a) temos mais um exemplo, desta vez com um ponto localizado a sua direita, diferentemente da anterior, esses dois pontos formam uma reta de <span class="math inline">\(-45^{\circ}\)</span>, fato que pode ser visto na figura <a href="segmentação.html#fig:houghdoispontosdireita">6.12</a>(b) onde o ponto de encontro das duas curvas acontece em <span class="math inline">\(\theta=-45^{\circ}\)</span> com um valor de <span class="math inline">\(\rho=0\)</span> já que a reta cruza a origem, ou seja, não possui distância em relação a ela.</p>

<div class="figure" style="text-align: center"><span id="fig:houghdoispontosdireita"></span>
<img src="imagens/06-segmentacao/hough_dois_ponto_direita.png" alt="Transformada de Hough para um ponto em -45º." width="75%" />
<p class="caption">
Figura 6.12: Transformada de Hough para um ponto em -45º.
</p>
</div>
<p>Nosso último exemplo contém uma imagem com três pontos, onde temos três tipos de retas possíveis. Observando a figura <a href="segmentação.html#fig:houghtrespontos">6.13</a>(a) podemos ver os pontos a, b e c e as retas que passam por eles d, e e f, e na figura <a href="segmentação.html#fig:houghtrespontos">6.13</a>(b) temos a transformada de Hough para esse imagem, algo interessante de se notar é o fato de a reta que passa pelos pontos b e c ser detectada duas vezes, isso se deve a uma característica da transformada de Hough chamada relação de adjacência reflexiva, ou seja, isso acontece como resultado pela maneira como <span class="math inline">\(\rho\)</span> e <span class="math inline">\(\theta\)</span> mudam de sinal quando chegamos as extremidades de <span class="math inline">\(\pm90^{\circ}\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:houghtrespontos"></span>
<img src="imagens/06-segmentacao/hough_tres_ponto.png" alt="Transformada de Hough para três pontos." width="75%" />
<p class="caption">
Figura 6.13: Transformada de Hough para três pontos.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:houghlineexemplo">6.14</a> temos nosso último exemplo na detecção de linhas, dessa vez realizado em uma imagem real, neste caso primeiramente foi realizado a detecção de bordas pelo método de Canny, como pode ser visto na figura <a href="segmentação.html#fig:houghlineexemplo">6.14</a>(a). Logo após foi realizada a transformação de Hough, com resultado em figura <a href="segmentação.html#fig:houghlineexemplo">6.14</a>(b) e por fim temos a imagem original com as linhas detectadas em figura <a href="segmentação.html#fig:houghlineexemplo">6.14</a>(c). Atenção ao fato de que nem todos os picos da transformada podem ser utilizados como linhas, pois teríamos um número enorme delas, para isso utilizamos um threshold, utilizando somente as linhas que tiverem o número de votos(acumulação na matriz) superior a um valor limítrofe.</p>

<div class="figure" style="text-align: center"><span id="fig:houghlineexemplo"></span>
<img src="imagens/06-segmentacao/hough_line_exemplo.jpg" alt="Resultado da transformada de Hough usada na detecção de linhas em uma imagem." width="95%" />
<p class="caption">
Figura 6.14: Resultado da transformada de Hough usada na detecção de linhas em uma imagem.
</p>
</div>
</div>
<div id="transformada-de-hough-para-detecção-de-círculos" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Transformada de Hough para detecção de círculos</h3>
<p>A transformada de Hough pode ser estendida para detecção de círculos, para isso substituímos a equação da reta pela equação do círculo:
<span class="math display">\[(x-x_0)^2+(y-y_0)^2=r^2\]</span></p>
<p>Nesse caso também andamos por cada pixel das bordas da imagem e o levamos ao espaço de parâmetro com as seguintes equações:</p>
<p><span class="math display">\[x_0=x-r\cos(\theta)\]</span>
e</p>
<p><span class="math display">\[y_0=y-\text{sen}(\theta)\]</span></p>
<p>A diferença é que neste caso o nosso espaço de parâmetro terá três dimensões, isso decorre do fato de que como desenhamos um círculo para cada pixel do círculo da imagem, a variação do diâmetro desse círculo deve levar a uma variação dos círculos descritos no espaço de parâmetros, então além da variação dos valores de <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> também devemos variar os valores de <span class="math inline">\(r\)</span>. Uma representação disso pode ser vista na figura <a href="segmentação.html#fig:houghCircle">6.15</a>(a) onde temos três pixels que definem um círculo, na figura <a href="segmentação.html#fig:houghCircle">6.15</a>(b) temos os círculos no espaço de parâmetros e na figura <a href="segmentação.html#fig:houghCircle">6.15</a>(c) podemos ver um representação de um espaço de parâmetros com diferentes raios.</p>

<div class="figure" style="text-align: center"><span id="fig:houghCircle"></span>
<img src="imagens/06-segmentacao/houghCircle.png" alt="Transformada de Hough para círculos.[18, p. 255]" width="60%" />
<p class="caption">
Figura 6.15: Transformada de Hough para círculos.<span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">18</a>, p. 255]</span>
</p>
</div>
<p>A figura <a href="segmentação.html#fig:moedas">6.16</a> contém uma imagem com algumas moedas, na figura <a href="segmentação.html#fig:houghcircleraios">6.17</a>(a) temos as bordas da imagem detectada com o método de Canny, logo após, na figura <a href="segmentação.html#fig:houghcircleraios">6.17</a>(b) - (f) temos a representação do espaço de Hough para diferentes valores de raio. E na figura <a href="segmentação.html#fig:houghcircleresultado">6.18</a> temos o resultado da detecção de círculo após encontrados os picos do espaço de parâmetros.</p>

<div class="figure" style="text-align: center"><span id="fig:moedas"></span>
<img src="imagens/06-segmentacao/moedas.jpg" alt="Imagem original de moedas. [8, p. 98]" width="55%" />
<p class="caption">
Figura 6.16: Imagem original de moedas. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:houghcircleraios"></span>
<img src="imagens/06-segmentacao/hough_circle_raios.jpg" alt="Canny e espaço de parâmetros. [8, p. 98]" width="100%" />
<p class="caption">
Figura 6.17: Canny e espaço de parâmetros. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:houghcircleresultado"></span>
<img src="imagens/06-segmentacao/hough_circle_resultado.jpg" alt="Resultado final da transformada de Hough para círculos. [8, p. 98]" width="55%" />
<p class="caption">
Figura 6.18: Resultado final da transformada de Hough para círculos. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>
</div>
</div>
<div id="detecção-de-blobs" class="section level2">
<h2><span class="header-section-number">6.4</span> Detecção de blobs</h2>
<p>Blobs, do inglês bolhas, são regiões da imagem em que os pixels têm valores aproximadamente iguais. Uma boa representação - um tanto quanto artificial - disso é a função gaussiana, como pode ser vista na figura <a href="segmentação.html#fig:gaussianblob">6.19</a>(a) e sua representação 2D na figura <a href="segmentação.html#fig:gaussianblob">6.19</a>(b), nela temos um conjunto de pixels com valores bem próximos, que caracterizam um blob.</p>

<div class="figure" style="text-align: center"><span id="fig:gaussianblob"></span>
<img src="imagens/06-segmentacao/gaussian_blob.jpg" alt="Função gaussiana em 3D e 2D." width="75%" />
<p class="caption">
Figura 6.19: Função gaussiana em 3D e 2D.
</p>
</div>
<p>Apesar do exemplo, a detecção de blobs não se restringe a elementos circulares, mas a qualquer conjunto de pixels.</p>
<div id="log" class="section level3">
<h3><span class="header-section-number">6.4.1</span> LoG</h3>
<p>Esse método utiliza o do Laplaciano do Gaussiano, que já foi apresentado anteriormente, mas que em resumo é o cálculo de derivadas segunda em uma imagem que foi anteriormente convolucionada com um filtro gaussiano, isso irá gerar fortes respostas positivas em blobs escuros e negativas em blobs escuros nos blobs de tamanho <span class="math inline">\(\sqrt{2\sigma}\)</span>. Como existe uma relação entre a respostas e o tamanho do desvio padrão, é necessário realizar a operação com uma gama de valores para o sigma, e assim detectar blobs de diferentes tamanhos.</p>

<div class="figure" style="text-align: center"><span id="fig:nasahubbledeep"></span>
<img src="imagens/06-segmentacao/nasa_hubble_deep.jpg" alt="Imagem de Campo Ultraprofundo do Hubble. [19]" width="55%" />
<p class="caption">
Figura 6.20: Imagem de Campo Ultraprofundo do Hubble. <span class="citation">[<a href="#ref-img:hubbledeep" role="doc-biblioref">19</a>]</span>
</p>
</div>
<p>Como podemos ver na figura <a href="segmentação.html#fig:gaussianblob">6.19</a> com diferentes valores de sigma conseguimos detectar objetos de variados tamanhos, como exemplo na figura <a href="segmentação.html#fig:logsigmas">6.21</a>(a) detectamos as estrelas da figura <a href="segmentação.html#fig:nasahubbledeep">6.20</a> que apresentam uma menor resposta ao filtro laplaciano.</p>

<div class="figure" style="text-align: center"><span id="fig:logsigmas"></span>
<img src="imagens/06-segmentacao/log_sigmas.jpg" alt="Laplaciano do Gaussiano com diferentes valores de sigma." width="100%" />
<p class="caption">
Figura 6.21: Laplaciano do Gaussiano com diferentes valores de sigma.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:loghubble">6.22</a> temos o resultado da detecção dos blobs utilizando LoG. Note que nem todas as estrelas foram detectadas, isso se deve ao fato do uso de um valor de threshold, onde definimos que queremos as detecções acima de determinado limiar. Na figura <a href="segmentação.html#fig:loghubblebaixo">6.23</a> podemos ver o resultado utilizando um valor de limiar menor, onde muito mais objetos foram localizados.</p>

<div class="figure" style="text-align: center"><span id="fig:loghubble"></span>
<img src="imagens/06-segmentacao/log_hubble.jpg" alt="Resultado da detecção de blobs com LoG." width="55%" />
<p class="caption">
Figura 6.22: Resultado da detecção de blobs com LoG.
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:loghubblebaixo"></span>
<img src="imagens/06-segmentacao/log_hubble_baixo_threshold.jpg" alt="Resultado da detecção de blobs com LoG com um threshold menor." width="55%" />
<p class="caption">
Figura 6.23: Resultado da detecção de blobs com LoG com um threshold menor.
</p>
</div>
</div>
<div id="dog" class="section level3">
<h3><span class="header-section-number">6.4.2</span> DoG</h3>
<p>Esse método é basicamente o mesmo do anterior, mas possui uma certa vantagem, que é o fato de ele ser mais eficiente. Como também já foi mencionado no tópico na seção anterior é possível aproximar o Laplaciano do Gaussiano através da Diferença do Gaussiano(DoG), ou seja, primeiramente se realiza a filtragem gaussiano com dois sigmas diferentes e se faz a subtração entre os dois. Realizamos esse processo para diferentes pares de valores, obtendo assim o mesmo espaço de escala construído com o processo do LoG. Na figura <a href="segmentação.html#fig:doghubble">6.24</a> temos um exemplo de detecção por DoG.</p>

<div class="figure" style="text-align: center"><span id="fig:doghubble"></span>
<img src="imagens/06-segmentacao/dog_hubble.jpg" alt="Resultado da detecção de blobs com DoG." width="55%" />
<p class="caption">
Figura 6.24: Resultado da detecção de blobs com DoG.
</p>
</div>
</div>
<div id="doh" class="section level3">
<h3><span class="header-section-number">6.4.3</span> DoH</h3>
<p>Uma matriz Hessiana é uma matriz que contém as derivadas de uma função. No nosso caso, utilizamos a Hessiana de ordem 2, pois estamos trabalhando com imagens, que possuem duas dimensões. Ela pode ser representada da seguinte maneira:</p>
<p><span class="math display">\[H[f(x_1, x_2, \dots,x_n)]=
\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2}\\ 
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2}
\end{bmatrix}\]</span></p>
<p>A matriz Hessiana tem muita utilidade pois com ela podemos descrever a curvatura em um ponto da função multivariável, o que no nosso caso pode ajudar a detectar os blobs, já que eles são aglomerados de pixels e devem estar separados do restante da imagem, ou seja, um aglomerado claro em um fundo escuro ou o contrário, e isso irá fazer com que sua função tenha uma mudança de sinal que pode ser detectada utilizando-se as informações da matriz. Além disso, como dito por Herbert Bay et al.<span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">20</a>]</span> os detectores baseados na Hessiana são mais estáveis e repetíveis(tem a mesma resposta para a mesma imagem com diferentes ângulos, iluminações etc.).</p>
<p>Um dos principais algoritmos que fazem uso dessa matriz se chama Speeded Up Robust Features (SURF)<span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">20</a>]</span>, esse método faz uso de várias técnicas que o tornam muito rápido, como seu próprio nome sugere. Uma dessas técnicas é o cálculo da integral da imagem, realizado a partir da soma de todos os pixels de uma área retangular a partir do x atual, sendo que este varia enquanto se é andado pela imagem.</p>

<div class="figure" style="text-align: center"><span id="fig:imageIntegral"></span>
<img src="imagens/06-segmentacao/imageIntegral.png" alt="Integral de uma imagem. [21]" width="55%" />
<p class="caption">
Figura 6.25: Integral de uma imagem. <span class="citation">[<a href="#ref-Cen2016StudyOV" role="doc-biblioref">21</a>]</span>
</p>
</div>
<p>Como pode ser visto na figura, a integral de uma imagem contém a soma das regiões, por exemplo, a primeira posição contém a soma de somente uma célula, no caso 1, a segunda tem a soma de duas células, na primeira linha estamos basicamente somando as células de uma só linha, na segunda começamos a formar regiões retangulares, por exemplo, na segunda linha e terceira coluna temos o valor 6, resultante da soma das seis células da primeira linha com a segunda. Com a integral podemos calcular a área de qualquer região com apenas quatro operações, da seguinte forma:
<span class="math display">\[soma = D+A-B-C\]</span></p>
<p>Onde {A,B,C,D} forma uma região. Como exemplo, caso queiramos calcular a área na região quadrada 2x2 na direita inferior utilizados:
<span class="math display">\[soma = 9 + 1 - 3 - 3 = 4\]</span></p>
<p>Isso nos ajuda na aplicação de box filters, já que precisaríamos da soma de determinadas áreas, e com isso aumentamos a velocidade do método.
Sendo <span class="math inline">\(X=(x,y)\)</span> um ponto em uma imagem, sua matriz Hessiana em <span class="math inline">\(X\)</span> a uma escala é dada por:</p>
<p><span class="math display">\[H(X,\sigma)=\begin{bmatrix}
L_{xx}(X, \sigma) &amp; L_{xy}(X, \sigma)\\ 
L_{xy}(X, \sigma) &amp; L_{yy}(X, \sigma)
\end{bmatrix}\]</span></p>
<p>Onde <span class="math inline">\(L_{xx}(X, \sigma)\)</span> é a convolução da imagem no ponto X com a derivada de segunda ordem gaussiana <span class="math inline">\(\frac{\partial^2g(\sigma)}{\partial x^²}\)</span> e assim por diante<span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">20</a>]</span>. Aqui entra em cena mais um elemento para melhorar a velocidade do algoritmo, Bay, Herbert et al. utilizam box filters para aproximar o filtro gaussiano. Como podemos ver na figura, onde os dois primeiros filtros são os derivativos gaussianos discretizados e os dois últimos são os aproximados a partir de box filters.</p>

<div class="figure" style="text-align: center"><span id="fig:discretizadogaussiano"></span>
<img src="imagens/06-segmentacao/discretizadogaussiano.png" alt="Filtro gaussiano discretizado e aproximado na direção \(y\) e \(xy\). [20]" width="85%" />
<p class="caption">
Figura 6.26: Filtro gaussiano discretizado e aproximado na direção <span class="math inline">\(y\)</span> e <span class="math inline">\(xy\)</span>. <span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">20</a>]</span>
</p>
</div>
<p>Chamamos as derivadas realizadas na imagem de <span class="math inline">\(D_{xx}\)</span>, <span class="math inline">\(D_{yy}\)</span>, <span class="math inline">\(D_{xy}\)</span>. Essas derivadas não são realizadas com somente um valor de <span class="math inline">\(\sigma\)</span>, mas como os detectores anteriores usam uma sequência de valores para assim criar um espaço de escalas e conseguir detectar blobs de diferentes tamanhos. Assim, a determinante da Hessiana é dado por:</p>
<p><span class="math display">\[det(H_{\text{aprox}}) = D_{xx}D_{yy}-(0.9D_{xy})^2\]</span></p>
<p>Sendo que o valor <span class="math inline">\(0.9\)</span> é um peso introduzido pelos autores Bay, Hebert et al. para corrigir as respostas quando utilizamos várias escalas de sigma e obter uma invariância escalar. Na figura temos o resultado de uma detecção de blobs realizada pela Determinante do Hessiano.</p>

<div class="figure" style="text-align: center"><span id="fig:dohhubble"></span>
<img src="imagens/06-segmentacao/doh_hubble.jpg" alt="Resultado da detecção de blobs com DoH." width="55%" />
<p class="caption">
Figura 6.27: Resultado da detecção de blobs com DoH.
</p>
</div>
</div>
</div>
<div id="detecção-de-junções-ou-cantos" class="section level2">
<h2><span class="header-section-number">6.5</span> Detecção de junções ou cantos</h2>
</div>
<div id="segmentação-por-limiarização" class="section level2">
<h2><span class="header-section-number">6.6</span> Segmentação por limiarização</h2>
</div>
<div id="método-de-otsu" class="section level2">
<h2><span class="header-section-number">6.7</span> método de Otsu</h2>
</div>
<div id="segmentação-usando-watersheds-morfológicas" class="section level2">
<h2><span class="header-section-number">6.8</span> Segmentação usando watersheds morfológicas</h2>


</div>
</div>
<h3>Refêrencias</h3>
<div id="refs" class="references">
<div id="ref-gonzalez2010">
<p>[2] R. C. Gonzalez e R. C. Woods, <em>Processamento digital de imagens</em>, 3º ed. São Paulo: Pearson Prentice Hall, 2010.</p>
</div>
<div id="ref-burger2009">
<p>[8] W. Burger, M. J. Burge, M. J. Burge, e M. J. Burge, <em>Principles of digital image processing</em>, vol. 111. Springer, 2009.</p>
</div>
<div id="ref-canny1986computational">
<p>[16] J. Canny, “A computational approach to edge detection”, <em>IEEE Transactions on pattern analysis and machine intelligence</em>, nº 6, p. 679–698, 1986.</p>
</div>
<div id="ref-sonka2014">
<p>[17] M. Sonka, V. Hlavac, e R. Boyle, <em>Image processing, analysis, and machine vision</em>. Cengage Learning, 2014.</p>
</div>
<div id="ref-nixon2019feature">
<p>[18] M. Nixon e A. Aguado, <em>Feature extraction and image processing for computer vision</em>. Academic press, 2019.</p>
</div>
<div id="ref-img:hubbledeep">
<p>[19] Nasa, “Hubble Ultra-Deep Field”. 2004, [Online]. Disponível em: <a href="https://imgsrc.hubblesite.org/hu/db/images/hs-2014-27-a-full_jpg.jpg">https://imgsrc.hubblesite.org/hu/db/images/hs-2014-27-a-full_jpg.jpg</a>.</p>
</div>
<div id="ref-bay2006surf">
<p>[20] H. Bay, T. Tuytelaars, e L. Van Gool, “Surf: Speeded up robust features”, p. 404–417, 2006.</p>
</div>
<div id="ref-Cen2016StudyOV">
<p>[21] K. Cen, “Study of Viola-Jones Real Time Face Detector”, 2016.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="filtros.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="refêrencias.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": null
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/covap-utfpr/pdi/edit/master/06-segmentacao.Rmd",
"text": "Editar "
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"citation_package": "biblatex"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
