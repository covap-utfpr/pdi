<!DOCTYPE html>
<html lang="pt-BR" xml:lang="pt-BR">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens e Visão Computacional</title>
  <meta name="description" content="Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens e Visão Computacional" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens e Visão Computacional" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Segmentação | Material introdutório de Processamento Digital de Imagens e Visão Computacional" />
  
  
  

<meta name="author" content="" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="filtros.html"/>
<link rel="next" href="refêrencias.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="logo"><a href="./"><img src="imagens/logo.jpeg"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Início</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#relação-de-processamento-digital-de-imagem-visão-computacional-e-computação-gráfica"><i class="fa fa-check"></i><b>1.1</b> Relação de Processamento Digital de Imagem, Visão Computacional e Computação Gráfica</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#aplicações-processamento-digital-de-imagens"><i class="fa fa-check"></i><b>1.2</b> Aplicações Processamento Digital de Imagens</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#etapas-do-processamento-e-análise-de-imagens"><i class="fa fa-check"></i><b>1.3</b> Etapas do Processamento e Análise de Imagens</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html"><i class="fa fa-check"></i><b>2</b> Formação da imagem</a><ul>
<li class="chapter" data-level="2.1" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#câmera-pinhole-e-geometria"><i class="fa fa-check"></i><b>2.1</b> Câmera pinhole e geometria</a></li>
<li class="chapter" data-level="2.2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#lentes"><i class="fa fa-check"></i><b>2.2</b> Lentes</a></li>
<li class="chapter" data-level="2.3" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#sensor"><i class="fa fa-check"></i><b>2.3</b> Sensor</a></li>
<li class="chapter" data-level="2.4" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#amostragem-e-quantização"><i class="fa fa-check"></i><b>2.4</b> Amostragem e Quantização</a><ul>
<li class="chapter" data-level="2.4.1" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#amostragem"><i class="fa fa-check"></i><b>2.4.1</b> Amostragem</a></li>
<li class="chapter" data-level="2.4.2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#quantização"><i class="fa fa-check"></i><b>2.4.2</b> Quantização</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#definição-de-imagem-digital"><i class="fa fa-check"></i><b>2.5</b> Definição de imagem digital</a></li>
<li class="chapter" data-level="2.6" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#resolução-espacial-e-de-intensidade"><i class="fa fa-check"></i><b>2.6</b> Resolução espacial e de intensidade</a></li>
<li class="chapter" data-level="2.7" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#pixels"><i class="fa fa-check"></i><b>2.7</b> Pixels</a><ul>
<li class="chapter" data-level="2.7.1" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#vizinhança"><i class="fa fa-check"></i><b>2.7.1</b> Vizinhança</a></li>
<li class="chapter" data-level="2.7.2" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#conectividade"><i class="fa fa-check"></i><b>2.7.2</b> Conectividade</a></li>
<li class="chapter" data-level="2.7.3" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#adjacência"><i class="fa fa-check"></i><b>2.7.3</b> Adjacência</a></li>
<li class="chapter" data-level="2.7.4" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#componente-conexa"><i class="fa fa-check"></i><b>2.7.4</b> Componente Conexa</a></li>
<li class="chapter" data-level="2.7.5" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#medidas-de-distância"><i class="fa fa-check"></i><b>2.7.5</b> Medidas de Distância</a></li>
<li class="chapter" data-level="2.7.6" data-path="formação-da-imagem.html"><a href="formação-da-imagem.html#operações-lógico-aritméticas"><i class="fa fa-check"></i><b>2.7.6</b> Operações Lógico-aritméticas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html"><i class="fa fa-check"></i><b>3</b> Transformacões geométricas</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#definição"><i class="fa fa-check"></i><b>3.1</b> Definição</a></li>
<li class="chapter" data-level="3.2" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#sistema-de-coordenadas-objetos-2d-e-3d"><i class="fa fa-check"></i><b>3.2</b> Sistema de coordenadas objetos (2D e 3D)</a></li>
<li class="chapter" data-level="3.3" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#representação-vetorial-e-matricial-de-imagens-digitalizadas"><i class="fa fa-check"></i><b>3.3</b> Representação Vetorial e Matricial de Imagens digitalizadas</a></li>
<li class="chapter" data-level="3.4" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#matrizes-em-computação-gráfica"><i class="fa fa-check"></i><b>3.4</b> Matrizes em Computação gráfica</a></li>
<li class="chapter" data-level="3.5" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformações-em-pontos-e-objetos"><i class="fa fa-check"></i><b>3.5</b> Transformações em Pontos e Objetos</a></li>
<li class="chapter" data-level="3.6" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformação-de-translação"><i class="fa fa-check"></i><b>3.6</b> Transformação de Translação</a></li>
<li class="chapter" data-level="3.7" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformação-de-escala"><i class="fa fa-check"></i><b>3.7</b> Transformação de Escala</a></li>
<li class="chapter" data-level="3.8" data-path="transformacões-geométricas.html"><a href="transformacões-geométricas.html#transformação-de-rotação"><i class="fa fa-check"></i><b>3.8</b> Transformação de Rotação</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html"><i class="fa fa-check"></i><b>4</b> Transformações radiométricas</a><ul>
<li class="chapter" data-level="4.1" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#transformação-linear"><i class="fa fa-check"></i><b>4.1</b> Transformação Linear</a></li>
<li class="chapter" data-level="4.2" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#transformação-logarítmica"><i class="fa fa-check"></i><b>4.2</b> Transformação Logarítmica</a></li>
<li class="chapter" data-level="4.3" data-path="transformações-radiométricas.html"><a href="transformações-radiométricas.html#transformação-de-potência"><i class="fa fa-check"></i><b>4.3</b> Transformação de Potência</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="filtros.html"><a href="filtros.html"><i class="fa fa-check"></i><b>5</b> Filtros</a><ul>
<li class="chapter" data-level="5.1" data-path="filtros.html"><a href="filtros.html#convolução"><i class="fa fa-check"></i><b>5.1</b> Convolução</a><ul>
<li class="chapter" data-level="5.1.1" data-path="filtros.html"><a href="filtros.html#definção-matemática-de-convolução"><i class="fa fa-check"></i><b>5.1.1</b> Definção matemática de convolução</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="filtros.html"><a href="filtros.html#média"><i class="fa fa-check"></i><b>5.2</b> Média</a></li>
<li class="chapter" data-level="5.3" data-path="filtros.html"><a href="filtros.html#mediana"><i class="fa fa-check"></i><b>5.3</b> Mediana</a></li>
<li class="chapter" data-level="5.4" data-path="filtros.html"><a href="filtros.html#gaussiano"><i class="fa fa-check"></i><b>5.4</b> Gaussiano</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="segmentação.html"><a href="segmentação.html"><i class="fa fa-check"></i><b>6</b> Segmentação</a><ul>
<li class="chapter" data-level="6.1" data-path="segmentação.html"><a href="segmentação.html#detecção-por-descontinuidade"><i class="fa fa-check"></i><b>6.1</b> Detecção por descontinuidade</a><ul>
<li class="chapter" data-level="6.1.1" data-path="segmentação.html"><a href="segmentação.html#detecção-de-pontos-isolados"><i class="fa fa-check"></i><b>6.1.1</b> Detecção de pontos isolados</a></li>
<li class="chapter" data-level="6.1.2" data-path="segmentação.html"><a href="segmentação.html#detecção-de-linhas"><i class="fa fa-check"></i><b>6.1.2</b> Detecção de linhas</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="segmentação.html"><a href="segmentação.html#detecção-de-bordas"><i class="fa fa-check"></i><b>6.2</b> Detecção de Bordas</a><ul>
<li class="chapter" data-level="6.2.1" data-path="segmentação.html"><a href="segmentação.html#modelos-de-bordas"><i class="fa fa-check"></i><b>6.2.1</b> Modelos de Bordas</a></li>
<li class="chapter" data-level="6.2.2" data-path="segmentação.html"><a href="segmentação.html#método-do-gradiente-roberts-prewitt-sobel"><i class="fa fa-check"></i><b>6.2.2</b> Método do gradiente ( Roberts, Prewitt, Sobel)</a></li>
<li class="chapter" data-level="6.2.3" data-path="segmentação.html"><a href="segmentação.html#método-de-marr-hildreth"><i class="fa fa-check"></i><b>6.2.3</b> Método de Marr-Hildreth</a></li>
<li class="chapter" data-level="6.2.4" data-path="segmentação.html"><a href="segmentação.html#método-de-canny"><i class="fa fa-check"></i><b>6.2.4</b> Método de Canny</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="segmentação.html"><a href="segmentação.html#transformada-de-hough"><i class="fa fa-check"></i><b>6.3</b> Transformada de Hough</a><ul>
<li class="chapter" data-level="6.3.1" data-path="segmentação.html"><a href="segmentação.html#transformada-de-hough-para-detecção-de-linhas"><i class="fa fa-check"></i><b>6.3.1</b> Transformada de Hough para detecção de linhas</a></li>
<li class="chapter" data-level="6.3.2" data-path="segmentação.html"><a href="segmentação.html#transformada-de-hough-para-detecção-de-círculos"><i class="fa fa-check"></i><b>6.3.2</b> Transformada de Hough para detecção de círculos</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="segmentação.html"><a href="segmentação.html#detecção-de-quinas"><i class="fa fa-check"></i><b>6.4</b> Detecção de Quinas</a><ul>
<li class="chapter" data-level="6.4.1" data-path="segmentação.html"><a href="segmentação.html#detector-de-quinas-de-moravec"><i class="fa fa-check"></i><b>6.4.1</b> Detector de Quinas de Moravec</a></li>
<li class="chapter" data-level="6.4.2" data-path="segmentação.html"><a href="segmentação.html#detector-de-quinas-de-harris"><i class="fa fa-check"></i><b>6.4.2</b> Detector de Quinas de Harris</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="segmentação.html"><a href="segmentação.html#detecção-de-blobs"><i class="fa fa-check"></i><b>6.5</b> Detecção de Blobs</a><ul>
<li class="chapter" data-level="6.5.1" data-path="segmentação.html"><a href="segmentação.html#log"><i class="fa fa-check"></i><b>6.5.1</b> LoG</a></li>
<li class="chapter" data-level="6.5.2" data-path="segmentação.html"><a href="segmentação.html#dog"><i class="fa fa-check"></i><b>6.5.2</b> DoG</a></li>
<li class="chapter" data-level="6.5.3" data-path="segmentação.html"><a href="segmentação.html#doh"><i class="fa fa-check"></i><b>6.5.3</b> DoH</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="segmentação.html"><a href="segmentação.html#limiarização"><i class="fa fa-check"></i><b>6.6</b> Limiarização</a><ul>
<li class="chapter" data-level="6.6.1" data-path="segmentação.html"><a href="segmentação.html#limiarização-global-simples"><i class="fa fa-check"></i><b>6.6.1</b> Limiarização global simples</a></li>
<li class="chapter" data-level="6.6.2" data-path="segmentação.html"><a href="segmentação.html#limiarização-pelo-método-de-otsu"><i class="fa fa-check"></i><b>6.6.2</b> Limiarização pelo Método de Otsu</a></li>
<li class="chapter" data-level="6.6.3" data-path="segmentação.html"><a href="segmentação.html#uso-de-suavização-para-limiarização"><i class="fa fa-check"></i><b>6.6.3</b> Uso de suavização para limiarização</a></li>
<li class="chapter" data-level="6.6.4" data-path="segmentação.html"><a href="segmentação.html#uso-de-bordas-para-limiarização"><i class="fa fa-check"></i><b>6.6.4</b> Uso de bordas para limiarização</a></li>
<li class="chapter" data-level="6.6.5" data-path="segmentação.html"><a href="segmentação.html#limiares-múltiplos"><i class="fa fa-check"></i><b>6.6.5</b> Limiares Múltiplos</a></li>
<li class="chapter" data-level="6.6.6" data-path="segmentação.html"><a href="segmentação.html#limiarização-variável"><i class="fa fa-check"></i><b>6.6.6</b> Limiarização variável</a></li>
<li class="chapter" data-level="6.6.7" data-path="segmentação.html"><a href="segmentação.html#particionamento-da-imagem"><i class="fa fa-check"></i><b>6.6.7</b> Particionamento da imagem</a></li>
<li class="chapter" data-level="6.6.8" data-path="segmentação.html"><a href="segmentação.html#limiarização-variável-baseada-nas-propriedades-locais-da-imagem"><i class="fa fa-check"></i><b>6.6.8</b> Limiarização variável baseada nas propriedades locais da imagem</a></li>
<li class="chapter" data-level="6.6.9" data-path="segmentação.html"><a href="segmentação.html#usando-média-de-movimento"><i class="fa fa-check"></i><b>6.6.9</b> Usando média de movimento</a></li>
<li class="chapter" data-level="6.6.10" data-path="segmentação.html"><a href="segmentação.html#limiarização-baseada-em-diversas-variáveis"><i class="fa fa-check"></i><b>6.6.10</b> Limiarização baseada em diversas variáveis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="refêrencias.html"><a href="refêrencias.html"><i class="fa fa-check"></i>Refêrencias</a></li>
<li class="divider"></li>
<li><center>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
<img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" />
</a></li></center>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Material introdutório de Processamento Digital de Imagens e Visão Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="segmentação" class="section level1">
<h1><span class="header-section-number">Capítulo 6</span> Segmentação</h1>
<p>A segmentação subdivide uma imagem para detecção de regiões ou objetos para uma determinada aplicação. Os principais métodos de segmentação utilizam a distribuição dos valores de intensidade, seja pelos padrões de similaridade ou de descontinuidade <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 454]</span>. Nas técnicas de similaridade, as imagens são divididas em regiões semelhantes com base em um conjunto de características. Na segmentação por descontinuidade se consideram as mudanças abruptas de intensidades, caracterizadas por pontos isolados, linhas ou bordas na imagem.</p>
<div id="detecção-por-descontinuidade" class="section level2">
<h2><span class="header-section-number">6.1</span> Detecção por descontinuidade</h2>
<p>Bordas podem ser descritas como o limite ou a fronteira entre duas regiões onde ocorre uma variação brusca de intensidade em uma determinada direção. Uma linha pode ser vista como um segmento de borda em que a intensidade do fundo de cada lado da linha ou é muito superior ou muito inferior à intensidade dos <em>pixels</em> da linha. Linhas com o comprimento e largura iguais a um <em>pixel</em> são tratados como pontos isolados <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 456]</span>.
Os métodos de detecção de bordas se baseiam no comportamento das derivadas, que podem detectar mudanças locais abruptas. Em uma função digital, as derivadas são aproximadas como termos de diferenças. Aproximações podem ser obtidas por meio de expansões em séries de Taylor, como demonstrado no livro “Processamento digital de imagens” <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 457]</span>, em que os resultados para a primeira e a segunda ordem no ponto <span class="math inline">\(x\)</span> de uma função <span class="math inline">\(f(x)\)</span> estão descritos respectivamente:</p>
<p><span class="math display">\[\frac{\delta f}{\delta x} = f&#39;(x) = f(x+1) - f(x)\]</span>
<span class="math display">\[\frac{\delta^2 f}{\delta x^2} = f&#39;&#39;(x) = f(x+1) + f(x-1) - 2f(x)\]</span></p>
<p>Para avaliar o comportamento das derivadas na transição de intensidades apresentamos na Figura <a href="segmentação.html#fig:imagemDerivadas">6.1</a> um perfil de intensidade horizontal (linha de digitalização) de uma imagem, juntamente com os resultados das duas últimas equações para alguns pontos. A imagem contém vários objetos sólidos, uma linha e um ponto interno de ruído, e a linha de digitalização está próxima ao centro, incluindo o ponto isolado. A Figura <a href="segmentação.html#fig:imagemDerivadas">6.1</a> (c) mostra uma simplificação do perfil e como as derivadas de primeira e segunda ordem se comportam quando encontram um ponto isolado, uma linha e as bordas dos objetos.</p>
<p>Com base nos resultados das equações na Figura <a href="segmentação.html#fig:imagemDerivadas">6.1</a> se observa que atendem as propriedades das derivadas. No início e ao longo da rampa de intensidade, a derivada de primeira ordem é diferente de zero, enquanto a segunda derivada é diferente de zero apenas no início e no fim da rampa. Estes comportamentos indicam que as derivadas de primeira ordem produzem <strong>bordas grossas, e as de segunda ordem produzem bordas mais finas</strong> <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 458]</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemDerivadas"></span>
<img src="imagens/06-segmentacao/imagemDerivadas.png" alt="(a) Imagem. (b) Perfil de intensidade horizontal no centro da imagem. (c) Perfil simplificado e resultados das derivadas. [2, p. 457]" width="55%" />
<p class="caption">
Figura 6.1: (a) Imagem. (b) Perfil de intensidade horizontal no centro da imagem. (c) Perfil simplificado e resultados das derivadas. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 457]</span>
</p>
</div>
<p>No ponto de ruído, a resposta para a derivada de segunda ordem é mais forte do que para a primeira derivada. <strong>Derivadas de segunda ordem acentuam as respostas em mudanças bruscas,</strong> podendo melhorar pequenos detalhes <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 458]</span>. Na linha com detalhes bem finos, a derivada de segunda ordem também tem maior magnitude. Nota-se nas bordas em rampa e nas bordas em degrau, que a segunda derivada tem sinais opostos (negativo para positivo ou vice-versa) conforme entra e sai da borda, o que caracteriza uma <strong>“borda dupla”</strong>. O sinal da segunda derivada também pode ser utilizado para determinar se uma transição em uma borda é de claro para escuro (segunda derivada negativa) ou de escuro para claro (segunda derivada positiva) <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 458]</span>.</p>
<div id="detecção-de-pontos-isolados" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Detecção de pontos isolados</h3>
<p>Considerando que as derivadas de segunda ordem têm uma resposta mais forte aos detalhes finos, o operador diferencial laplaciano:</p>
<p><span class="math display">\[\nabla^2f(x,y) = \frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2}\]</span>
é ideal para a detecção de pontos <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 459]</span>. As aproximações das derivadas de segunda ordem por termos de diferenças vistas podem ser estendidas para os dois termos do laplaciano, respectivamente:</p>
<p><span class="math display">\[\frac{\partial^2f}{\partial x^2} = f(x+1, y) + f(x-1, y) -2f(x,y)\]</span>
<span class="math display">\[\frac{\partial^2f}{\partial y^2} = f(x, y+1) + f(x, y-1) -2f(x,y)\]</span>
Ao se relacionar essas três últimas equações, obtém-se o laplaciano discreto:</p>
<p><span class="math display">\[\nabla^2f(x,y) = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) -4f(x,y)\]</span></p>
<p>Essa equação pode ser implementada utilizando a máscara de filtragem identificada na Figura <a href="segmentação.html#fig:mascarasLaplacianas">6.2</a> (a). Para incluir as direções diagonais na definição do laplaciano digital se acrescenta mais dois termos a esta equação, um para cada direção diagonal. A Figura <a href="segmentação.html#fig:mascarasLaplacianas">6.2</a> (b) mostra a máscara de filtragem desta atualização que inclui as diagonais.</p>

<div class="figure" style="text-align: center"><span id="fig:mascarasLaplacianas"></span>
<img src="imagens/06-segmentacao/mascarasLaplacianas.png" alt="(a) Máscara referente a equação laplaciana discreta. (b) Máscara que inclui as diagonais. [2, p. 106]" width="55%" />
<p class="caption">
Figura 6.2: (a) Máscara referente a equação laplaciana discreta. (b) Máscara que inclui as diagonais. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 106]</span>
</p>
</div>
<p>A intensidade de um ponto isolado será muito diferente do seu entorno, portanto, ao aplicar a máscara, as únicas diferenças de intensidade relevantes serão as mais altas, maiores que um limite determinado (<span class="math inline">\(T\)</span>) para serem consideradas pontos isolados <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 459]</span>. Para detectar o ponto se utiliza a seguinte expressão:</p>
<p><span class="math display">\[
g(x,y) = 
\begin{cases}
  1,\ se\ R(x,y) \geq T
  \\0,\ caso\ contrário
\end{cases}
\]</span>
em que <span class="math inline">\(g\)</span> é a imagem de saída, <span class="math inline">\(T\)</span> é um limiar não negativo, e <span class="math inline">\(R\)</span> é o operador laplaciano. O ponto isolado será detectado no local <span class="math inline">\((x, y)\)</span> em que a máscara está centrada se o módulo da resposta nesse ponto exceder o limiar estabelecido. Os pontos detectados são rotulados como <span class="math inline">\(1\)</span> na imagem de saída, e todos os outros são rotulados <span class="math inline">\(0\)</span>, o que produz uma imagem binária.</p>
</div>
<div id="detecção-de-linhas" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Detecção de linhas</h3>
<p>Semelhante à detecção de pontos isolados, as derivadas de segunda ordem geram respostas mais fortes na detecção de linhas, e produzem linhas mais finas do que as derivadas de primeira ordem <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 460]</span>. Ao utilizar a máscara laplaciana da Figura (fig:mascarasLaplacianas) sobre a imagem de um componente em um circuito eletrônico (parte de uma conexão <em>wire-bond</em>), representado na Figura (fig:imagemDeteccaoLinhas) (a), obtém-se como resultado a Figura (fig:imagemDeteccaoLinhas) (b). Na seção ampliada da Figura (fig:imagemDeteccaoLinhas) (b), as linhas mais claras identificam os pontos positivos, o cinza escuro são os valores negativos, e o cinza médio representa zero. O efeito de linha dupla ao se utilizar a segunda derivada é evidente na seção ampliada.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemDeteccaoLinhas"></span>
<img src="imagens/06-segmentacao/imagemDeteccaoLinhas.png" alt="(a) Imagem do circuito. (b) Resultado do filtro laplaciano. (c) Valor absoluto do filtro laplaciano. (d) Valores positivos do filtro laplaciano. [2, p. 460]" width="55%" />
<p class="caption">
Figura 6.3: (a) Imagem do circuito. (b) Resultado do filtro laplaciano. (c) Valor absoluto do filtro laplaciano. (d) Valores positivos do filtro laplaciano. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 460]</span>
</p>
</div>
<p>Para destacar as linhas após a aplicação do filtro e remover os valores negativos pode ser utilizado o módulo dos valores calculados ou utilizar apenas os valores positivos do laplaciano <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 460]</span>, os resultados destas metodologias estão identificados na Figura (fig:imagemDeteccaoLinhas) (c) e Figura (fig:imagemDeteccaoLinhas) (d), respectivamente. Nota-se que as linhas geradas pela abordagem do módulo são mais grossas, pois a espessura é o dobro se comparada com a outra metodologia. Nas duas situações, as linhas mais largas que o tamanho do filtro laplaciano são separadas por um “vale” de zeros. A detecção de linhas é ideal quando a espessura é menor que o detector, ao contrário se recomenda tratar o elemento como uma região e utilizar outros métodos <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 460]</span>.</p>
<p>O filtro laplaciano na Figura <a href="segmentação.html#fig:mascarasLaplacianas">6.2</a> é isotrópico, assim a sua resposta independe da direção <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 460]</span>. No caso das linhas pode ser interessante a detecção em apenas uma determinada direção, utilizando, por exemplo, uma das máscaras apresentadas na Figura <a href="segmentação.html#fig:mascarasDeteccaoLinhas">6.4</a>. Para a primeira máscara da Figura <a href="segmentação.html#fig:mascarasDeteccaoLinhas">6.4</a>, os sinais mais fortes ocorrem em linhas horizontais da imagem que passam pela linha do meio da máscara. O segundo filtro detecta melhor as linhas com <span class="math inline">\(45°\)</span> de inclinação; o terceiro filtro para linhas verticais e o quarto, para linhas com <span class="math inline">\(-45º\)</span> de inclinação. Vale destacar que estamos utilizando a convenção de que os eixos da imagem têm sua origem no canto superior esquerdo, com o eixo <span class="math inline">\(x\)</span> positivo apontando para baixo, e o eixo <span class="math inline">\(y\)</span> positivo se estendendo à direita. Os ângulos das linhas são medidos em relação ao eixo <span class="math inline">\(x\)</span> positivo.</p>

<div class="figure" style="text-align: center"><span id="fig:mascarasDeteccaoLinhas"></span>
<img src="imagens/06-segmentacao/mascarasDeteccaoLinhas.png" alt="Máscaras para detecção de linhas em uma determinada direção. [2, p. 461]" width="55%" />
<p class="caption">
Figura 6.4: Máscaras para detecção de linhas em uma determinada direção. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 461]</span>
</p>
</div>
<p>Quando o objetivo é detectar todas as linhas da imagem em uma direção específica se aplica a máscara associada a essa direção e se define um limiar (<span class="math inline">\(T\)</span>) para selecionar os sinais mais fortes. Para os quatro últimos filtros apresentados, as linhas de <span class="math inline">\(1\)</span> <em>pixel</em> de espessura apresentam os maiores resultados <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 462]</span>.</p>
</div>
</div>
<div id="detecção-de-bordas" class="section level2">
<h2><span class="header-section-number">6.2</span> Detecção de Bordas</h2>
<div id="modelos-de-bordas" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Modelos de Bordas</h3>
<p>Na Figura <a href="segmentação.html#fig:modelosBordas">6.5</a> estão os principais modelos de borda, que são classificados de acordo com os perfis de intensidade. A primeira borda, borda em degrau, apresenta uma transição entre dois níveis de intensidade e são consideradas ideais com uma distância de <span class="math inline">\(1\)</span> <em>pixel</em>. Na prática, as bordas nas imagens digitais não apresentam uma transição tão bem definida, assim modelos mais apropriados consideram um perfil de rampa como na Figura <a href="segmentação.html#fig:modelosBordas">6.5</a> (b) <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 462]</span>. Quanto mais indefinida é a transição da borda, menor é a inclinação da rampa. Em vez de uma borda com <span class="math inline">\(1\)</span> <em>pixel</em> de espessura, todos os pontos na rampa fazem parte da borda.
Figura - Modelos de bordas com seus respectivos perfis de intensidade.</p>

<div class="figure" style="text-align: center"><span id="fig:modelosBordas"></span>
<img src="imagens/06-segmentacao/modelosBordas.png" alt="(a) Borda degrau. (b) Borda rampa. (c) Borda telhado. [2, p. 462]" width="55%" />
<p class="caption">
Figura 6.5: (a) Borda degrau. (b) Borda rampa. (c) Borda telhado. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 462]</span>
</p>
</div>
<p>No terceiro modelo de borda, Figura <a href="segmentação.html#fig:modelosBordas">6.5</a> (c), em forma de telhado ou <em>roof edge</em>, a base (largura) de uma borda é definida pela espessura e a nitidez da linha. Quando a base é igual <span class="math inline">\(1\)</span> <em>pixel</em> de espessura, uma borda em forma de telhado é definida como uma linha <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 462]</span>.</p>
<p>As imagens da Figura <a href="segmentação.html#fig:derivadasImagensRuidosas">6.6</a> não apresentam ruídos, entretanto os modelos de detecção devem considerar que as bordas estejam desfocadas e com ruídos. Na primeira coluna da Figura estão três bordas de perfil rampa com diferentes níveis de ruídos, e abaixo de cada imagem está o perfil horizontal de intensidade que passa pelo centro da imagem. A primeira imagem no canto esquerdo não apresenta ruído, e as outras duas imagens da primeira coluna foram alteradas com ruído gaussiano aditivo com média zero e desvio padrão de <span class="math inline">\(0.1\)</span> e <span class="math inline">\(1.0\)</span> níveis de intensidade, respectivamente.</p>

<div class="figure" style="text-align: center"><span id="fig:derivadasImagensRuidosas"></span>
<img src="imagens/06-segmentacao/derivadasImagensRuidosas.png" alt="Primeira coluna: imagens e perfis de intensidade de uma borda em declive corrompida pelo ruído gaussiano aleatório de desvio padrão \(0.0\), \(0.1\) e \(1.0\) níveis de intensidade, respectivamente. Segunda coluna: imagens da primeira derivada. Terceira coluna: imagens da segunda derivada. [2, p. 465]" width="55%" />
<p class="caption">
Figura 6.6: Primeira coluna: imagens e perfis de intensidade de uma borda em declive corrompida pelo ruído gaussiano aleatório de desvio padrão <span class="math inline">\(0.0\)</span>, <span class="math inline">\(0.1\)</span> e <span class="math inline">\(1.0\)</span> níveis de intensidade, respectivamente. Segunda coluna: imagens da primeira derivada. Terceira coluna: imagens da segunda derivada. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 465]</span>
</p>
</div>
<p>Na segunda e terceira coluna estão identificados, respectivamente, a primeira e a segunda derivada dos perfis de intensidade da primeira coluna. A primeira derivada é utilizada para detectar bordas, pois identifica pontos de transição abrupta de intensidade na imagem. Para o resultado da primeira derivada na primeira linha, os valores na rampa são positivos e, nas regiões de intensidade constante é igual a zero. As duas faixas pretas na imagem da parte superior da coluna central são os resultados iguais a zero da primeira derivada, e os valores constantes estão identificados como cinza claro.</p>
<p>Como as bordas são uma transição de uma região escura para uma região branca, a segunda derivada na terceira coluna é positiva no início da rampa e negativa no final. A linha que passa por estes dois resultados da derivada se intercepta com o eixo de intensidade zero, gerando o ponto de cruzamento por zero que é utilizado para localizar o centro de bordas espessas <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 464]</span>. Nas regiões de intensidade constante as derivadas de segunda ordem também são zero, e se apresentam na cor cinza claro nas imagens da terceira coluna. As linhas finas verticais brancas e pretas são os resultados positivos e negativos da segunda derivada.</p>
<p>Mesmo não sendo perceptível os ruídos nas imagens da segunda e terceira linha, eles apresentaram um impacto significativo nas derivadas, principalmente na derivada de segunda ordem que é mais sensível aos ruídos. Quanto maior o ruído mais difícil de se associar com os perfis das derivadas, dificultando a detecção de bordas. Este comportamento pode ser tratado com a suavização da imagem em uma etapa anterior a segmentação <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 464]</span>.</p>
</div>
<div id="método-do-gradiente-roberts-prewitt-sobel" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Método do gradiente ( Roberts, Prewitt, Sobel)</h3>
<p>Na detecção de bordas, as derivadas de primeira ordem são calculadas utilizando a magnitude do gradiente, que é um vetor cuja a direção indica os pontos de maior variação de intensidade <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 155]</span>. Na figura indica que a direção do gradiente sempre será perpendicular à direção tangente da borda. Para uma função <span class="math inline">\(f(x, y)\)</span>, o gradiente de <span class="math inline">\(f\)</span> nas coordenadas <span class="math inline">\((x, y)\)</span> na forma matricial é expresso como:</p>
<p><span class="math display">\[\nabla f 
= \begin{bmatrix}
G_x
\\ G_y
\end{bmatrix}
= \begin{bmatrix}
\frac{\partial f}{\partial x}
\\ \frac{\partial f}{\partial y}
\end{bmatrix}\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:vetorGradiente"></span>
<img src="imagens/06-segmentacao/vetorGradiente.png" alt="Vetor gradiente \(\nabla f\) em uma borda. [3, p. 155]" width="55%" />
<p class="caption">
Figura 6.7: Vetor gradiente <span class="math inline">\(\nabla f\)</span> em uma borda. <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 155]</span>
</p>
</div>
<p>O módulo ou magnitude (tamanho) do vetor <span class="math inline">\(\nabla f\)</span> é dado como <span class="math inline">\(M(x,y)\)</span>:
<span class="math display">\[M(x,y) = \sqrt{G^2_x + G^2_y}\]</span></p>
<p>O módulo do gradiente é a maior taxa de variação de <span class="math inline">\(f(x,y)\)</span> na direção do vetor gradiente. Devido ao custo computacional, a magnitude do gradiente é aproximada pelo uso dos valores absolutos <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 155]</span>:
<span class="math display">\[M(x,y) \simeq |G_x| + |G_y|\]</span>
A direção do vetor gradiente é dada pelo ângulo:
<span class="math display">\[
\alpha(x,y) = 
tg^{-1}
\begin{bmatrix}
\frac{G_y}{G_x}
\end{bmatrix}
\]</span></p>
<p>medido em relação ao eixo <span class="math inline">\(x\)</span>. Da mesma forma que a magnitude <span class="math inline">\(M(x, y)\)</span>, ou imagem gradiente, o ângulo <span class="math inline">\(\alpha(x, y)\)</span> também é uma imagem do mesmo tamanho que a original formado pela divisão da imagem <span class="math inline">\(G_y\)</span> por <span class="math inline">\(G_x\)</span> <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 466]</span>.</p>
<p>Para calcular as derivadas parciais <span class="math inline">\(\partial f/ \partial x\)</span> e <span class="math inline">\(\partial f/ \partial y\)</span> no caso de quantidades digitais é necessário utilizar aproximações discretas e, em seguida, determinar as máscaras de filtragem correspondentes. Uma forma de aproximação é considerar a diferença entre os elementos da vizinhança para calcular a magnitude do gradiente <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 157]</span>. Ao se utilizar as diferenças cruzadas como na seguinte equação:</p>
<p><span class="math display">\[M(x,y) \simeq |f(x,y) - f(x+1, y+1)| + |f(x,y+1) - f(x+1, y)|\]</span>
é o mesmo que aplicar os filtros de tamanho 2x2 da Figura <a href="segmentação.html#fig:operadorRoberts">6.8</a> e somar os resultados absolutos.</p>

<div class="figure" style="text-align: center"><span id="fig:operadorRoberts"></span>
<img src="imagens/06-segmentacao/operadorRoberts.png" alt="Operador de Roberts. [3, p. 157]" width="55%" />
<p class="caption">
Figura 6.8: Operador de Roberts. <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 157]</span>
</p>
</div>
<p>Estes operadores, conhecidos como operadores de Roberts, foram uma das primeiras tentativas de usar máscaras 2-D, entretanto não são tão úteis quanto máscaras simétricas ao redor do ponto central, em que as menores são de tamanho 3×3 <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 467]</span>. As aproximações mais simples para as derivadas parciais usando máscaras de tamanho 3×3 são dadas por:</p>
<p><span class="math display">\[ 
\begin{split}
M(x,y) &amp;\simeq
|[f(x+1,y-1) + f(x+1,y) + f(x+1,y+1)]-\\
 &amp;\ \ \ \ \ [f(x-1,y-1) + f(x-1,y) + f(x-1,y+1)]+\\
 &amp;\ \ \ \ \ [f(x-1,y+1) + f(x,y+1) + f(x+1,y+1)]-\\
 &amp;\ \ \ \ \ [f(x-1,y-1) + f(x,y-1) + f(x+1,y-1)]|
\end{split}
\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:operadorPrewitt"></span>
<img src="imagens/06-segmentacao/operadorPrewitt.png" alt="Operador de Prewitt. [3, p. 158]" width="55%" />
<p class="caption">
Figura 6.9: Operador de Prewitt. <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 158]</span>
</p>
</div>
<p>A equação pode ser implementada aplicando as máscaras da Figura <a href="segmentação.html#fig:operadorSobel">6.10</a>, que recebem o nome de operadores de Prewitt. Uma variação deste último método utiliza o valor <span class="math inline">\(2\)</span> como peso no centro do coeficiente <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 158]</span>:</p>
<p><span class="math display">\[ 
\begin{split}
M(x,y) &amp;\simeq
|[f(x+1,y-1) + 2f(x+1,y) + 2f(x+1,y+1)]-\\
 &amp;\ \ \ \ \ [f(x-1,y-1) + 2f(x-1,y) + f(x-1,y+1)]+\\
 &amp;\ \ \ \ \ [f(x-1,y+1) + 2f(x,y+1) + f(x+1,y+1)]-\\
 &amp;\ \ \ \ \ [f(x-1,y-1) + 2f(x,y-1) + f(x+1,y-1)]|
\end{split}
\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:operadorSobel"></span>
<img src="imagens/06-segmentacao/operadorSobel.png" alt="Operador de Sobel. [3, p. 158]" width="55%" />
<p class="caption">
Figura 6.10: Operador de Sobel. <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 158]</span>
</p>
</div>
<p>O resultado das equações pode ser obtido com a soma dos valores absolutos dos resultados das máscaras na Figura <a href="segmentação.html#fig:operadorSobel">6.10</a>, chamadas de operadores de Sobel. Mesmo que as máscaras de Prewitt sejam mais simples de implementar do que as máscaras de Sobel, as de Sobel são mais utilizadas por melhor suavização, diminuindo os ruídos <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 468]</span>.</p>
<p>Ao calcular a magnitude como uma aproximação da soma dos valores absolutos dos componentes de gradiente <span class="math inline">\(G_x\)</span> e <span class="math inline">\(G_y\)</span> (Equação) pode se perder a propriedade isotrópica dos filtros. No caso das máscaras de Sobel e de Prewitt este problema não ocorre, pois dão resultados isotrópicos apenas para bordas verticais e horizontais, e que são independentes da equação ou equação <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 468]</span>.</p>
</div>
<div id="método-de-marr-hildreth" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Método de Marr-Hildreth</h3>
<p>Nos métodos de detecção de bordas utilizando a derivada de segunda ordem se observa maior sensibilidade aos ruídos, assim se recomenda um pré-processamento de suavização. A técnica de detecção proposta por Marr e Hildreth (1980), por exemplo, combina a filtragem Gaussiana com o operador Laplaciano <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 163]</span>. Após a suavização da imagem com o filtro gaussiano, as bordas são identificadas pelos pontos de cruzamento por zero da segunda derivada.</p>
<p>Um aspecto que torna a técnica interessante para imagens de diferentes escalas é que considera as características da borda e dos ruídos, empregando-se operadores de tamanho mais adequado para cada imagem <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 470]</span>. Operadores de maior tamanho são recomendados para detectar bordas borradas, enquanto operadores menores detectam melhor detalhes finos com foco nítido. Como o laplaciano é isotrópico, respondendo de forma igual às variações nas diferentes direções, evita-se a utilização de várias máscaras <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 472]</span>.</p>
<p>O operador proposto por Marr e Hildreth é obtido pela convolução:
<span class="math display">\[g(x,y) = \nabla^2[G(x,y)*f(x,y)]\]</span>
em que <span class="math inline">\(f(x,y)\)</span> é a imagem, <span class="math inline">\(\nabla^2\)</span> é o operador laplaciano, (<span class="math inline">\(\partial^2 f / \partial x^2 + \partial^2 f / \partial y^2\)</span>), e <span class="math inline">\(G\)</span> é a função gaussiana 2-D:
<span class="math display">\[G(x,y) = e^{-\frac{x^2 + y^b}{2\sigma^2}}\]</span>
com desvio padrão <span class="math inline">\(\sigma\)</span>. Em razão da linearidade das operações, a ordem da diferenciação e da convolução podem ser alteradas <span class="citation">[<a href="#ref-pedrini2008" role="doc-biblioref">3</a>, p. 163]</span>, assim após a diferenciação da expressão gaussiana se obtém o Laplaciano da Gaussiana (LoG):
<span class="math display">\[\nabla^2G(x,y) = 
\begin{bmatrix}
\frac{x^2 + y^2 - \sigma^2}{\sigma^4} e^{-\frac{x^2 + y^b}{2\sigma^2}}
\end{bmatrix}\]</span></p>
<p>As máscaras podem ser geradas pela amostragem da equação e ajustando os coeficientes para que a soma seja zero. Um exemplo de máscara 5x5 que atende ao Laplaciano da Gaussiana está na Figura <a href="segmentação.html#fig:laplacianoGaussiana">6.11</a> (d). O comportamento dessa máscara se aproxima do efeito da função LoG na Figura <a href="segmentação.html#fig:laplacianoGaussiana">6.11</a> (a), em que o termo positivo e central é rodeado por uma região negativa cujo os valores aumentam ao se distanciar da origem, e uma região externa com zeros <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 472]</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:laplacianoGaussiana"></span>
<img src="imagens/06-segmentacao/laplacianoGaussiana.png" alt="(a) Gráfico 3-D do negativo de LoG. (b) Imagem do negativo de LoG. (c) Seção transversal de (a). (d) Aproximação de máscara 5x5 para LoG. [2, p. 471]" width="55%" />
<p class="caption">
Figura 6.11: (a) Gráfico 3-D do negativo de LoG. (b) Imagem do negativo de LoG. (c) Seção transversal de (a). (d) Aproximação de máscara 5x5 para LoG. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 471]</span>
</p>
</div>
<p>Devido ao formato na Figura <a href="segmentação.html#fig:laplacianoGaussiana">6.11</a> a função LoG é conhecida como operador de chapéu mexicano. Na Figura <a href="segmentação.html#fig:laplacianoGaussiana">6.11</a> o gráfico 3-D, a imagem e a seção transversal se referem ao negativo da função LoG. Na seção transversal (Figura <a href="segmentação.html#fig:laplacianoGaussiana">6.11</a> (c)), o cruzamento por zero do LoG ocorre em <span class="math inline">\(x^2 + y^2 = 2 \sigma^2\)</span> , definindo um círculo centrado na origem e de raio <span class="math inline">\(2\sigma\)</span>.</p>
<p>Na prática, o filtro LoG é gerado pelas seguintes etapas <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 472]</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Define-se um filtro <span class="math inline">\(n\)</span>×<span class="math inline">\(n\)</span> gaussiano a partir de amostragem com a equação. Lembrando da sugestão que para tamanho do filtro gaussiano <span class="math inline">\(n\)</span> seja o menor inteiro ímpar maior ou igual a <span class="math inline">\(6\sigma\)</span>.</p></li>
<li><p>Após suavização da imagem com o filtro gaussiano, o resultado é processado pelo laplaciano, por exemplo, com uma máscara 3×3 na Figura.</p></li>
<li><p>Na imagem resultante da etapa anterior são encontrados os pontos de cruzamento por zero. Estes pontos podem ser identificados em um <em>pixel</em>, <span class="math inline">\(p\)</span>, com base na sua vizinhança de 3x3. No caso de <span class="math inline">\(p\)</span> ser um cruzamento por zero, pelo menos dois de seus vizinhos opostos devem apresentar sinais diferentes. Neste caso são realizados quatro testes: esquerda/direita, acima/abaixo e com as duas diagonais. Quando se utiliza um limiar para identificar o cruzamento por zero, tanto os sinais dos vizinhos opostos devem ser diferentes quanto o valor absoluto da diferença numérica deve ultrapassar o limiar para que o ponto <span class="math inline">\(p\)</span> seja um cruzamento por zero.</p></li>
</ol>
<p>O filtro LoG também pode ser aproximado com a convolução de uma máscara gerada a partir da diferença de duas funções gaussianas (DoG) <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 473]</span>:
<span class="math display">\[DoG(x,y) = \frac{1}{2\pi \sigma^2_1}  e^  {-\frac{x^2+y^2}{2\sigma^2_1}}
-
\frac{1}{2\pi \sigma^2_2}  e^  {-\frac{x^2+y^2}{2\sigma^2_2}}\]</span></p>
<p>com <span class="math inline">\(\sigma_1 &gt; \sigma_2\)</span>. Marr e Hildreth mostraram que para <span class="math inline">\(\sigma_2/\sigma_1 = 1.6\)</span> o operador tem maior aproximação com a função LoG <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 473]</span>. Para que LoG e DoG tenham os mesmos cruzamentos por zero se sugere que se mantenha a seguinte relação para o valor de <span class="math inline">\(\sigma\)</span> em LoG:
<span class="math display">\[\sigma^2 = \frac{\sigma^2_1\sigma^2_2}{\sigma^2_1 - \sigma^2_2}
\ln 
\begin{bmatrix}
\frac{\sigma^2_1}{\sigma^2_2}
\end{bmatrix}\]</span></p>
<p>Para estabelecer uma mesma escala de amplitude no resultado dos dois operadores, ocorre um ajuste para o mesmo valor na origem em ambas as funções <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>.</p>
</div>
<div id="método-de-canny" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Método de Canny</h3>
<p>O algoritmo de Canny recebeu esse nome em alusão a John Canny, que o propôs em seu artigo, “A computational Approach to Edge Detection”<span class="citation">[<a href="#ref-canny1986computational" role="doc-biblioref">17</a>]</span>, publicado em 1986. Sua formulação se baseava em três pontos principais:</p>
<ul>
<li>Uma baixa taxa de erro, ou seja, todas as bordas presentes na imagem devem ser encontradas e não deve haver respostas espúrias.</li>
<li>O segundo critério diz que as bordas detectadas devem estar bem localizadas, em outras palavras, elas devem estar o mais próximo possível das bordas verdadeiras.</li>
<li>O terceiro e último critério diz que se deve minimizar o número de máximos locais em torno da borda verdadeira, para que não sejam encontrados múltiplos pixels de borda onde deve haver somente um.</li>
</ul>
<p>Em seu trabalho, Canny buscou encontrar soluções ótimas, matematicamente, que obedecessem os três critérios. Apesar disso, é muito difícil, ou impossível, encontrar uma solução que satisfaça completamente os objetivos descritos<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>. Todavia é possível utilizar uma aproximação por meio de otimização numérica com as bordas em degrau em um exemplo 1-D que contenham ruído branco gaussiano e mostrar que uma boa aproximação para um ótimo detector de bordas é a primeira derivada de uma gaussiana<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>:</p>
<p><span class="math display">\[\frac{\mathrm{d} }{\mathrm{d} x}e^{\frac{-x^2}{2\sigma^2}} = \frac{-x}{\sigma^2}e^{\frac{-x^2}{2\sigma^2}}\]</span></p>
<p>Canny demonstrou que a utilização dessa aproximação pode ser feita com uma taxa 20% inferior à solução numérica, o que a torna praticamente imperceptível para muitas das aplicações<span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 474]</span>.
A ideia anterior foi imaginada em um aspecto 1D, precisamos agora, expandir esse conceito para uma generalização 2D. Uma borda de degrau pode ser caracterizada pela sua posição, orientação e possível magnitude. Aplicar um filtro Gaussiano em uma imagem e depois diferenciá-la forma um simples e efetivo operador direcional<span class="citation">[<a href="#ref-sonka2014" role="doc-biblioref">18</a>, p. 145]</span>. Digamos então que <span class="math inline">\(f(x,y)\)</span> seja uma imagem e <span class="math inline">\(G(x,y)\)</span> a função gaussiana:</p>
<p><span class="math display">\[G(x,y) = e^{-\frac{x^2+y^2}{2\sigma^2}}\]</span></p>
<p>Temos como saída a imagem suavizada:</p>
<p><span class="math display">\[f_s(x,y)=G(x,y)*f(x,y)\]</span></p>
<p>E após isso realizamos o cálculo da magnitude e direção do gradiente:</p>
<p><span class="math display">\[M(x,y) = \sqrt{g_x^2+g_y^2}\]</span>
<span class="math display">\[\alpha(x,y)= \tan^{-1}\left ( \frac{g_y}{g_x} \right )\]</span></p>
<p>onde <span class="math inline">\(g_x=\partial f_s/\partial x\)</span> e <span class="math inline">\(g_y=\partial f_s/\partial y\)</span>. Para o cálculo das derivadas parciais podemos utilizar tanto Prewitt quanto Sobel. Como essa primeira etapa utiliza operadores que calculam as primeiras derivadas, acabamos com bordas grossas, e o terceiro objetivo da proposta de Canny é ter bordas com único ponto, por isso o próximo passo é a de afinar as bordas encontradas. O método que usaremos para isso é chamado supressão dos não máximos. Esse processo tem como base a discretização das direções da normal da borda(vetor gradiente), ou seja, em uma região 3x3 temos 4 direções possíveis, como pode ser visto na figura <a href="segmentação.html#fig:edgeorientation">6.12</a>(c), sendo que consideramos 4 pois é contando as duas direções, como exemplo, consideramos um borda de 45º se ela se encontra entre +157,5º e +112,5º ou -67,5º e -22,5º.
Na figura <a href="segmentação.html#fig:edgeorientation">6.12</a>(a) temos um exemplo de duas orientações que podem existir em uma borda horizontal, e na figura <a href="segmentação.html#fig:edgeorientation">6.12</a>(b) podemos ver a normal de uma borda horizontal e o intervalo de valores onde a direção do vetor gradiente pode existir.</p>

<div class="figure" style="text-align: center"><span id="fig:edgeorientation"></span>
<img src="imagens/06-segmentacao/edge_orientation.png" alt="Discretização das direções. (a)Borda horizontal. (b) Intervalo dos possíveis valores do ângulo, normal da borda, para uma borda horizontal. (c) Intervalo de valores do ângulo da normal para os diferentes tipos de borda. [2, p. 475]" width="70%" />
<p class="caption">
Figura 6.12: Discretização das direções. (a)Borda horizontal. (b) Intervalo dos possíveis valores do ângulo, normal da borda, para uma borda horizontal. (c) Intervalo de valores do ângulo da normal para os diferentes tipos de borda. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 475]</span>
</p>
</div>
<p>Se consideramos <span class="math inline">\(d1\)</span>, <span class="math inline">\(d2\)</span>, <span class="math inline">\(d3\)</span> e <span class="math inline">\(d4\)</span> como as direções possíveis em uma área 3x3, podemos formular o seguinte esquema de supressão de não máximos de uma região 3x3 centrada em todos os pontos <span class="math inline">\((x,y)\)</span> de <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 475]</span>:
- Encontrar a direção <span class="math inline">\(d_k\)</span> que está mais perto de <span class="math inline">\(\alpha (x,y)\)</span>.
- Se o valor de <span class="math inline">\(M(x,y)\)</span> for inferior a pelo menos um dos seus dois vizinhos ao logo de <span class="math inline">\(d_k\)</span>, deixe <span class="math inline">\(g_N(x,y)=0\)</span>(supressão); caso contrário, deixe <span class="math inline">\(g_N(x,y)=M(x,y)\)</span>.
Onde <span class="math inline">\(g_N(x,y)\)</span> é a imagem suprimida.
A última operação a ser realizada é a limiarização, para se remover os pontos de falsas bordas. Aqui usaremos a limiarização por histerese que utiliza dois limiares, um baixo(<span class="math inline">\(T_L\)</span>) e um alto (<span class="math inline">\(T_H\)</span>), sendo que Canny sugeriu, em seu trabalho, que a razão entre o limiar alto para o baixo deva ser de dois ou três para um.
Podemos imaginar essa limiarização da seguinte forma, criamos duas imagens adicionais:</p>
<p><span class="math display">\[g_{NH}(x,y) = g_N(x,y)\geq T_H\]</span> e <span class="math display">\[g_{NL}(x,y) = g_N(x,y)\geq T_L\]</span></p>
<p>Onde <span class="math inline">\(g_{NH}(x,y)\)</span> e <span class="math inline">\(g_{NL}(x,y)\)</span> são definidas inicialmente como <span class="math inline">\(0\)</span>. Temos então que <span class="math inline">\(g_{NH}(x,y)\)</span>conterá os pixels que são maiores que o nosso limiar e <span class="math inline">\(g_{NL}(x,y)\)</span> terá os pixels que estão acima do nosso limiar baixo, o que significa que ele contém os pixels que se encontram no meio dos dois limiares mais o que está acima do limiar alto, temos então que remover esses pixels, o que significa:
<span class="math display">\[g_{NL}(x,y)=g_{NL}(x,y)-g_{NH}(x,y)\]</span></p>
<p>Podemos chamar os pixels de <span class="math inline">\(g_{NH}(x,y)\)</span> de pixels fortes e os de <span class="math inline">\(g_{NL}(x,y)\)</span> de fracos. Ao final dessa limiarização todos os pixels fortes são classificados como borda válida, mas com falhas, que nos leva a outro processo:</p>
<ul>
<li>Localizar o próximo pixel borda a ser revisado em <span class="math inline">\(g_{NH}(x,y)\)</span>, chamaremos esse pixel de p.</li>
<li>Classificar todos os pixels fracos de <span class="math inline">\(g_{NL}(x,y)\)</span> que tenham conexão, como a conectividade-8, como bordas válidas.</li>
<li>Quando todos os pixels de <span class="math inline">\(g_{NL}(x,y)\)</span> Se forem analisados, pulamos para 4, senão voltamos para 1.</li>
<li>Zerar todos os pixels de <span class="math inline">\(g_{NL}(x,y)\)</span> que não são bordas válidas.</li>
</ul>
<p>Ao final desses processos teremos a imagem de saída do algoritmo de Canny. Como dito por <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 476]</span>, o uso de duas imagens <span class="math inline">\(g_{NH}(x,y)\)</span> e <span class="math inline">\(g_{NL}(x,y)\)</span> é uma boa maneira para se explicar o algoritmo de uma maneira simples, mas na prática isso pode ser feito diretamente na imagem <span class="math inline">\(g_N(x,y)\)</span>.
Por fim, sumarizando os passos do algoritmo, com um exemplo:</p>
<ol style="list-style-type: decimal">
<li>Imagem original</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:original"></span>
<img src="imagens/06-segmentacao/original.jpg" alt="Imagem original." width="50%" />
<p class="caption">
Figura 6.13: Imagem original.
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Aplicação do filtro gaussiano para suavizar a imagem.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:gaussian"></span>
<img src="imagens/06-segmentacao/gaussian.jpg" alt="Imagem filtrada com filtro gaussiano." width="50%" />
<p class="caption">
Figura 6.14: Imagem filtrada com filtro gaussiano.
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Cálculo da magnitude do gradiente e dos ângulos.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:derivadas"></span>
<img src="imagens/06-segmentacao/derivadas.jpg" alt="(a) Sobel na direção vertical. (b) Sobel na direção horizontal. (c) Gradiente. (d) Angulos. [8, p. 98]" width="75%" />
<p class="caption">
Figura 6.15: (a) Sobel na direção vertical. (b) Sobel na direção horizontal. (c) Gradiente. (d) Angulos. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li>Aplicação da supressão não máxima para afinar as bordas.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:supressao"></span>
<img src="imagens/06-segmentacao/supressao.jpg" alt="Resultado da supressão não máxima." width="50%" />
<p class="caption">
Figura 6.16: Resultado da supressão não máxima.
</p>
</div>
<ol start="6" style="list-style-type: decimal">
<li>Usar limiarização por histerese e análise de conectividade para detectar e conectar as bordas.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:threshold"></span>
<img src="imagens/06-segmentacao/threshold.jpg" alt="Resultado da histerese e conecção de bordas." width="50%" />
<p class="caption">
Figura 6.17: Resultado da histerese e conecção de bordas.
</p>
</div>
<ol start="7" style="list-style-type: decimal">
<li>Resultado final.</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:canny"></span>
<img src="imagens/06-segmentacao/canny.jpg" alt="Resultado final da detecção de bordas de Canny." width="50%" />
<p class="caption">
Figura 6.18: Resultado final da detecção de bordas de Canny.
</p>
</div>
</div>
</div>
<div id="transformada-de-hough" class="section level2">
<h2><span class="header-section-number">6.3</span> Transformada de Hough</h2>
<p>A Transformada de Hough é uma técnica utilizada para detectar formas em imagens, sejam elas linhas, círculos ou elipses. Apesar de ela ser muito utilizada e ter sido criada para detecção principalmente de linhas, ela pode ser usada para a detecção de outras formas, como dito anteriormente.</p>
<div id="transformada-de-hough-para-detecção-de-linhas" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Transformada de Hough para detecção de linhas</h3>
<p>Para começar a entender essa transformada, imaginemos que temos um ponto <span class="math inline">\((x_i, y_i)\)</span> no plano <span class="math inline">\(xy\)</span> e a equação da reta <span class="math inline">\(y_i=ax_i+b\)</span>. Pelo ponto <span class="math inline">\((x_i, y_i)\)</span> passam infinitas retas e todas satisfazem a equação. Podemos escrever a equação anterior em relação a <span class="math inline">\(b\)</span>, ou seja, <span class="math inline">\(b=-x_ia+y_i\)</span>, o que nos leva ao plano <span class="math inline">\(ab\)</span>(espaço de parâmetros) onde essa nova equação gerará uma única reta.</p>
<p>Agora imaginemos um outro ponto <span class="math inline">\((x_j, y_j)\)</span> no plano <span class="math inline">\(xy\)</span>, podemos também levá-lo ao plano ab com a equação <span class="math inline">\(b=-x_ja+y_j\)</span>. Como podemos ver na figura <a href="segmentação.html#fig:planoxy">6.19</a>(b) as duas retas geradas no plano <span class="math inline">\(ab\)</span> se cruzam nas coordenadas <span class="math inline">\((a&#39;, b&#39;)\)</span>, e esse ponto de cruzamento representa a reta que cruza os dois pontos no plano <span class="math inline">\(xy\)</span>, como podemos ver na mesma representação <a href="segmentação.html#fig:planoxy">6.19</a>(b). Na realidade, todos os pontos pertencentes a reta definida por esses dois pontos em <span class="math inline">\(xy\)</span> tem sua reta respectiva em <span class="math inline">\(ab\)</span> e todas elas se cruzam no ponto <span class="math inline">\((a&#39;, b&#39;)\)</span>, isso nos dá uma maneira de realizar a detecção de bordas, pois podemos imaginar essa reta como nossa borda, assim, para achá-la basta localizar o ponto no espaço de parâmetros onde um grande número de retas se cruzam.</p>

<div class="figure" style="text-align: center"><span id="fig:planoxy"></span>
<img src="imagens/06-segmentacao/planoxy.png" alt="Plano xy e ab. [2, p. 483]" width="65%" />
<p class="caption">
Figura 6.19: Plano xy e ab. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 483]</span>
</p>
</div>
<p>Ocorre um pequeno problema nessa forma, pois quando a reta se aproxima da direção vertical, <span class="math inline">\(ab\)</span> se aproxima do infinito. Para resolver essa dificuldade, em vez de levarmos os pontos a retas no espaço <span class="math inline">\(ab\)</span> cartesiano utilizamos um espaço em coordenadas polares. Para isso utilizamos a seguinte equação:
<span class="math display">\[\rho=x\cos{\theta}+y\ sen{\ \theta}\]</span>
Na figura <a href="segmentação.html#fig:planoxyrhotheta">6.20</a>(a) podemos ver isso de maneira gráfica, temos que p corresponde à distância da origem até a reta. Cada uma das curvas senoidais da figura <a href="segmentação.html#fig:planoxyrhotheta">6.20</a>(b) representa um conjunto de linhas que cruzam os dois pontos da figura <a href="segmentação.html#fig:planoxyrhotheta">6.20</a>(a), sendo que na interseção das curvas temos a reta que cruza esses pontos.</p>

<div class="figure" style="text-align: center"><span id="fig:planoxyrhotheta"></span>
<img src="imagens/06-segmentacao/planoxyrhotheta.png" alt="Imagem de ônibus com filtro de aguçamento e de suavização [8, p. 98]" width="90%" />
<p class="caption">
Figura 6.20: Imagem de ônibus com filtro de aguçamento e de suavização <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>
<p>A figura <a href="segmentação.html#fig:planoxyrhotheta">6.20</a>(c) mostra como fazemos a representação do espaço , usamos uma matriz onde esse espaço é subdividido em várias células, chamadas células acumuladoras. Os valores de <span class="math inline">\(\theta_{\text{min}}\)</span> e <span class="math inline">\(\theta_{\text{max}}\)</span> são geralmente <span class="math inline">\(-90^{\circ}\leq \theta\leq90^{\circ}\)</span> e os valores de <span class="math inline">\(\rho_min\)</span> e <span class="math inline">\(\rho_max\)</span> são <span class="math inline">\(-D\leq\rho\leq D\)</span>, onde <span class="math inline">\(D\)</span> é o comprimento da diagonal da imagem, ou seja, <span class="math inline">\(D=\sqrt{vertical^2+horizontal^2}\)</span>. O que fazemos então é andar por todos os pontos de borda da imagem de entrada e calcular o valor de a partir da equação apresentada anteriormente usando o valor de <span class="math inline">\((x,y)\)</span> e variando o ângulo , com isso a cada valor do ângulo teremos um diferente e somamos mais um na célula correspondente da matriz acumuladora, que inicialmente é toda preenchida com zeros. Ao final de todo o processo termos determinadas células com valores mais altos, essas são conhecidas como picos e correspondem ao cruzamento de duas ou mais curvas senoidais do plano o que corresponde a uma linha ligando pontos no plano <span class="math inline">\(xy\)</span>.</p>
<p>A seguir temos um exemplo, que nos ajuda a entender e ver na prática o funcionamento da transformada de Hough. A figura <a href="segmentação.html#fig:houghumponto">6.21</a>(a) contém uma imagem de tamanho 101x101 com um ponto no centro, ou seja <span class="math inline">\((x,y)=(50,50)\)</span> e a figura <a href="segmentação.html#fig:houghumponto">6.21</a>(b) contém a matriz acumuladora da transformada, onde podemos ver a curva senóide formada pelo ponto. Verificando os valores nela vemos que para <span class="math inline">\(\rho=-90^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50 \cdot \cos(-90^{\circ})+50\cdot\text{sen}(-90^{\circ}) = -50\]</span>
para <span class="math inline">\(\theta=90^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50\cdot \cos(90^{\circ})+50\cdot\text{sen}(90^{\circ})=50\]</span>
para <span class="math inline">\(\theta=45^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50\cdot \cos(45^{\circ})+50\cdot \text{sen}(45^{\circ})\approx70,71\]</span>
e para <span class="math inline">\(\theta=-45^{\circ}\)</span> temos:</p>
<p><span class="math display">\[\rho=50\cdot\cos(-45º)+50\cdot \text{sen}(-45º)=0\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:houghumponto"></span>
<img src="imagens/06-segmentacao/hough_um_ponto.jpg" alt="Transformada de Hough para um ponto." width="75%" />
<p class="caption">
Figura 6.21: Transformada de Hough para um ponto.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.22</a>(a) temos dois pontos, a e b, onde foi realizada a transformada de Hough que tem como espaço de saída a figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.22</a>(b). A reta que passa por esses dois pontos, chamada de reta c é representada por uma reta pontilhada na figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.22</a>(a) e na figura <a href="segmentação.html#fig:houghdoispontosesquerda">6.22</a>(b) temos o ponto no plano que representa essa reta, ou seja, uma reta a uma distância <span class="math inline">\(\rho\approx70,71\)</span> da origem com ângulo de <span class="math inline">\(45^{\circ}\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:houghdoispontosesquerda"></span>
<img src="imagens/06-segmentacao/hough_dois_ponto_esquerda.png" alt="Transformada de Hough para um ponto em 45º." width="75%" />
<p class="caption">
Figura 6.22: Transformada de Hough para um ponto em 45º.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:houghdoispontosdireita">6.23</a>(a) temos mais um exemplo, desta vez com um ponto localizado a sua direita, diferentemente da anterior, esses dois pontos formam uma reta de <span class="math inline">\(-45^{\circ}\)</span>, fato que pode ser visto na figura <a href="segmentação.html#fig:houghdoispontosdireita">6.23</a>(b) onde o ponto de encontro das duas curvas acontece em <span class="math inline">\(\theta=-45^{\circ}\)</span> com um valor de <span class="math inline">\(\rho=0\)</span> já que a reta cruza a origem, ou seja, não possui distância em relação a ela.</p>

<div class="figure" style="text-align: center"><span id="fig:houghdoispontosdireita"></span>
<img src="imagens/06-segmentacao/hough_dois_ponto_direita.png" alt="Transformada de Hough para um ponto em -45º." width="75%" />
<p class="caption">
Figura 6.23: Transformada de Hough para um ponto em -45º.
</p>
</div>
<p>Nosso último exemplo contém uma imagem com três pontos, onde temos três tipos de retas possíveis. Observando a figura <a href="segmentação.html#fig:houghtrespontos">6.24</a>(a) podemos ver os pontos a, b e c e as retas que passam por eles d, e e f, e na figura <a href="segmentação.html#fig:houghtrespontos">6.24</a>(b) temos a transformada de Hough para esse imagem, algo interessante de se notar é o fato de a reta que passa pelos pontos b e c ser detectada duas vezes, isso se deve a uma característica da transformada de Hough chamada relação de adjacência reflexiva, ou seja, isso acontece como resultado pela maneira como <span class="math inline">\(\rho\)</span> e <span class="math inline">\(\theta\)</span> mudam de sinal quando chegamos as extremidades de <span class="math inline">\(\pm90^{\circ}\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:houghtrespontos"></span>
<img src="imagens/06-segmentacao/hough_tres_ponto.png" alt="Transformada de Hough para três pontos." width="75%" />
<p class="caption">
Figura 6.24: Transformada de Hough para três pontos.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:houghlineexemplo">6.25</a> temos nosso último exemplo na detecção de linhas, dessa vez realizado em uma imagem real, neste caso primeiramente foi realizado a detecção de bordas pelo método de Canny, como pode ser visto na figura <a href="segmentação.html#fig:houghlineexemplo">6.25</a>(a). Logo após foi realizada a transformação de Hough, com resultado em figura <a href="segmentação.html#fig:houghlineexemplo">6.25</a>(b) e por fim temos a imagem original com as linhas detectadas em figura <a href="segmentação.html#fig:houghlineexemplo">6.25</a>(c). Atenção ao fato de que nem todos os picos da transformada podem ser utilizados como linhas, pois teríamos um número enorme delas, para isso utilizamos um threshold, utilizando somente as linhas que tiverem o número de votos(acumulação na matriz) superior a um valor limítrofe.</p>

<div class="figure" style="text-align: center"><span id="fig:houghlineexemplo"></span>
<img src="imagens/06-segmentacao/hough_line_exemplo.jpg" alt="Resultado da transformada de Hough usada na detecção de linhas em uma imagem." width="95%" />
<p class="caption">
Figura 6.25: Resultado da transformada de Hough usada na detecção de linhas em uma imagem.
</p>
</div>
</div>
<div id="transformada-de-hough-para-detecção-de-círculos" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Transformada de Hough para detecção de círculos</h3>
<p>A transformada de Hough pode ser estendida para detecção de círculos, para isso substituímos a equação da reta pela equação do círculo:
<span class="math display">\[(x-x_0)^2+(y-y_0)^2=r^2\]</span></p>
<p>Nesse caso também andamos por cada pixel das bordas da imagem e o levamos ao espaço de parâmetro com as seguintes equações:</p>
<p><span class="math display">\[x_0=x-r\cos(\theta)\]</span>
e</p>
<p><span class="math display">\[y_0=y-\text{sen}(\theta)\]</span></p>
<p>A diferença é que neste caso o nosso espaço de parâmetro terá três dimensões, isso decorre do fato de que como desenhamos um círculo para cada pixel do círculo da imagem, a variação do diâmetro desse círculo deve levar a uma variação dos círculos descritos no espaço de parâmetros, então além da variação dos valores de <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> também devemos variar os valores de <span class="math inline">\(r\)</span>. Uma representação disso pode ser vista na figura <a href="segmentação.html#fig:houghCircle">6.26</a>(a) onde temos três pixels que definem um círculo, na figura <a href="segmentação.html#fig:houghCircle">6.26</a>(b) temos os círculos no espaço de parâmetros e na figura <a href="segmentação.html#fig:houghCircle">6.26</a>(c) podemos ver um representação de um espaço de parâmetros com diferentes raios.</p>

<div class="figure" style="text-align: center"><span id="fig:houghCircle"></span>
<img src="imagens/06-segmentacao/houghCircle.png" alt="Transformada de Hough para círculos.[19, p. 255]" width="60%" />
<p class="caption">
Figura 6.26: Transformada de Hough para círculos.<span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 255]</span>
</p>
</div>
<p>A figura <a href="segmentação.html#fig:moedas">6.27</a> contém uma imagem com algumas moedas, na figura <a href="segmentação.html#fig:houghcircleraios">6.28</a>(a) temos as bordas da imagem detectada com o método de Canny, logo após, na figura <a href="segmentação.html#fig:houghcircleraios">6.28</a>(b) - (f) temos a representação do espaço de Hough para diferentes valores de raio. E na figura <a href="segmentação.html#fig:houghcircleresultado">6.29</a> temos o resultado da detecção de círculo após encontrados os picos do espaço de parâmetros.</p>

<div class="figure" style="text-align: center"><span id="fig:moedas"></span>
<img src="imagens/06-segmentacao/moedas.jpg" alt="Imagem original de moedas. [8, p. 98]" width="55%" />
<p class="caption">
Figura 6.27: Imagem original de moedas. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:houghcircleraios"></span>
<img src="imagens/06-segmentacao/hough_circle_raios.jpg" alt="Canny e espaço de parâmetros. [8, p. 98]" width="100%" />
<p class="caption">
Figura 6.28: Canny e espaço de parâmetros. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:houghcircleresultado"></span>
<img src="imagens/06-segmentacao/hough_circle_resultado.jpg" alt="Resultado final da transformada de Hough para círculos. [8, p. 98]" width="55%" />
<p class="caption">
Figura 6.29: Resultado final da transformada de Hough para círculos. <span class="citation">[<a href="#ref-burger2009" role="doc-biblioref">8</a>, p. 98]</span>
</p>
</div>
</div>
</div>
<div id="detecção-de-quinas" class="section level2">
<h2><span class="header-section-number">6.4</span> Detecção de Quinas</h2>
<p>Quinas são pontos chaves na visão computacional por serem muito úteis na descrição e correspondência de objetos usando poucos dados. E para identificação dos pontos, existem diferentes métodos, dentre eles o mais comum é o de Harris, que é o sucessor do de Moravec <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 178]</span>.</p>
<div id="detector-de-quinas-de-moravec" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Detector de Quinas de Moravec</h3>
<p>Moravec obtém sua medida de curvatura através de uma variação média de intensidade em quatro direções principais: <span class="math inline">\((0,1), (0,-1), (1,0)\)</span> e <span class="math inline">\((-1,0)\)</span>. Isso é feito através da seguinte equação, considerando a análise sobre o <span class="math inline">\(pixel(x,y)\)</span>, o deslocamento <span class="math inline">\((u,v)\)</span> e a janela <span class="math inline">\(2w+1\)</span> <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 185]</span>.</p>
<p><span class="math display">\[E_{u,v}(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}[P_{x+i,\ y+j} - P_{x+i+u,\ y+j+v}]^2\]</span>
Essa equação também aproxima a função de autocorrelação na direção <span class="math inline">\((u,v)\)</span> <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 186]</span>.</p>
<p>O detector de Moravec apesar de ser intuitivo seu funcionamento, ele considera apenas um pequeno conjunto de mudanças possíveis. Então, Harris propôs ainda avaliar a autocorrelação, mas por uma expressão analítica <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 185]</span>.</p>
</div>
<div id="detector-de-quinas-de-harris" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Detector de Quinas de Harris</h3>
<p>O detector de Harris é desenvolvido na ideia de Moravec e sua equação, mas com uma abordagem mais complexa. Harris assume que <span class="math inline">\(P_{x+i+u,\ y+j+v}\)</span> possa ser estimado pela série de Taylor de primeira ordem <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 193]</span>. Dessa forma,</p>
<p><span class="math display">\[P_{x+i+u,\ y+j+v} = P_{x+i,\ y+j} + \frac{\partial{P_{x+i,\ y+j}}}{\partial x}u + \frac{\partial{P_{x+i,\ y+j}}}{\partial y}v \]</span></p>
<p>Substituindo na equação de Moravec
<span class="math display">\[E_{u,v}(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}[\frac{\partial{P_{x+i,\ y+j}}}{\partial x}u + \frac{\partial{P_{x+i,\ y+j}}}{\partial y}v]^2\]</span>
E expandindo a potência
<span class="math display">\[E_{u,v}(x,y) = A(x,y)u^2 + 2C(x,y)uv + B(x,y)v^2\]</span>
Esta última equação pode ser representada forma de matriz. Representação útil para compreensão mais à frente neste tópico <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 187]</span>.
<span class="math display">\[
\begin{split}
E_{u,v}(x,y) &amp;= 
\begin{bmatrix}u &amp; v\end{bmatrix}
\begin{bmatrix}A(x,y) &amp; C(x,y)\\ C(x,y) &amp; B(x,y)\end{bmatrix}
\begin{bmatrix}u \\ v\end{bmatrix}
\\&amp;= D^TMD
\end{split}
\]</span>
onde
<span class="math display">\[A(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w}(\frac{\partial P_{x+i, y+j}}{\partial x})^2\]</span>
<span class="math display">\[B(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w} (\frac{\partial P_{x+i, y+j}}{\partial y})^2\]</span>
<span class="math display">\[C(x,y) = \sum_{i=-w}^{w} \sum_{j=-w}^{w} (\frac{\partial P_{x+i, y+j}}{\partial x})(\frac{\partial P_{x+i, y+j}}{\partial y})\]</span>
Como <span class="math inline">\(E_{u.v}(x,y)\)</span> tem a forma de uma função quadrática, então possui dois eixos principais. Podemos rotacioná-la a fim de alinhar seus eixos com os do sistema de coordenadas, obtendo <span class="math inline">\(F_{u,v}(x,y)\)</span> <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 187]</span>.
<span class="math display">\[F_{u,v}(x,y) = \alpha(x,y)^2u^2 + \beta(x,y)^2v^2\]</span>
Ou em sua forma matricial. Note que são rotacionados os eixos definidos pelo <span class="math inline">\(D\)</span>
<span class="math display">\[F_{u,v}(x,y) = R^TD^TMDR\]</span>
<span class="math display">\[F_{u,v}(x,y) = D^TR^TMRD\]</span>
<span class="math display">\[F_{u,v}(x,y) = D^TQD\]</span>
<span class="math display">\[Q = \begin{bmatrix} \alpha &amp; 0\\ 0 &amp; \beta  \end{bmatrix}\]</span>
Os valores de <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> são proporcionais à função de autocorrelação nos principais eixos. Dessa forma, <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> serão pequenos se o <span class="math inline">\(pixel(x,y)\)</span> for de uma região com intensidade constante, um será de valor grande e outro pequeno se estiverem em uma borda reta, e ambos terão valores grandes se estiverem em uma borda com curvatura acentuada. Portanto, a medida de curvatura é definida como <span class="math inline">\(k_k(x,y)\)</span> <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 187]</span>.
<span class="math display">\[k_k(x,y) = \alpha \beta - k(\alpha + \beta)^2\]</span>
No qual <span class="math inline">\(k\)</span> controla a sensibilidade do detector.</p>
<p>Como <span class="math inline">\(Q\)</span> é uma composição ortogonal de <span class="math inline">\(M\)</span>. Os elementos de Q são chamados de autovalores <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 188]</span>. Inferimos que
<span class="math display">\[Q = R^TMR\]</span>
Então, a partir da equivalência de determinantes e traços, é possível produzir uma equação equivalente a <span class="math inline">\(Y\)</span> com os valores da matriz <span class="math inline">\(M\)</span> <span class="citation">[<a href="#ref-nixon2019feature" role="doc-biblioref">19</a>, p. 188]</span>.
<span class="math display">\[\alpha \beta = A(x,y)B(x,y) - C(x,y)^2\]</span>
<span class="math display">\[\alpha + \beta = A(x,y) + B(x,y)\]</span>
Assim
<span class="math display">\[
\begin{split}
k_k(x,y) &amp;= \alpha \beta - k(\alpha + \beta)^2
\\&amp;= A(x,y)B(x,y) - C(x,y)^2 - k(A(x,y) + B(x,y))^2
\\&amp;=det(M) - k(trace(M))^2
\end{split}
\]</span>
A Figura <a href="segmentação.html#fig:imagemQuinas">6.30</a> (a) é a imagem original. A Figura <a href="segmentação.html#fig:imagemQuinas">6.30</a> (b) foi gerada usando o detector de Harris com uma vizinhança 5x5 (<span class="math inline">\(w=2\)</span>) para cada deslocamento <span class="math inline">\((u,v)\)</span>, com a derivada sendo calculada pelo Operador de Sobel (3x3) e com sensibilizador <span class="math inline">\(k=0.01\)</span>. Limiarizou-se a imagem de curvatura, descartando os valores que não fossem maiores que 9% do valor máximo. E nas posições <span class="math inline">\((x,y)\)</span> da imagem que continham as curvaturas, foi destacado em rosa.
Observe que a imagem identificou as quinas do tabuleiro de xadrez e do cubo mágico, porém não detectou outras quinas como as das árvores. Além disso, foi encontrado quinas que não são próprias dos objetos, e sim da iluminação.
Variando tanto o sensibilizador da função, <span class="math inline">\(k\)</span>, como o limiar é provável que consigamos encontrar mais quinas, com o custo de também poder classificar ruídos que foram identificados como bordas também como quinas. Entretanto, já vimos que o filtro gaussiano pode ser que nos ajude neste problema.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemQuinas"></span>
<img src="imagens/06-segmentacao/imagemQuinas.png" alt="Exemplo de detecção de Quinas pelo método de Harris." width="55%" />
<p class="caption">
Figura 6.30: Exemplo de detecção de Quinas pelo método de Harris.
</p>
</div>
</div>
</div>
<div id="detecção-de-blobs" class="section level2">
<h2><span class="header-section-number">6.5</span> Detecção de Blobs</h2>
<p>Blobs, do inglês bolhas, são regiões da imagem em que os pixels têm valores aproximadamente iguais. Uma boa representação - um tanto quanto artificial - disso é a função gaussiana, como pode ser vista na figura <a href="segmentação.html#fig:gaussianblob">6.31</a>(a) e sua representação 2D na figura <a href="segmentação.html#fig:gaussianblob">6.31</a>(b), nela temos um conjunto de pixels com valores bem próximos, que caracterizam um blob.</p>

<div class="figure" style="text-align: center"><span id="fig:gaussianblob"></span>
<img src="imagens/06-segmentacao/gaussian_blob.jpg" alt="Função gaussiana em 3D e 2D." width="75%" />
<p class="caption">
Figura 6.31: Função gaussiana em 3D e 2D.
</p>
</div>
<p>Apesar do exemplo, a detecção de blobs não se restringe a elementos circulares, mas a qualquer conjunto de pixels.</p>
<div id="log" class="section level3">
<h3><span class="header-section-number">6.5.1</span> LoG</h3>
<p>Esse método utiliza o do Laplaciano do Gaussiano, que já foi apresentado anteriormente, mas que em resumo é o cálculo de derivadas segunda em uma imagem que foi anteriormente convolucionada com um filtro gaussiano, isso irá gerar fortes respostas positivas em blobs escuros e negativas em blobs escuros nos blobs de tamanho <span class="math inline">\(\sqrt{2\sigma}\)</span>. Como existe uma relação entre a respostas e o tamanho do desvio padrão, é necessário realizar a operação com uma gama de valores para o sigma, e assim detectar blobs de diferentes tamanhos.</p>

<div class="figure" style="text-align: center"><span id="fig:nasahubbledeep"></span>
<img src="imagens/06-segmentacao/nasa_hubble_deep.jpg" alt="Imagem de Campo Ultraprofundo do Hubble. [20]" width="55%" />
<p class="caption">
Figura 6.32: Imagem de Campo Ultraprofundo do Hubble. <span class="citation">[<a href="#ref-img:hubbledeep" role="doc-biblioref">20</a>]</span>
</p>
</div>
<p>Como podemos ver na figura <a href="segmentação.html#fig:gaussianblob">6.31</a> com diferentes valores de sigma conseguimos detectar objetos de variados tamanhos, como exemplo na figura <a href="segmentação.html#fig:logsigmas">6.33</a>(a) detectamos as estrelas da figura <a href="segmentação.html#fig:nasahubbledeep">6.32</a> que apresentam uma menor resposta ao filtro laplaciano.</p>

<div class="figure" style="text-align: center"><span id="fig:logsigmas"></span>
<img src="imagens/06-segmentacao/log_sigmas.jpg" alt="Laplaciano do Gaussiano com diferentes valores de sigma." width="100%" />
<p class="caption">
Figura 6.33: Laplaciano do Gaussiano com diferentes valores de sigma.
</p>
</div>
<p>Na figura <a href="segmentação.html#fig:loghubble">6.34</a> temos o resultado da detecção dos blobs utilizando LoG. Note que nem todas as estrelas foram detectadas, isso se deve ao fato do uso de um valor de threshold, onde definimos que queremos as detecções acima de determinado limiar. Na figura <a href="segmentação.html#fig:loghubblebaixo">6.35</a> podemos ver o resultado utilizando um valor de limiar menor, onde muito mais objetos foram localizados.</p>

<div class="figure" style="text-align: center"><span id="fig:loghubble"></span>
<img src="imagens/06-segmentacao/log_hubble.jpg" alt="Resultado da detecção de blobs com LoG." width="55%" />
<p class="caption">
Figura 6.34: Resultado da detecção de blobs com LoG.
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:loghubblebaixo"></span>
<img src="imagens/06-segmentacao/log_hubble_baixo_threshold.jpg" alt="Resultado da detecção de blobs com LoG com um threshold menor." width="55%" />
<p class="caption">
Figura 6.35: Resultado da detecção de blobs com LoG com um threshold menor.
</p>
</div>
</div>
<div id="dog" class="section level3">
<h3><span class="header-section-number">6.5.2</span> DoG</h3>
<p>Esse método é basicamente o mesmo do anterior, mas possui uma certa vantagem, que é o fato de ele ser mais eficiente. Como também já foi mencionado no tópico na seção anterior é possível aproximar o Laplaciano do Gaussiano através da Diferença do Gaussiano(DoG), ou seja, primeiramente se realiza a filtragem gaussiano com dois sigmas diferentes e se faz a subtração entre os dois. Realizamos esse processo para diferentes pares de valores, obtendo assim o mesmo espaço de escala construído com o processo do LoG. Na figura <a href="segmentação.html#fig:doghubble">6.36</a> temos um exemplo de detecção por DoG.</p>

<div class="figure" style="text-align: center"><span id="fig:doghubble"></span>
<img src="imagens/06-segmentacao/dog_hubble.jpg" alt="Resultado da detecção de blobs com DoG." width="55%" />
<p class="caption">
Figura 6.36: Resultado da detecção de blobs com DoG.
</p>
</div>
</div>
<div id="doh" class="section level3">
<h3><span class="header-section-number">6.5.3</span> DoH</h3>
<p>Uma matriz Hessiana é uma matriz que contém as derivadas de uma função. No nosso caso, utilizamos a Hessiana de ordem 2, pois estamos trabalhando com imagens, que possuem duas dimensões. Ela pode ser representada da seguinte maneira:</p>
<p><span class="math display">\[H[f(x_1, x_2, \dots,x_n)]=
\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2}\\ 
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2}
\end{bmatrix}\]</span></p>
<p>A matriz Hessiana tem muita utilidade pois com ela podemos descrever a curvatura em um ponto da função multivariável, o que no nosso caso pode ajudar a detectar os blobs, já que eles são aglomerados de pixels e devem estar separados do restante da imagem, ou seja, um aglomerado claro em um fundo escuro ou o contrário, e isso irá fazer com que sua função tenha uma mudança de sinal que pode ser detectada utilizando-se as informações da matriz. Além disso, como dito por Herbert Bay et al.<span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">21</a>]</span> os detectores baseados na Hessiana são mais estáveis e repetíveis(tem a mesma resposta para a mesma imagem com diferentes ângulos, iluminações etc.).</p>
<p>Um dos principais algoritmos que fazem uso dessa matriz se chama Speeded Up Robust Features (SURF)<span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">21</a>]</span>, esse método faz uso de várias técnicas que o tornam muito rápido, como seu próprio nome sugere. Uma dessas técnicas é o cálculo da integral da imagem, realizado a partir da soma de todos os pixels de uma área retangular a partir do x atual, sendo que este varia enquanto se é andado pela imagem.</p>

<div class="figure" style="text-align: center"><span id="fig:imageIntegral"></span>
<img src="imagens/06-segmentacao/imageIntegral.png" alt="Integral de uma imagem. [22]" width="55%" />
<p class="caption">
Figura 6.37: Integral de uma imagem. <span class="citation">[<a href="#ref-Cen2016StudyOV" role="doc-biblioref">22</a>]</span>
</p>
</div>
<p>Como pode ser visto na figura, a integral de uma imagem contém a soma das regiões, por exemplo, a primeira posição contém a soma de somente uma célula, no caso 1, a segunda tem a soma de duas células, na primeira linha estamos basicamente somando as células de uma só linha, na segunda começamos a formar regiões retangulares, por exemplo, na segunda linha e terceira coluna temos o valor 6, resultante da soma das seis células da primeira linha com a segunda. Com a integral podemos calcular a área de qualquer região com apenas quatro operações, da seguinte forma:
<span class="math display">\[soma = D+A-B-C\]</span></p>
<p>Onde {A,B,C,D} forma uma região. Como exemplo, caso queiramos calcular a área na região quadrada 2x2 na direita inferior utilizados:
<span class="math display">\[soma = 9 + 1 - 3 - 3 = 4\]</span></p>
<p>Isso nos ajuda na aplicação de box filters, já que precisaríamos da soma de determinadas áreas, e com isso aumentamos a velocidade do método.
Sendo <span class="math inline">\(X=(x,y)\)</span> um ponto em uma imagem, sua matriz Hessiana em <span class="math inline">\(X\)</span> a uma escala é dada por:</p>
<p><span class="math display">\[H(X,\sigma)=\begin{bmatrix}
L_{xx}(X, \sigma) &amp; L_{xy}(X, \sigma)\\ 
L_{xy}(X, \sigma) &amp; L_{yy}(X, \sigma)
\end{bmatrix}\]</span></p>
<p>Onde <span class="math inline">\(L_{xx}(X, \sigma)\)</span> é a convolução da imagem no ponto X com a derivada de segunda ordem gaussiana <span class="math inline">\(\frac{\partial^2g(\sigma)}{\partial x^²}\)</span> e assim por diante<span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">21</a>]</span>. Aqui entra em cena mais um elemento para melhorar a velocidade do algoritmo, Bay, Herbert et al. utilizam box filters para aproximar o filtro gaussiano. Como podemos ver na figura, onde os dois primeiros filtros são os derivativos gaussianos discretizados e os dois últimos são os aproximados a partir de box filters.</p>

<div class="figure" style="text-align: center"><span id="fig:discretizadogaussiano"></span>
<img src="imagens/06-segmentacao/discretizadogaussiano.png" alt="Filtro gaussiano discretizado e aproximado na direção \(y\) e \(xy\). [21]" width="85%" />
<p class="caption">
Figura 6.38: Filtro gaussiano discretizado e aproximado na direção <span class="math inline">\(y\)</span> e <span class="math inline">\(xy\)</span>. <span class="citation">[<a href="#ref-bay2006surf" role="doc-biblioref">21</a>]</span>
</p>
</div>
<p>Chamamos as derivadas realizadas na imagem de <span class="math inline">\(D_{xx}\)</span>, <span class="math inline">\(D_{yy}\)</span>, <span class="math inline">\(D_{xy}\)</span>. Essas derivadas não são realizadas com somente um valor de <span class="math inline">\(\sigma\)</span>, mas como os detectores anteriores usam uma sequência de valores para assim criar um espaço de escalas e conseguir detectar blobs de diferentes tamanhos. Assim, a determinante da Hessiana é dado por:</p>
<p><span class="math display">\[det(H_{\text{aprox}}) = D_{xx}D_{yy}-(0.9D_{xy})^2\]</span></p>
<p>Sendo que o valor <span class="math inline">\(0.9\)</span> é um peso introduzido pelos autores Bay, Hebert et al. para corrigir as respostas quando utilizamos várias escalas de sigma e obter uma invariância escalar. Na figura temos o resultado de uma detecção de blobs realizada pela Determinante do Hessiano.</p>

<div class="figure" style="text-align: center"><span id="fig:dohhubble"></span>
<img src="imagens/06-segmentacao/doh_hubble.jpg" alt="Resultado da detecção de blobs com DoH." width="55%" />
<p class="caption">
Figura 6.39: Resultado da detecção de blobs com DoH.
</p>
</div>
</div>
</div>
<div id="limiarização" class="section level2">
<h2><span class="header-section-number">6.6</span> Limiarização</h2>
<p>“a seção anterior, as regiões eram identificadas achando primeiro os segmentos de borda e, em seguida, tentando-se conectá-las com as fronteiras. Nesta seção, discutem-se as técnicas de divisão de imagens diretamente em regiões com base nos valores de intensidade e/ou as propriedades desses valores” <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 486]</span>.</p>
<p>“Em virtude de suas propriedades intuitivas, simplicidade de implementação e velocidade computacional, a limiarização de imagens tem uma posição central nas aplicações de segmentação de imagem” <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 486]</span>.</p>
<p>É importante salientar que a chance de sucesso da limiarização de intensidade é proporcional à largura e a profundidade do(s) vale(s) que separam os modos (ou classes) do histograma. E os principais fatores que afetam as propriedades do(s) vale(s) são <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 487]</span>:</p>
<ul>
<li><p>A separação entre picos: quanto mais distantes forem os picos entre si, melhores as possibilidades de separação da imagem</p></li>
<li><p>Índice de ruído da imagem: os modos ampliam com o aumento do ruído</p></li>
<li><p>O tamanho relativo dos objetos e do fundo</p></li>
<li><p>A uniformidade da fonte de iluminação</p></li>
<li><p>A uniformidade da reflexão da imagem</p></li>
</ul>
<p>Suponha que os histogramas de intensidade de uma imagem composta por objetos claros sobre um fundo escuro, conforme Figura <a href="segmentação.html#fig:histograma4didatica">6.40</a> (a), de tal forma que os <em>pixels</em> do objeto e do fundo tenham valores de intensidade agrupados em dois modos ou dois grupos dominantes (Gonzalez; Woods, 2010, p. 486); a idéia é selecionar um limiar <span class="math inline">\(T\)</span> que separa estes modos. E caso tenha três modos, usa-se dois limiares, conforme Figura <a href="segmentação.html#fig:histograma4didatica">6.40</a> (b). Em outras palavras, a segmentação da imagem da Figura <a href="segmentação.html#fig:histograma4didatica">6.40</a> (a) é dada por <span class="math inline">\(g(x,y)\)</span><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>:</p>
<p><span class="math display">\[g(x,y) =
\begin{cases}
1,\ se f(x,y) &gt; T \\
0,\ se f(x,y) \leq T
\end{cases}\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:histograma4didatica"></span>
<img src="imagens/06-segmentacao/histograma4didatica.png" alt="Histogramas de intensidade que podem ser divididos por um limiar único, (a), e limiares duplos, (b). [2, p. 486]" width="55%" />
<p class="caption">
Figura 6.40: Histogramas de intensidade que podem ser divididos por um limiar único, (a), e limiares duplos, (b). <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 486]</span>
</p>
</div>
<p>Quando <span class="math inline">\(T\)</span> é uma constante aplicável em uma imagem inteira, o processo é conhecido como limiarização global. Caso <span class="math inline">\(T\)</span> mude ao longo da imagem, usamos o termo limiarização variável. E quando <span class="math inline">\(T\)</span> denotar uma limiarização variável na qual o valor <span class="math inline">\(T\)</span> em qualquer ponto <span class="math inline">\((x,y)\)</span> em uma imagem depende das propriedades de sua vizinhança (por exemplo, a intensidade média dos <em>pixels</em> da vizinhança), o chamamos de limiarização local ou regional<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 486]</span>.</p>
<p>Os problemas de segmentação que exigem mais do que dois limiares são difíceis (muitas vezes impossíveis) de resolver e os melhores resultados, geralmente, são obtidos por meio de métodos como a limiarização variável ou aumento da região, como discutido <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 486]</span>.</p>
<ul>
<li><strong>O papel do ruído da limiarização</strong></li>
</ul>
<p>O ruído de uma imagem é capaz de fazer com que fique difícil achar um limiar ideal para segmentar a imagem sem processamentos adicionais, pois o(s) vale(s) da imagem podem desaparecer <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>]</span>.</p>
<p>Observe que conforme os exemplos da Figura <a href="segmentação.html#fig:imagemRuido">6.41</a> e seus respectivos histogramas, o aumento no desvio padrão nos níveis de intensidade do ruído gaussiano faz com que o vale que separava os dois modos desapareça, tornando difícil a segmentação do fundo e do objeto.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemRuido"></span>
<img src="imagens/06-segmentacao/imagemRuido.png" alt="(a) Imagem de 8 bits livre de ruído, típica de Computação Gráfica. (b) Imagem com ruído gaussiano aditivo de média 0 e desvio padrão de 10 níveis de intensidade. (c) Imagem com ruído gaussiano aditivo de média 0 e desvio padrão de 50 níveis de intensidade. (d) a (f) Histogramas correspondentes [2, p. 487]." width="55%" />
<p class="caption">
Figura 6.41: (a) Imagem de 8 bits livre de ruído, típica de Computação Gráfica. (b) Imagem com ruído gaussiano aditivo de média 0 e desvio padrão de 10 níveis de intensidade. (c) Imagem com ruído gaussiano aditivo de média 0 e desvio padrão de 50 níveis de intensidade. (d) a (f) Histogramas correspondentes <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 487]</span>.
</p>
</div>
<ul>
<li><strong>O papel da iluminação e refletância</strong></li>
</ul>
<p>O problema da iluminação é quando não é possível ter uma incidência uniforme da luz, causando um sombreamento. O mesmo efeito acontece quando o problema não é na iluminação, mas nas características da superfície do objeto; pois a iluminação e refletância produzem o mesmo problema. Note que, pela Figura <a href="segmentação.html#fig:imagemRefletancia">6.42</a>, o histograma deixou de ser bimodal. Logo para segmentar imagens com problemas de iluminação e refletância não é simples</p>

<div class="figure" style="text-align: center"><span id="fig:imagemRefletancia"></span>
<img src="imagens/06-segmentacao/imagemRefletancia.png" alt="(a) Imagem ruidosa. (b) Rampa de intensidade no intervalo [0.2, 0.6]. (c) Produto de (a) e (b). (d) a (f) Histogramas correspondentes [2, p. 488]." width="55%" />
<p class="caption">
Figura 6.42: (a) Imagem ruidosa. (b) Rampa de intensidade no intervalo [0.2, 0.6]. (c) Produto de (a) e (b). (d) a (f) Histogramas correspondentes <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 488]</span>.
</p>
</div>
<p>E como solução há três abordagens básicas. Corrigir diretamente o padrão de sombreamento através de uma multiplicação com o comportamento inverso do sombreamento. Por exemplo, a iluminação não uniforme, porém fixa, pode ser corrigida multiplicando a imagem pelo inverso do padrão de iluminação, que pode ser obtida na aquisição de uma imagem de uma superfície plana de intensidade constante. Outra maneira é corrigí-lo por meio do processamento, por exemplo, utilizando a transformada <em>top-hat</em>. E a terceira abordagem é a de contornar isso utilizando a limiarização variável <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 488]</span>.</p>
<div id="limiarização-global-simples" class="section level3">
<h3><span class="header-section-number">6.6.1</span> Limiarização global simples</h3>
<p>A limiarização global simples é um método iterativo básico e que não é o mais eficiente. Ele é um processo iterativo que denomina o limiar ideal como aquele que produz menor diferença entre as médias de intensidade dos modos, o de segmentação e o desprezado <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 488]</span>.</p>
<p>Ele consiste em:</p>
<ol style="list-style-type: decimal">
<li><p>Selecionar uma estimativa inicial para o limiar global, <span class="math inline">\(T\)</span>.</p></li>
<li><p>Segmentar a imagem usando <span class="math inline">\(T\)</span>. Isso dará origem a dois grupos de pixels: <span class="math inline">\(G_{1}\)</span> , composto por todos os pixels com valores de intensidade <span class="math inline">\(&gt; T\)</span>, e <span class="math inline">\(G_{2}\)</span>, composto pelos pixels com valores <span class="math inline">\(\leq T\)</span>.</p></li>
<li><p>Calcular os valores de intensidade média dos grupos, <span class="math inline">\(m_{1}\)</span> e <span class="math inline">\(m_{2}\)</span>.</p></li>
<li><p>Calcular um novo valor de limiar: <span class="math inline">\(T = \frac{m_{1}+m_{2}}{2}\)</span>.</p></li>
<li><p>Repita as etapas 2 a 4 até que a diferença entre os valores de <span class="math inline">\(T\)</span> das iterações sucessivas seja menor que o parâmetro predefinido <span class="math inline">\(\Delta T\)</span>.</p></li>
</ol>
<p>Exemplo de Limiarização Global:
A Figura <a href="segmentação.html#fig:imagemLimiarGlobalSimples">6.43</a> (a) consiste na imagem de uma digital com ruído. A Figura <a href="segmentação.html#fig:imagemLimiarGlobalSimples">6.43</a> (b) mostra que seu histograma possui um vale bem nítido e pela aplicação do algoritmo, usando <span class="math inline">\(\Delta T = 0\)</span> e iniciando <span class="math inline">\(T\)</span> igual a média de intensidade da imagem, após três iterações, encontramos o limiar <span class="math inline">\(T = 125.4\)</span>. A Figura <a href="segmentação.html#fig:imagemLimiarGlobalSimples">6.43</a> (c) mostra o resultado obtido como <span class="math inline">\(T = 125\)</span>. Como esperado, a partir da separação clara entre os modos no histograma, segmentação entre o objeto e o fundo foi bastante eficaz.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarGlobalSimples"></span>
<img src="imagens/06-segmentacao/imagemLimiarGlobalSimples.png" alt="(a) Impressão digital ruidosa. (b) Histograma. (c) Segmentação resultante usando um limiar global. [2, p. 489]." width="55%" />
<p class="caption">
Figura 6.43: (a) Impressão digital ruidosa. (b) Histograma. (c) Segmentação resultante usando um limiar global. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 489]</span>.
</p>
</div>
</div>
<div id="limiarização-pelo-método-de-otsu" class="section level3">
<h3><span class="header-section-number">6.6.2</span> Limiarização pelo Método de Otsu</h3>
<p>O método de Otsu é uma abordagem que relaciona as informações do histograma com conceitos estatísticos para produzir o chamado limiar ótimo, que é denotado por aquele que maximiza a variância entre classes ou minimiza a variância intraclasse <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 489]</span>. Lembrando que classe é o mesmo que modos do histograma.</p>
<p>O primeiro passo é obter o histograma da imagem normalizado, isto é, no qual os pesos de cada intensidade são a probabilidade da ocorrência daquela intensidade na imagem. Segue a equação abaixo que representa um histograma normalizado, no qual <span class="math inline">\(L\)</span> representa a quantidade de níveis de intensidade e <span class="math inline">\(p_{i}\)</span>, a probabilidade de ocorrência da intensidade <span class="math inline">\(i\)</span> na imagem <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 490]</span>.</p>
<p><span class="math display">\[\sum_{i=0}^{L-1}{p_{i} = 1,\ p_{i} \geq 0}\]</span></p>
<p>Para entender a equação cerne de Otsu, é preciso compreender algumas equações que a compõe. A probabilidade de ocorrência do modo 1 é dada pela equação abaixo <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 490]</span></p>
<p><span class="math display">\[P_{1}(k) = \sum_{i=0}^{k}{p_{i}}\]</span>
E o valor da intensidade média dos <em>pixels</em> da classe 1, <span class="math inline">\(C_{1}\)</span>, para dado limiar <span class="math inline">\(k\)</span> pode ser calculado pela equação abaixo <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 490]</span></p>
<p><span class="math display">\[\begin{split}
m_{1}(k) &amp; = \sum_{i=0}^{k}{iP(i/C_{1})}\\
&amp; = \sum_{i=0}^{k}{iP(C_{1}/i)P(i)/P(C_{i})}\\
&amp; = \frac{1}{P_{1}(k)}\sum_{i=0}^{k}{ip_{i}}\\
\end{split}\]</span>
E a média acumulada (intensidade média) até o nível <span class="math inline">\(k\)</span> ou da classe <span class="math inline">\(C_{1}\)</span> é dada por <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 490]</span></p>
<p><span class="math display">\[m(k) = \sum_{i=0}^{k}{ip_{i}}\]</span></p>
<p>Entendidas as equações anteriores, chegamos a equação cerne, que denota a variância entre classes.</p>
<p><span class="math display">\[\sigma_B^2(k) = \frac{[m_GP_{1}(k) - m(k)]^{2}}{P_1(k)[1 - P_1(k)]}\]</span>
Então, o limiar ótimo é o valor que maximiza a variância entre classes, denominado <span class="math inline">\(k^*\)</span> <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 491]</span>, representado na equação abaixo. E conforme informado anteriormente, esse resultado é o mesmo que minimiza a variância dentro das classes; isso se deve a uma propriedade estatística que relaciona a variância global de intensidade da imagem, a variância interclasse e a variância intraclasse.</p>
<p><span class="math display">\[\sigma_B^2(k^*) = \max_{0 \leq k \leq L-1} \sigma_B^2(k)\]</span>
Se o máximo existir para mais de um valor de <span class="math inline">\(k\)</span>, é habitual calcular a média dos valores de <span class="math inline">\(k\)</span> <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 491]</span>.</p>
<p>Uma métrica adimensional pode ser usada para obter uma estimativa quantitativa da separabilidade das classes, o que dá uma idéia da facilidade e do resultado da segmentação.</p>
<p><span class="math display">\[\eta = \frac{\sigma_B^2(k^*)}{\sigma_G^2}\]</span>
Tendo o limiar ótimo, <span class="math inline">\(k^*\)</span>, segmentamos a imagem como já visto.</p>
<p>Para o cálculo da métrica adimensional, é preciso conhecer a variância global das intensidades da imagem que pode ser obtida pela seguinte equação:
<span class="math display">\[\sigma_G^2 = \sum_{i=0}^{L-1}{(i - m_G)}^2p_i\]</span>
Resumo do algoritmo de Otsu <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 492]</span>:</p>
<ol style="list-style-type: decimal">
<li>Calcular o histograma normalizado da imagem de entrada. Designar os componentes do histograma como <span class="math inline">\(p_i, i = 0, 1, 2, ..., L-1\)</span>.</li>
<li>Calcular as somas acumuladas, <span class="math inline">\(P_1(k)\)</span>, para <span class="math inline">\(k = 0, 1, 2, ..., L-1\)</span>.</li>
<li>Calcular as médias acumuladas <span class="math inline">\(m(k)\)</span>, para <span class="math inline">\(k = 0, 1, 2, ..., L-1\)</span>.</li>
<li>Calcular a intensidade média global, <span class="math inline">\(m_G\)</span>.</li>
<li>Calcular a variância entre classes, <span class="math inline">\(\sigma_B^2(k)\)</span>, para <span class="math inline">\(k = 0, 1, 2, ..., L-1\)</span>.</li>
<li>Obter o limiar ideal de Otsu, <span class="math inline">\(k^*\)</span>, caso haja mais de um, faz-se a média dos valores.</li>
<li>Obter a medida de separabilidade, <span class="math inline">\(\eta^*\)</span>, a fim de estimar a qualidade da segmentação.</li>
</ol>
<p>A Figura <a href="segmentação.html#fig:imagemOtsu">6.44</a> (a) mostra uma imagem de microscópio ótico de células polimerosomas e a Figura <a href="segmentação.html#fig:imagemOtsu">6.44</a> (b), seu histograma. O objetivo deste exemplo é segmentar as moléculas do fundo. A Figura <a href="segmentação.html#fig:imagemOtsu">6.44</a> (c) é o resultado pela limiarização global simples. Como o histograma não tem vales distintos e a diferença de intensidade entre o fundo e os objetos é pequena, o algoritmo não conseguiu alcançar a segmentação desejada. A Figura <a href="segmentação.html#fig:imagemOtsu">6.44</a> (d) mostra o resultado obtido pelo método de Otsu. Esse resultado, obviamente, é superior ao da Figura <a href="segmentação.html#fig:imagemOtsu">6.44</a> (c). O valor do limiar calculado pelo algoritmo simples foi o de 169, enquanto o limiar calculado pelo método de Otsu era o de 181, que está mais próximo das áreas mais claras na imagem que define as células. A medida de separabilidade foi 0.467.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemOtsu"></span>
<img src="imagens/06-segmentacao/imagemOtsu.png" alt="(a) Imagem original. (b) Histograma (os picos elevados foram cortados para realçar os detalhes nos valores mais baixos). (c) Resultado da segmentação pela limiarização global simples. (d) Resultado da segmentação pelo método de Otsu. [2, p. 492]." width="55%" />
<p class="caption">
Figura 6.44: (a) Imagem original. (b) Histograma (os picos elevados foram cortados para realçar os detalhes nos valores mais baixos). (c) Resultado da segmentação pela limiarização global simples. (d) Resultado da segmentação pelo método de Otsu. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 492]</span>.
</p>
</div>
</div>
<div id="uso-de-suavização-para-limiarização" class="section level3">
<h3><span class="header-section-number">6.6.3</span> Uso de suavização para limiarização</h3>
<p>O objetivo da suavização é tentar separar os histogramas de imagens ruidosas, que tendem a ser unimodais, em modos com vales mais profundos; pois, quanto mais profundo o vale, melhor será a segmentação da imagem.</p>
<p>Atente-se ao tipo de média e ao tamanho do <em>kernel</em>, aconselha-se o filtro gaussiano, pois ele minimiza o borramento de fronteira, e suaviza o ruído ainda que de maneira mais branda do que um filtro de média.</p>
<p>A Figura <a href="segmentação.html#fig:imagemSuavizacaoLimiarizacao">6.45</a> (a) mostra uma imagem ruidosa, a <a href="segmentação.html#fig:imagemSuavizacaoLimiarizacao">6.45</a> (b) mostra seu histograma, a Figura <a href="segmentação.html#fig:imagemSuavizacaoLimiarizacao">6.45</a> (c) mostra o resultado do método de Otsu. Já a Figura <a href="segmentação.html#fig:imagemSuavizacaoLimiarizacao">6.45</a> (d) mostra a imagem de (a) suavizada usando uma máscara de média de tamanho 5x5 e a Figura <a href="segmentação.html#fig:imagemSuavizacaoLimiarizacao">6.45</a> (e) é seu histograma e a Figura <a href="segmentação.html#fig:imagemSuavizacaoLimiarizacao">6.45</a> (f) é resultado da limiarização pelo método de Otsu.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemSuavizacaoLimiarizacao"></span>
<img src="imagens/06-segmentacao/imagemSuavizacaoLimiarizacao.png" alt="Exemplo de suavização antes da aplicação do método de Otsu [2, p. 493]." width="55%" />
<p class="caption">
Figura 6.45: Exemplo de suavização antes da aplicação do método de Otsu <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 493]</span>.
</p>
</div>
<p>Apesar do filtro de média poder nos ajudar, nem sempre será capaz disso. A Figura <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> (a) mostra uma imagem ruidosa e a <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> (b) mostra o seu histograma, observe que o pontinho branco parece nem estar presente no histograma. E após aplicado o método de Otsu, a <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> (c), observe que não foi obtida a segmentação desejada. Então, tentou-se um filtro de média 5x5, que reduz o ruído, Figura <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> (d). O resultado no histograma foi a redução do espalhamento do histograma, Figura <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> (e), mas a distribuição ainda é unimodal, resultando em falha na segmentação, o que é visto na Figura <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> (f).</p>

<div class="figure" style="text-align: center"><span id="fig:ImagemSuavizacaoLimiarizacaoProblem"></span>
<img src="imagens/06-segmentacao/ImagemSuavizacaoLimiarizacaoProblem.png" alt="Exemplo de insucesso na segmentação por Otsu, mesmo com prévia suavização." width="55%" />
<p class="caption">
Figura 6.46: Exemplo de insucesso na segmentação por Otsu, mesmo com prévia suavização.
</p>
</div>
<p>Portanto, note que, se a região que deseja segmentar for muito pequena em relação ao background e houver ruído, o que pode surgir na captura da imagem, a chance de não dar certo pelos métodos vistos é grande; pois como os métodos que até agora vimos operam apenas no histograma da imagem, sem uso de maiores recursos. Como visto, imagens com essa característica, um mínimo ruído persiste e nem foi obtido um vale considerável entre as duas regiões. Isso pode ser atribuído ao fato de que a região é tão pequena que sua contribuição para o histograma é insignificante em comparação à intensidade da propagação causada pelo ruído <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 493]</span>. A solução para isso é o uso de máscaras de borda, que será detalhado a seguir.</p>
</div>
<div id="uso-de-bordas-para-limiarização" class="section level3">
<h3><span class="header-section-number">6.6.4</span> Uso de bordas para limiarização</h3>
<p>Em uma imagem com ruído na qual a região a ser segmentada é muito pequena, é como se não houvesse aquela região e houvesse apenas o <em>background</em>. Isso é observado na aparência unimodal do histograma.</p>
<p>Portanto, fica difícil estimar um limiar ideal pelos algoritmos supracitados. E como visto anteriormente, é preciso uma aparência bimodal para uma boa segmentação, então, precisamos de um histograma equilibrado; para isso, tomamos o histograma das bordas mais destacadas da imagem. Isso pode ser resumido em gerar uma máscara de gradiente ou laplaciano da imagem, limiarizá-la com um valor alto e usar como máscara para imagem original e prosseguir com o processo de segmentação do objeto a partir dessa amostra, pois, dessa forma, é gerado um histograma simétrico e com um vale destacado, porque, com a máscara de borda, há probabilidade de um píxel estar no <em>background</em> ou <em>foreground</em> tende a ser equilibrada <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 494]</span>.</p>
<p>O que se espera com os tipos de máscaras de borda, conforme visto no estudo detecção de bordas, é que a de gradiente produzirá bordas mais grossas e menor detecção aos ruídos da imagem, e a de laplace, bordas mais finas e maior detecção de ruídos, além de apresentar melhor custo computacional. Entretanto, é possível modificar este algoritmo para que tanto a magnitude do gradiente quanto o valor absoluto das imagens laplacianas sejam utilizadas; nesse caso, poderíamos especificar um limiar para cada imagem e formar a lógica OU dos dois resultados para obter a imagem marcadora, essa abordagem é útil quando se deseja ter mais controle sobre os pontos que foram considerados como sendo pontos válidos de borda <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 494]</span>.</p>
<p>Resumo das etapas de segmentação pela identificação de bordas do objeto <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 494]</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Calcular uma imagem de borda da imagem capturada, <span class="math inline">\(f(x,y)\)</span>, ora como a magnitude do gradiente, ora como o valor absoluto do laplaciano, usando qualquer um dos métodos.</p></li>
<li><p>Especificar um valor de limiar, <span class="math inline">\(T\)</span>.</p></li>
<li><p>Limiarizar a imagem a partir da Etapa 1, utilizando o limiar estabelecido na Etapa 2 para produzir uma imagem binária, <span class="math inline">\(g_{T}(x,y)\)</span>. Esta imagem é usada como uma imagem de máscara na etapa seguinte para selecionar os pixels de <span class="math inline">\(f(x,y)\)</span> que correspondem aos pixels “fortes” da borda.</p></li>
<li><p>Calcular um histograma utilizando apenas os pixels de <span class="math inline">\(f(x,y)\)</span>, que correspondem aos endereços de pixel avaliados com o número 1 em <span class="math inline">\(g_{T}(x,y)\)</span>.</p></li>
<li><p>Use o histograma da Etapa 4 para segmentar <span class="math inline">\(f(x,y)\)</span> globalmente, utilizando, por exemplo, o método de Otsu.</p></li>
</ol>
<p>A Figura <a href="segmentação.html#fig:imagemLimiarizGradiente">6.47</a> (a) e (b) mostram as mesmas imagens da Figura <a href="segmentação.html#fig:ImagemSuavizacaoLimiarizacaoProblem">6.46</a> e seu histograma. Vimos que essa imagem não adianta ser suavizada. Entretanto, usamos a estratégia de máscara de borda que obteve um ótimo resultado. A Figura <a href="segmentação.html#fig:imagemLimiarizGradiente">6.47</a> (c) mostra o gradiente já limiarizado, A Figura <a href="segmentação.html#fig:imagemLimiarizGradiente">6.47</a> (d) e (e) mostra a máscara multiplicada a imagem original, que tem um histograma mais relevante à segmentação. E a Figura <a href="segmentação.html#fig:imagemLimiarizGradiente">6.47</a> (f) mostra o resultado da segmentação pelo novo histograma, <a href="segmentação.html#fig:imagemLimiarizGradiente">6.47</a> (e), através do Método de Otsu. O limiar foi de <span class="math inline">\(134\)</span>, que fica aproximadamente a meio caminho entre os picos no histograma.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizGradiente"></span>
<img src="imagens/06-segmentacao/imagemLimiarizGradiente.png" alt="Exemplo de limiarização por meio de máscara de borda de gradiente." width="55%" />
<p class="caption">
Figura 6.47: Exemplo de limiarização por meio de máscara de borda de gradiente.
</p>
</div>
<p>Já a Figura <a href="segmentação.html#fig:imagemLimiarizLaplace">6.48</a> (a) e (b) mostra uma imagem de 8 bits de células de levedura e seu histograma. A tentativa em detectar em segmentar os pontos claros pelo método de Otsu sem prévia etapa não foi sucedida, embora o método seja capaz de isolar algumas das regiões das células muitas da regiões segmentadas à direita não estão separadas. O limiar calculado foi de <span class="math inline">\(42\)</span> e a medida de separabilidade foi de <span class="math inline">\(0.636\)</span>.<br />
A Figura <a href="segmentação.html#fig:imagemLimiarizLaplace">6.48</a> (d) mostra a imagem <span class="math inline">\(g_T(x,y)\)</span> obtida pelo cálculo do valor absoluto da imagem laplaciana e a limiarização com <span class="math inline">\(T\)</span> definido a <span class="math inline">\(115\)</span> em uma escala de intensidade no intervalo <span class="math inline">\([0, 255]\)</span>. Este valor de <span class="math inline">\(T\)</span> corresponde aproximadamente ao percentil <span class="math inline">\(99.5\)</span> dos valores da imagem laplaciana absoluta; assim, a limiarização a este nível deve resultar em um conjunto de <em>pixels</em> reduzido, como mostra esta Figura. A Figura <a href="segmentação.html#fig:imagemLimiarizLaplace">6.48</a> (e) é o histograma dos <em>pixels</em> diferentes a zero no produto de (a) e (d). Finalmente a Figura <a href="segmentação.html#fig:imagemLimiarizLaplace">6.48</a> (f) mostra o resultado da segmentação global da imagem original utilizando o método de Otsu baseado no histograma da Figura <a href="segmentação.html#fig:imagemLimiarizLaplace">6.48</a> (e). Este resultado está de acordo com as localizações dos pontos claros na imagem. O limiar calculado pelo método de Otsu foi <span class="math inline">\(115\)</span> e a medida de separabilidade foi de <span class="math inline">\(0.762\)</span>, sendo que ambos são superiores aos valores obtidos utilizando o histograma original <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 495]</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizLaplace"></span>
<img src="imagens/06-segmentacao/imagemLimiarizLaplace.png" alt="Exemplo de limiarização por meio de máscara de borda laplaciana." width="55%" />
<p class="caption">
Figura 6.48: Exemplo de limiarização por meio de máscara de borda laplaciana.
</p>
</div>
</div>
<div id="limiares-múltiplos" class="section level3">
<h3><span class="header-section-number">6.6.5</span> Limiares Múltiplos</h3>
<p>A diferença entre os limiares múltiplos e o que vimos até agora é que se usa mais de um limiar para segmentar a imagem a fim de produzir uma melhor medida de separabilidade entre as classes, por conseguinte, melhor segmentação.
Entretanto, como as aplicações que requerem mais de dois limiares geralmente são resolvidas com mais do que apenas valores de intensidade. Ao invés disso, o caminho é usar descritores adicionais (por exemplo, cor) e o problema é moldado para reconhecimento de padrões, como explicado a seguir em Limiarização baseada em diversas variáveis <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 497]</span>.</p>
<p>No caso das classes <span class="math inline">\(K, C_1, C_2, ..., C_K\)</span>, a variância entre classes se generaliza pela expressão
<span class="math display">\[\sigma_{B}^{2} = \sum_{k=1}^K{P_k(m_k-m_G)^2}\]</span>
na qual
<span class="math display">\[P_k = \sum_{i\in C_k}{p_i}\]</span>
<span class="math display">\[m_k = \frac{1}{P_k} \sum_{i \in C_k}{ip_i} \]</span>
As classes <span class="math inline">\(K\)</span> são separadas por <span class="math inline">\(K-1\)</span> limiares cujos valores, <span class="math inline">\(k^*_1, k^*_2, ..., k^*_k-1\)</span>
<span class="math display">\[
\sigma_{B}^{2}(k^*_1, k^*_2, ..., k^*_{K-1}) =
\max_{0&lt;k_1&lt;k_2&lt;...k_{n-1}&lt;L-1}{\sigma_{B}^{2}(k_1, k_2, ..., k_{K-1})}
\]</span></p>
<p>Como observado na equação anterior, o valor máximo é obtido testando todas as possibilidades de valores para cada limiar, mas lembre-se que não faz sentido assumir limiares para <span class="math inline">\(0\)</span> e <span class="math inline">\(L-1\)</span>, pois são os extremos da faixa de intensidade.</p>
<p>Também pode ser feito a avaliação de sua medida de separabilidade. Como exemplo, tomemos um histograma com três classes <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 497]</span>.</p>
<p><span class="math display">\[\eta(k^*_1, k^*_2) = \frac{\sigma^2_{B}(k^*_1,k^*_2)}{\sigma^2_{G}}\]</span></p>
<p>A Figura <a href="segmentação.html#fig:imagemLimiarizacaoMult">6.49</a> (a) mostra a imagem de um <em>iceberg</em>. É notório que será possível dividí-la com dois limiares<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> a partir das predominâncias de três grupos de intensidade. Olhando no histograma, <a href="segmentação.html#fig:imagemLimiarizacaoMult">6.49</a> (b), pelos vales bem destacados também é observado isso. Encontra-se pelo método de Otsu dois limiares, <span class="math inline">\(80\)</span> e <span class="math inline">\(177\)</span>, com uma excelente medida de separabilidade de <span class="math inline">\(0.954\)</span>. Limiarizando a Figura <a href="segmentação.html#fig:imagemLimiarizacaoMult">6.49</a> (a) o resultado que se obtém é uma segmentação muito boa, Figura <a href="segmentação.html#fig:imagemLimiarizacaoMult">6.49</a> (c) <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 498]</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizacaoMult"></span>
<img src="imagens/06-segmentacao/imagemLimiarizacaoMult.png" alt="(a) Imagem de um iceberg. (b) Histograma. (c) Imagem segmentada em três regiões usando os limiares duplos de Otsu." width="55%" />
<p class="caption">
Figura 6.49: (a) Imagem de um <em>iceberg</em>. (b) Histograma. (c) Imagem segmentada em três regiões usando os limiares duplos de Otsu.
</p>
</div>
</div>
<div id="limiarização-variável" class="section level3">
<h3><span class="header-section-number">6.6.6</span> Limiarização variável</h3>
<p>Vimos perante seções anteriores, que fatores como ruído e iluminação são impecílios para uma boa segmentação. Também foi visto que suavização e informações das bordas podem ser usadas para resolver isto. No entanto, é frequente o caso que essas estratégias são ineficientes ou nem possíveis. Como solução para tal, usamos limiares variáveis.</p>
</div>
<div id="particionamento-da-imagem" class="section level3">
<h3><span class="header-section-number">6.6.7</span> Particionamento da imagem</h3>
<p>O particionamento da imagem consiste em fracionar a imagem em retângulos suficientemente pequenos de maneira que eles tenham iluminação e refletância uniformes e aplicar o método de Otsu em cada um deles. O sucesso do método é análogo ao da máscara de bordas, ele produz, para cada fração, histogramas simétricos com vales profundos <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 498]</span>.</p>
<p>A Figura <a href="segmentação.html#fig:imagemLimiarizacaoVariavel">6.50</a> (a) e (b) mostra uma imagem e seu histograma. Pelo seu histograma é plausível que não resultaria em uma boa segmentação, seja pelo método de Otsu, Figura <a href="segmentação.html#fig:imagemLimiarizacaoVariavel">6.50</a> (c) ou pelo método iterativo, Figura <a href="segmentação.html#fig:imagemLimiarizacaoVariavel">6.50</a> (d). Após fracionada a imagem, Figura <a href="segmentação.html#fig:imagemLimiarizacaoVariavel">6.50</a> (e), a segmentação por Otsu teve sucesso, Figura <a href="segmentação.html#fig:imagemLimiarizacaoVariavel">6.50</a> (f). <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 498]</span></p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizacaoVariavel"></span>
<img src="imagens/06-segmentacao/imagemLimiarizacaoVariavel.png" alt="Exemplo da técnica de particionamento da imagem." width="55%" />
<p class="caption">
Figura 6.50: Exemplo da técnica de particionamento da imagem.
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:imagemHistoVari"></span>
<img src="imagens/06-segmentacao/imagemHistoVari.png" alt="Representa o histograma das subimagens da Figura 6.50 (e)." width="55%" />
<p class="caption">
Figura 6.51: Representa o histograma das subimagens da Figura <a href="segmentação.html#fig:imagemLimiarizacaoVariavel">6.50</a> (e).
</p>
</div>
</div>
<div id="limiarização-variável-baseada-nas-propriedades-locais-da-imagem" class="section level3">
<h3><span class="header-section-number">6.6.8</span> Limiarização variável baseada nas propriedades locais da imagem</h3>
<p>É uma técnica em que se calcula um limiar para cada ponto, <span class="math inline">\((x,y)\)</span>, com base em uma ou mais propriedades calculadas em sua vizinhança. Apesar de parecer trabalhoso, os algoritmos e hardwares modernos permitem o processamento rápido da vizinhança, especialmente para as funções comuns, como as operações lógicas e aritméticas <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 499]</span>.
Utilizaremos como abordagem básica duas propriedades, <span class="math inline">\(\sigma_{xy}(x,y)\)</span> e <span class="math inline">\(m_{xy}(x,y)\)</span>, já que indicam o grau de contraste e intensidade média na vizinhança. Seguem cálculos da limiarização usando apenas a intensidade do ponto, sendo <span class="math inline">\(T_{xy}\)</span>, o limiar local. As equações seguintes são formas comuns de limiares variáveis locais <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 499]</span>:</p>
<p><span class="math display">\[T_{xy} = a\sigma_{xy} + bm_{xy}\]</span>
em que <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> são constantes não negativas, e</p>
<p><span class="math display">\[T_{xy} = a\sigma_{xy} + bm_{G}\]</span>
, na qual <span class="math inline">\(m_G\)</span> é a média global da imagem.</p>
<p>Também pode ser usado predicados a fim de determinar o limiar, <span class="math inline">\(T_{xy}\)</span>, de segmentação. No entanto, o preço dessa limiarização mais rebuscada é um aumento no custo computacional <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 499]</span>. E a imagem <span class="math inline">\(g_{xy}\)</span>, ficaria conforme um exemplo a seguir:</p>
<p><span class="math display">\[g(x,y) =
\begin{cases}
  1,\ se\ f(x,y) &gt; a\sigma_{xy}\ \ E\ \ f(x,y) &gt; bm_{xy}\\
  0,\ caso\ contrário
\end{cases}
\]</span></p>
<p>A Figura <a href="segmentação.html#fig:imagemLimiarizVariavel">6.52</a> (a) é a imagem de células de levedura da Figura anterior <a href="segmentação.html#fig:imagemLimiarizLaplace">6.48</a> (a). A Figura <a href="segmentação.html#fig:imagemLimiarizVariavel">6.52</a> (b) é um exemplo da segmentação da Figura <a href="segmentação.html#fig:imagemLimiarizVariavel">6.52</a> (a) com dois limiares. Entretanto, note que as células do canto superior direito foram segmentadas de forma unida. A Figura <a href="segmentação.html#fig:imagemLimiarizVariavel">6.52</a> (c) é a imagem dos desvios padrão locais da vizinhança de tamanho 3x3 de cada <em>píxel</em>. E foi escolhida a média global ao invés da local, pois geralmente produz melhores resultados quando o fundo é quase constante e todas as intensidades de objeto estão acima ou abaixo da intensidade do fundo. Os pesos <span class="math inline">\(a=30\)</span> e <span class="math inline">\(b=1,5\)</span> foram assumidos. E, por fim, foi limiarizada pelo predicado exemplificado na última equação e não pela intensidade de um ponto, Figura <a href="segmentação.html#fig:imagemLimiarizVariavel">6.52</a> (d).</p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizVariavel"></span>
<img src="imagens/06-segmentacao/imagemLimiarizVariavel.png" alt="Exemplo de limiarização variável baseada nas propriedades locais [2, p. 500]." width="55%" />
<p class="caption">
Figura 6.52: Exemplo de limiarização variável baseada nas propriedades locais <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 500]</span>.
</p>
</div>
</div>
<div id="usando-média-de-movimento" class="section level3">
<h3><span class="header-section-number">6.6.9</span> Usando média de movimento</h3>
<p>O método de médias móveis é usado geralmente quando os objetos de interesse são pequenos (ou finos) em relação ao tamanho da imagem, uma condição que as imagens de texto digitado ou manuscrito possuem <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 501]</span>. “Essa aplicação é muito útil no processamento de documentos” <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 500]</span>. O procedimento consiste em um <em>kernel</em> 1D que percorre a imagem linha por linha e calcula média móvel com base em um intervalo de um dado tamanho fixo. A regra inicial é usar um intervalo de tamanho 5 vezes maior que a largura média do objeto que deseja limiarizar <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 501]</span>.
Digamos que <span class="math inline">\(z_{k+1}\)</span> denota a intensidade do ponto encontrado na sequência de digitalização na Etapa <span class="math inline">\(k+1\)</span>. A média móvel (intensidade média) com este novo ponto é dada por
<span class="math display">\[\begin{split}
m(k+1) 
&amp; = \frac{1}{n} \sum_{i = k+2-n}^{k+1}{z_i}\\
&amp; = m(k) + \frac{1}{n}(z_{k+1} - z_{k-n})
\end{split}\]</span></p>
<p>na qual <span class="math inline">\(n\)</span> é o tamanho do intervalo ou número de <em>pixels</em> utilizados no cálculo da média e <span class="math inline">\(m(1)=\frac{z1}{n}\)</span>. Este valor inicial não é rigorosamente correto porque a média de um único ponto é o valor do ponto em si. No entanto, o usamos para que cálculos especiais não sejam necessários quando é executada pela primeira vez. Já que a média móvel é calculada para cada ponto da imagem, a segmentação é baseada no limiar <span class="math inline">\(T_{xy}=bm_{xy}\)</span>, em que <span class="math inline">\(b\)</span> é constante e <span class="math inline">\(m_{xy}\)</span> é a média móvel no ponto <span class="math inline">\((x,y)\)</span> na imagem de entrada <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 500]</span>. A diferença desse método ao explicado na seção anterior é que neste usasse um <em>kernel</em> 1D que avalia linha por linha a imagem.</p>
<p>Na Figura <a href="segmentação.html#fig:imagemMediaMovel1">6.53</a> (a) mostra uma imagem de texto escrito à mão sombreada por um padrão de intensidade. Esta forma de sombreamento de intensidade é típica de imagens obtidas com um flash fotográfico. A Figura <a href="segmentação.html#fig:imagemMediaMovel1">6.53</a> (b) é o resultado da segmentação pela limiarização global de Otsu. A Figura <a href="segmentação.html#fig:imagemMediaMovel1">6.53</a> (b) mostra uma segmentação bem sucedida com limiarização local usando médias móveis, usando <span class="math inline">\(n=20\)</span>, já que a largura média do traço era de <span class="math inline">\(4\)</span> <em>pixels</em>, e <span class="math inline">\(b=0.5\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemMediaMovel1"></span>
<img src="imagens/06-segmentacao/imagemMediaMovel1.png" alt="Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de flash fotográfico. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. [2, p. 501]." width="55%" />
<p class="caption">
Figura 6.53: Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de flash fotográfico. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 501]</span>.
</p>
</div>
<p>Já na Figura <a href="segmentação.html#fig:imagemMediaMovel2">6.54</a> (a) mostra uma imagem de texto escrito à mão corrompida por um sombreamento senoidal. Esta forma de sombreamento de intensidade é típica de quando o fornecimento de energia em um digitalizador de documentos não é apropriado. A Figura <a href="segmentação.html#fig:imagemMediaMovel2">6.54</a> (a) é a imagem original, a Figura <a href="segmentação.html#fig:imagemMediaMovel2">6.54</a> (b) é o resultado da limiarização por Otsu e a Figura <a href="segmentação.html#fig:imagemMediaMovel2">6.54</a> (c) é o resultado pela média móvel. Os parâmetros utilizados foram o mesmo do anterior, sendo <span class="math inline">\(n=20\)</span> e <span class="math inline">\(b=0.5\)</span>, o que mostra relativa robustez do método.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemMediaMovel2"></span>
<img src="imagens/06-segmentacao/imagemMediaMovel2.png" alt="Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de problemas em scanner em que o fornecimento de energia não é o apropriado. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. [2, p. 502]." width="55%" />
<p class="caption">
Figura 6.54: Exemplo de aplicação da limiarização por médias móveis em um documento corrompido por um sombreamento típico de problemas em <em>scanner</em> em que o fornecimento de energia não é o apropriado. (a) Imagem original. (b) Aplicado método de Otsu. (c) Aplicado método de médias móveis. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 502]</span>.
</p>
</div>
</div>
<div id="limiarização-baseada-em-diversas-variáveis" class="section level3">
<h3><span class="header-section-number">6.6.10</span> Limiarização baseada em diversas variáveis</h3>
<p>Até agora, falamos apenas da limiarização baseada em uma única variável: intensidade dos tons de cinza. Em alguns casos, um sensor pode disponibilizar mais de uma variável para identificar cada <em>pixel</em> em uma imagem e, assim, permitir uma limiarização multivariada.
Um exemplo notável é a imagem em cores, na qual os componentes são vermelho (R), verde (G) e azul (B). Neste caso, cada <em>“pixel”</em> é identificado por três
valores e pode ser representado como um vetor 3-D, <span class="math inline">\(z = (z_1+z_2+z_3)^T\)</span>, cujos componentes são as cores RGB em um ponto. Estes pontos 3-D são frequentemente chamados de <em>voxels</em>, para denotar elementos volumétricos em oposição aos elementos de imagem <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 501]</span>.</p>
<p>Numa limiarização focada na intensidade de cinza, de apenas uma variável, avaliamos apenas a intensidade, um gráfico de duas variáveis (histograma convencional). A sua limiarização é simples. Já no R, G, B, gráfico tridimensional, avaliamos a distância dos píxels da imagem a um píxel de referência, e o limiar é representado pelo contorno de uma Figura(a) simétrica na qual <strong>contém</strong> os <em>píxels</em> segmentados e tem como seu centro o <em>píxel</em> de referência. Conforme demonstrado na Figura <a href="segmentação.html#fig:imagemLimiarizMultiv">6.55</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizMultiv"></span>
<img src="imagens/06-segmentacao/imagemLimiarizMultiv.png" alt="Segmentação multivariada no RGB. Gráfico-3D [2, p. 295]." width="55%" />
<p class="caption">
Figura 6.55: Segmentação multivariada no RGB. Gráfico-3D <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 295]</span>.
</p>
</div>
<p>Suponha que queiramos extrair de uma imagem colorida todas as regiões com uma faixa de cor específica: por exemplo, tons avermelhados da Figura <a href="segmentação.html#fig:imagemLimiarizMultiv2">6.56</a> (a). Vamos denotar a cor avermelhada média em que estamos interessados, a amostra é demarcada pelo retângulo de bordas claras em Figura <a href="segmentação.html#fig:imagemLimiarizMultiv2">6.56</a> (a). Uma forma de segmentar uma imagem colorida com base neste parâmetro é calcular uma medida de distância, <span class="math inline">\(D(z, a)\)</span>, entre um ponto de cor arbitrária, <span class="math inline">\(z\)</span>, e a cor média, <span class="math inline">\(a\)</span>. Então, tem-se a segmentação, Figura <a href="segmentação.html#fig:imagemLimiarizMultiv2">6.56</a> (b):</p>
<p><span class="math display">\[ g=
\begin{cases}
  1,\ se\ D(z,a)\ &lt;\ T\\
  0,\ caso\ contrário
\end{cases}
\]</span></p>

<div class="figure" style="text-align: center"><span id="fig:imagemLimiarizMultiv2"></span>
<img src="imagens/06-segmentacao/imagemLimiarizMultiv2.png" alt="Exemplo de segmentação multivariada no RGB. [2, p. 295]." width="55%" />
<p class="caption">
Figura 6.56: Exemplo de segmentação multivariada no RGB. <span class="citation">[<a href="#ref-gonzalez2010" role="doc-biblioref">2</a>, p. 295]</span>.
</p>
</div>
<p>Porém, esse cálculo de distância dos pontos ao centro em formato esférico é trabalhoso para o computador. Uma maneira mais eficiente é usar um delimitador cúbico. Nessa metodologia, o cubo é centralizado em <span class="math inline">\(a\)</span> e suas dimensões ao longo de cada um dos eixos de cor são escolhidas em proporção ao desvio padrão das amostras da imagem ao longo de cada um dos eixos (R, G e B).</p>
<p>Portanto, o procedimento da Figura <a href="segmentação.html#fig:imagemLimiarizMultiv2">6.56</a> (a) consistiu em calcular o vetor médio <span class="math inline">\(a\)</span> utilizando os pontos de cor contidos no retângulo. Em seguida, calculou-se o desvio padrão dos componentes vermelho, verde e azul dessas amostras. Um cubo foi centralizado em <span class="math inline">\(a\)</span>, e as dimensões ao longo de cada um dos eixos RGB foram escolhidas como 1,25 multiplicado pelo desvio padrão ao longo dos eixos correspondentes. Por exemplo, no eixo <span class="math inline">\(R\)</span>, vermelho, a dimensão do cubo é de <span class="math inline">\((a_R - 1,25\sigma_R)\)</span> até <span class="math inline">\((a_R + 1,25\sigma_R)\)</span>, no qual <span class="math inline">\(a_R\)</span> indica o valor do componente vermelho de <span class="math inline">\(a\)</span>. E por fim, realizou-se a limiarização.</p>


</div>
</div>
</div>
<h3>Refêrencias</h3>
<div id="refs" class="references">
<div id="ref-gonzalez2010">
<p>[2] R. C. Gonzalez e R. C. Woods, <em>Processamento digital de imagens</em>, 3º ed. São Paulo: Pearson Prentice Hall, 2010.</p>
</div>
<div id="ref-pedrini2008">
<p>[3] H. Pedrini e W. Robson Schwartz, <em>Análise de imagens digitais: princípios, algoritmos e aplicações</em>, 3º ed. São Paulo: Thomson Learning Edicoes Ltda, 2007.</p>
</div>
<div id="ref-burger2009">
<p>[8] W. Burger, M. J. Burge, M. J. Burge, e M. J. Burge, <em>Principles of digital image processing</em>, vol. 111. Springer, 2009.</p>
</div>
<div id="ref-canny1986computational">
<p>[17] J. Canny, “A computational approach to edge detection”, <em>IEEE Transactions on pattern analysis and machine intelligence</em>, nº 6, p. 679–698, 1986.</p>
</div>
<div id="ref-sonka2014">
<p>[18] M. Sonka, V. Hlavac, e R. Boyle, <em>Image processing, analysis, and machine vision</em>. Cengage Learning, 2014.</p>
</div>
<div id="ref-nixon2019feature">
<p>[19] M. Nixon e A. Aguado, <em>Feature extraction and image processing for computer vision</em>. Academic press, 2019.</p>
</div>
<div id="ref-img:hubbledeep">
<p>[20] Nasa, “Hubble Ultra-Deep Field”. 2004, [Online]. Disponível em: <a href="https://imgsrc.hubblesite.org/hu/db/images/hs-2014-27-a-full_jpg.jpg">https://imgsrc.hubblesite.org/hu/db/images/hs-2014-27-a-full_jpg.jpg</a>.</p>
</div>
<div id="ref-bay2006surf">
<p>[21] H. Bay, T. Tuytelaars, e L. Van Gool, “Surf: Speeded up robust features”, p. 404–417, 2006.</p>
</div>
<div id="ref-Cen2016StudyOV">
<p>[22] K. Cen, “Study of Viola-Jones Real Time Face Detector”, 2016.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>se <span class="math inline">\(f(x,y) \leq T\)</span>, significa que se desconsida^ o endereço daquele <em>píxel</em><a href="segmentação.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>O uso desses termos não é universal e é provável vê-los sendo utilizados indiferentemente na literatura de processamento de imagem.<a href="segmentação.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>A limiarização com dois limiares às vezes é chamada histerese de limiarização.<a href="segmentação.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="filtros.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="refêrencias.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": null
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/covap-utfpr/pdi/edit/master/06-segmentacao.Rmd",
"text": "Editar "
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"citation_package": "biblatex"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
